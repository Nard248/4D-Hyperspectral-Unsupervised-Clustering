{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-10T12:11:04.383447Z",
     "start_time": "2025-04-10T12:10:56.620384Z"
    }
   },
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "\n",
    "with h5py.File('../kiwi_hyperspectral_4d_data_with_mask.h5', 'r') as f:\n",
    "    # Create basic noise metrics on a few sample slices to establish baseline\n",
    "    # Pick a few representative excitation wavelengths for testing\n",
    "    excitation_wavelengths = [300, 350, 400, 450, 500]  # Example values, adjust to your actual data\n",
    "\n",
    "    # Create dictionary to store original data samples for testing\n",
    "    test_samples = {}\n",
    "\n",
    "    for ex_wavelength in excitation_wavelengths:\n",
    "        group_name = f'excitation_{ex_wavelength}'\n",
    "        if group_name in f:\n",
    "            # Get average cube for this excitation\n",
    "            if 'average_cube' in f[group_name]:\n",
    "                # Store a few emission bands for testing\n",
    "                avg_cube = f[group_name]['average_cube'][:]\n",
    "                # Select a few bands (beginning, middle, end)\n",
    "                band_indices = [0, avg_cube.shape[0]//2, avg_cube.shape[0]-1]\n",
    "                for band_idx in band_indices:\n",
    "                    test_samples[f\"ex{ex_wavelength}_band{band_idx}\"] = avg_cube[band_idx]\n",
    "\n",
    "    # Print some basic noise statistics\n",
    "    for name, image in test_samples.items():\n",
    "        print(f\"Sample {name}:\")\n",
    "        print(f\"  Min: {np.min(image):.4f}, Max: {np.max(image):.4f}\")\n",
    "        print(f\"  Mean: {np.mean(image):.4f}, Std: {np.std(image):.4f}\")\n",
    "        print(f\"  Signal-to-Noise Ratio: {np.mean(image)/np.std(image):.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample ex300_band0:\n",
      "  Min: 11.2000, Max: 237.3000\n",
      "  Mean: 40.6019, Std: 8.7898\n",
      "  Signal-to-Noise Ratio: 4.6192\n",
      "Sample ex300_band70:\n",
      "  Min: 4.4000, Max: 78.9000\n",
      "  Mean: 13.4735, Std: 2.9796\n",
      "  Signal-to-Noise Ratio: 4.5219\n",
      "Sample ex300_band140:\n",
      "  Min: 1.6000, Max: 30.2000\n",
      "  Mean: 5.7430, Std: 1.3336\n",
      "  Signal-to-Noise Ratio: 4.3064\n",
      "Sample ex350_band0:\n",
      "  Min: 14.9000, Max: 180.4000\n",
      "  Mean: 42.2566, Std: 8.9541\n",
      "  Signal-to-Noise Ratio: 4.7192\n",
      "Sample ex350_band70:\n",
      "  Min: 5.0000, Max: 67.5000\n",
      "  Mean: 14.0121, Std: 3.0434\n",
      "  Signal-to-Noise Ratio: 4.6041\n",
      "Sample ex350_band140:\n",
      "  Min: 2.0000, Max: 29.4000\n",
      "  Mean: 5.9886, Std: 1.3601\n",
      "  Signal-to-Noise Ratio: 4.4032\n",
      "Sample ex400_band0:\n",
      "  Min: 17.0000, Max: 373.7000\n",
      "  Mean: 45.7771, Std: 12.0766\n",
      "  Signal-to-Noise Ratio: 3.7906\n",
      "Sample ex400_band70:\n",
      "  Min: 5.3000, Max: 79.2000\n",
      "  Mean: 14.9543, Std: 3.4642\n",
      "  Signal-to-Noise Ratio: 4.3168\n",
      "Sample ex400_band140:\n",
      "  Min: 2.0000, Max: 37.4000\n",
      "  Mean: 6.3930, Std: 1.5202\n",
      "  Signal-to-Noise Ratio: 4.2053\n",
      "Sample ex450_band0:\n",
      "  Min: 0.0000, Max: 667.7000\n",
      "  Mean: 61.2972, Std: 36.2671\n",
      "  Signal-to-Noise Ratio: 1.6902\n",
      "Sample ex450_band70:\n",
      "  Min: 0.0000, Max: 183.6000\n",
      "  Mean: 20.0706, Std: 12.1800\n",
      "  Signal-to-Noise Ratio: 1.6478\n",
      "Sample ex450_band140:\n",
      "  Min: 0.0000, Max: 112.7000\n",
      "  Mean: 8.3021, Std: 4.1596\n",
      "  Signal-to-Noise Ratio: 1.9959\n",
      "Sample ex500_band0:\n",
      "  Min: 0.0000, Max: 1449.5000\n",
      "  Mean: 97.6778, Std: 114.2248\n",
      "  Signal-to-Noise Ratio: 0.8551\n",
      "Sample ex500_band70:\n",
      "  Min: 0.0000, Max: 351.6000\n",
      "  Mean: 32.9051, Std: 38.8713\n",
      "  Signal-to-Noise Ratio: 0.8465\n",
      "Sample ex500_band140:\n",
      "  Min: 0.0000, Max: 81.5000\n",
      "  Mean: 9.3342, Std: 5.8557\n",
      "  Signal-to-Noise Ratio: 1.5940\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T12:12:25.905789Z",
     "start_time": "2025-04-10T12:11:31.456678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.restoration import (denoise_bilateral, denoise_tv_chambolle,\n",
    "                                denoise_nl_means, denoise_wavelet)\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import bm3d  # Install via: pip install bm3d\n",
    "\n",
    "# Function to visualize and compare results\n",
    "# Fix the compare_denoising function to specify data_range\n",
    "def compare_denoising(original, denoised_results, title=\"Denoising Comparison\"):\n",
    "    \"\"\"\n",
    "    Compare original image with denoised versions\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    original : 2D array\n",
    "        Original noisy image\n",
    "    denoised_results : dict\n",
    "        Dictionary with method names as keys and denoised images as values\n",
    "    title : str\n",
    "        Plot title\n",
    "    \"\"\"\n",
    "    n_methods = len(denoised_results)\n",
    "    fig, axes = plt.subplots(1, n_methods + 1, figsize=(4*(n_methods + 1), 4))\n",
    "\n",
    "    # Plot original\n",
    "    axes[0].imshow(original, cmap='viridis')\n",
    "    axes[0].set_title(\"Original\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Calculate data range for metrics\n",
    "    data_range = original.max() - original.min()\n",
    "\n",
    "    # Plot denoised versions\n",
    "    for i, (method_name, denoised) in enumerate(denoised_results.items()):\n",
    "        axes[i+1].imshow(denoised, cmap='viridis')\n",
    "        # Calculate PSNR and SSIM with explicit data_range\n",
    "        p = psnr(original, denoised, data_range=data_range)\n",
    "        s = ssim(original, denoised, data_range=data_range)\n",
    "        axes[i+1].set_title(f\"{method_name}\\nPSNR: {p:.2f}, SSIM: {s:.4f}\")\n",
    "        axes[i+1].axis('off')\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "# Process each test sample with classical methods\n",
    "results = {}\n",
    "for name, original in test_samples.items():\n",
    "    print(f\"Processing {name}...\")\n",
    "\n",
    "    # Estimate noise level from image\n",
    "    # For Poisson noise, the variance equals the mean, so sqrt(mean) is the standard deviation\n",
    "    noise_sigma_est = np.sqrt(np.mean(original))\n",
    "    print(f\"  Estimated noise sigma: {noise_sigma_est:.4f}\")\n",
    "\n",
    "    # Initialize results dictionary for this sample\n",
    "    denoised_images = {}\n",
    "\n",
    "    # 1. Bilateral Filter - edge-preserving smoothing\n",
    "    denoised_images[\"Bilateral\"] = denoise_bilateral(original, sigma_color=0.1, sigma_spatial=1)\n",
    "\n",
    "    # 2. Total Variation (TV) - edge-preserving smoothing with flat regions\n",
    "    denoised_images[\"TV-Chambolle\"] = denoise_tv_chambolle(original, weight=0.1)\n",
    "\n",
    "    # 3. Non-Local Means - exploits self-similarity\n",
    "    # Patch size and search window can be tuned\n",
    "    denoised_images[\"NL-Means\"] = denoise_nl_means(original, h=0.8*noise_sigma_est,\n",
    "                                                  patch_size=5, patch_distance=6,\n",
    "                                                  fast_mode=True)\n",
    "\n",
    "    # 4. Wavelet Denoising - good for preserving edges\n",
    "    denoised_images[\"Wavelet\"] = denoise_wavelet(original, method='BayesShrink',\n",
    "                                               mode='soft', wavelet='db4')\n",
    "\n",
    "    # 5. BM3D - state-of-the-art patch-based denoising\n",
    "    denoised_images[\"BM3D\"] = bm3d.bm3d(original, sigma_psd=noise_sigma_est)\n",
    "\n",
    "    # Plot and compare results\n",
    "    fig = compare_denoising(original, denoised_images,\n",
    "                           f\"Denoising Results for {name}\")\n",
    "\n",
    "    # Store results for this sample\n",
    "    results[name] = {\n",
    "        'original': original,\n",
    "        'denoised': denoised_images,\n",
    "        'figure': fig\n",
    "    }\n",
    "\n",
    "    # Save figure\n",
    "    fig.savefig(f\"Denoising Standard With Mask/denoising_comparison_{name}.png\", dpi=150)\n",
    "    plt.close(fig)"
   ],
   "id": "980eb9ca356e8b6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ex300_band0...\n",
      "  Estimated noise sigma: 6.3720\n",
      "Processing ex300_band70...\n",
      "  Estimated noise sigma: 3.6706\n",
      "Processing ex300_band140...\n",
      "  Estimated noise sigma: 2.3964\n",
      "Processing ex350_band0...\n",
      "  Estimated noise sigma: 6.5005\n",
      "Processing ex350_band70...\n",
      "  Estimated noise sigma: 3.7433\n",
      "Processing ex350_band140...\n",
      "  Estimated noise sigma: 2.4472\n",
      "Processing ex400_band0...\n",
      "  Estimated noise sigma: 6.7659\n",
      "Processing ex400_band70...\n",
      "  Estimated noise sigma: 3.8671\n",
      "Processing ex400_band140...\n",
      "  Estimated noise sigma: 2.5284\n",
      "Processing ex450_band0...\n",
      "  Estimated noise sigma: 7.8293\n",
      "Processing ex450_band70...\n",
      "  Estimated noise sigma: 4.4800\n",
      "Processing ex450_band140...\n",
      "  Estimated noise sigma: 2.8813\n",
      "Processing ex500_band0...\n",
      "  Estimated noise sigma: 9.8832\n",
      "Processing ex500_band70...\n",
      "  Estimated noise sigma: 5.7363\n",
      "Processing ex500_band140...\n",
      "  Estimated noise sigma: 3.0552\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T15:01:23.193712Z",
     "start_time": "2025-04-09T15:00:39.485514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import scipy.ndimage as ndi\n",
    "from skimage.restoration import denoise_tv_bregman\n",
    "\n",
    "# Anscombe transform to stabilize variance of Poisson noise\n",
    "def anscombe_transform(image):\n",
    "    \"\"\"Apply Anscombe transform to convert Poisson noise to Gaussian noise\"\"\"\n",
    "    return 2 * np.sqrt(np.maximum(image + 3/8, 0))\n",
    "\n",
    "# Inverse Anscombe transform with bias correction\n",
    "def inverse_anscombe_transform(image):\n",
    "    \"\"\"Apply inverse Anscombe transform with bias correction\"\"\"\n",
    "    return (image/2)**2 - 3/8\n",
    "\n",
    "# Function to apply Anscombe + denoiser + inverse Anscombe\n",
    "def anscombe_denoise(image, denoiser, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Apply Anscombe transform, denoise, and inverse Anscombe\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : 2D array\n",
    "        Input image with Poisson noise\n",
    "    denoiser : function\n",
    "        Denoising function to apply (e.g., bm3d.bm3d)\n",
    "    *args, **kwargs :\n",
    "        Arguments to pass to the denoiser\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    denoised_image : 2D array\n",
    "        Denoised image\n",
    "    \"\"\"\n",
    "    # Apply Anscombe transform\n",
    "    transformed = anscombe_transform(image)\n",
    "\n",
    "    # Apply denoiser to transformed image\n",
    "    denoised_transformed = denoiser(transformed, *args, **kwargs)\n",
    "\n",
    "    # Apply inverse Anscombe transform\n",
    "    denoised = inverse_anscombe_transform(denoised_transformed)\n",
    "\n",
    "    # Ensure non-negative values\n",
    "    denoised = np.maximum(denoised, 0)\n",
    "\n",
    "    return denoised\n",
    "\n",
    "# Process each test sample with Poisson-specific methods\n",
    "poisson_results = {}\n",
    "for name, original in test_samples.items():\n",
    "    print(f\"Processing {name} with Poisson-specific methods...\")\n",
    "\n",
    "    # Initialize results dictionary for this sample\n",
    "    denoised_images = {}\n",
    "\n",
    "    # 1. Anscombe + BM3D (very effective for Poisson noise)\n",
    "    denoised_images[\"Anscombe+BM3D\"] = anscombe_denoise(\n",
    "        original, bm3d.bm3d, sigma_psd=1.0)  # Sigma=1.0 after Anscombe transform\n",
    "\n",
    "    # 2. Anscombe + Wavelet\n",
    "    denoised_images[\"Anscombe+Wavelet\"] = anscombe_denoise(\n",
    "        original, denoise_wavelet, method='BayesShrink', mode='soft', wavelet='db4')\n",
    "\n",
    "    # 3. Total Variation with Poisson fidelity term\n",
    "    # Note: This is an approximation; a true Poisson-TV would need specialized solvers\n",
    "    denoised_images[\"TV-Bregman\"] = denoise_tv_bregman(original, weight=0.1)\n",
    "\n",
    "    # 4. Median filter (often effective for salt-and-pepper/shot noise)\n",
    "    denoised_images[\"Median\"] = ndi.median_filter(original, size=3)\n",
    "\n",
    "    # Plot and compare results\n",
    "    fig = compare_denoising(original, denoised_images,\n",
    "                           f\"Poisson Denoising Results for {name}\")\n",
    "\n",
    "    # Store results for this sample\n",
    "    poisson_results[name] = {\n",
    "        'original': original,\n",
    "        'denoised': denoised_images,\n",
    "        'figure': fig\n",
    "    }\n",
    "\n",
    "    # Save figure\n",
    "    fig.savefig(f\"Poisson Denoising/poisson_denoising_comparison_{name}.png\", dpi=150)\n",
    "    plt.close(fig)"
   ],
   "id": "7b2c6e6803cd9d16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ex300_band0 with Poisson-specific methods...\n",
      "Processing ex300_band70 with Poisson-specific methods...\n",
      "Processing ex300_band140 with Poisson-specific methods...\n",
      "Processing ex350_band0 with Poisson-specific methods...\n",
      "Processing ex350_band70 with Poisson-specific methods...\n",
      "Processing ex350_band140 with Poisson-specific methods...\n",
      "Processing ex400_band0 with Poisson-specific methods...\n",
      "Processing ex400_band70 with Poisson-specific methods...\n",
      "Processing ex400_band140 with Poisson-specific methods...\n",
      "Processing ex450_band0 with Poisson-specific methods...\n",
      "Processing ex450_band70 with Poisson-specific methods...\n",
      "Processing ex450_band140 with Poisson-specific methods...\n",
      "Processing ex500_band0 with Poisson-specific methods...\n",
      "Processing ex500_band70 with Poisson-specific methods...\n",
      "Processing ex500_band140 with Poisson-specific methods...\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T15:07:21.556264Z",
     "start_time": "2025-04-09T15:05:22.181522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For 3D data (x, y, emission for a fixed excitation), BM4D is a powerful extension\n",
    "# This requires installing the bm4d package: pip install bm4d\n",
    "import bm4d\n",
    "\n",
    "def process_with_bm4d(cube, sigma=None):\n",
    "    \"\"\"\n",
    "    Process a 3D hyperspectral cube with BM4D\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    cube : 3D array (bands, height, width)\n",
    "        Hyperspectral cube to denoise\n",
    "    sigma : float or None\n",
    "        Noise standard deviation. If None, estimated from data.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    denoised_cube : 3D array\n",
    "        Denoised hyperspectral cube\n",
    "    \"\"\"\n",
    "    # Reshape to (height, width, bands) as expected by BM4D\n",
    "    cube_reshaped = np.transpose(cube, (1, 2, 0))\n",
    "\n",
    "    # Estimate noise if not provided\n",
    "    if sigma is None:\n",
    "        # For Poisson, estimate as sqrt(mean)\n",
    "        sigma = np.sqrt(np.mean(cube_reshaped))\n",
    "\n",
    "    # Apply BM4D\n",
    "    denoised_reshaped = bm4d.bm4d(cube_reshaped, sigma)\n",
    "\n",
    "    # Reshape back to original form\n",
    "    denoised_cube = np.transpose(denoised_reshaped, (2, 0, 1))\n",
    "\n",
    "    return denoised_cube\n",
    "\n",
    "# Test BM4D on one excitation's cube\n",
    "with h5py.File('../kiwi_hyperspectral_4d_data.h5', 'r') as f:\n",
    "    for ex_wavelength in excitation_wavelengths:  # Just try the first one\n",
    "        group_name = f'excitation_{ex_wavelength}'\n",
    "        if group_name in f and 'average_cube' in f[group_name]:\n",
    "            print(f\"Processing full cube for excitation {ex_wavelength} with BM4D...\")\n",
    "\n",
    "            # Get the cube\n",
    "            cube = f[group_name]['average_cube'][:]\n",
    "\n",
    "            # Process with BM4D\n",
    "            denoised_cube = process_with_bm4d(cube)\n",
    "\n",
    "            # Compare a few bands\n",
    "            for band_idx in [0, cube.shape[0]//2, cube.shape[0]-1]:\n",
    "                # Plot original vs denoised for this band\n",
    "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "                ax1.imshow(cube[band_idx], cmap='viridis')\n",
    "                ax1.set_title(f\"Original - Band {band_idx}\")\n",
    "                ax1.axis('off')\n",
    "\n",
    "                ax2.imshow(denoised_cube[band_idx], cmap='viridis')\n",
    "                ax2.set_title(f\"BM4D Denoised - Band {band_idx}\")\n",
    "                ax2.axis('off')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"Advanced Denoising/bm4d_ex{ex_wavelength}_band{band_idx}.png\", dpi=150)\n",
    "                plt.close()"
   ],
   "id": "25de6647faf22b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing full cube for excitation 300 with BM4D...\n",
      "Processing full cube for excitation 350 with BM4D...\n",
      "Processing full cube for excitation 400 with BM4D...\n",
      "Processing full cube for excitation 450 with BM4D...\n",
      "Processing full cube for excitation 500 with BM4D...\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T15:57:16.324212Z",
     "start_time": "2025-04-09T15:57:13.550120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Set up GPU memory growth to avoid OOM errors\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Create Noise2Void U-Net model\n",
    "def build_n2v_model(input_shape):\n",
    "    \"\"\"Build a U-Net model suitable for Noise2Void training\"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "\n",
    "    # Decoder\n",
    "    up4 = Concatenate()([UpSampling2D(size=(2, 2))(conv3), conv2])\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(up4)\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(conv4)\n",
    "\n",
    "    up5 = Concatenate()([UpSampling2D(size=(2, 2))(conv4), conv1])\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(up5)\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    outputs = Conv2D(1, 1, activation='linear')(conv5)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create blind-spot mask for Noise2Void\n",
    "def create_blind_spot_mask(batch_size, height, width, blind_spot_percentage=0.25):\n",
    "    \"\"\"Create a random blind spot mask for Noise2Void training\"\"\"\n",
    "    # Create random mask (1 for blind spots, 0 for normal pixels)\n",
    "    mask = np.zeros((batch_size, height, width, 1))\n",
    "\n",
    "    # Randomly select percentage of pixels to be blind spots\n",
    "    for i in range(batch_size):\n",
    "        num_pixels = int(height * width * blind_spot_percentage)\n",
    "        flat_idx = np.random.choice(height * width, num_pixels, replace=False)\n",
    "        y_idx, x_idx = np.unravel_index(flat_idx, (height, width))\n",
    "        mask[i, y_idx, x_idx, 0] = 1\n",
    "\n",
    "    return mask.astype(np.bool)\n",
    "\n",
    "# Noise2Void data generator\n",
    "def n2v_data_generator(images, batch_size=8, blind_spot_percentage=0.25):\n",
    "    \"\"\"Generate training batches for Noise2Void\"\"\"\n",
    "    num_images = len(images)\n",
    "    height, width = images[0].shape\n",
    "\n",
    "    while True:\n",
    "        # Select random images for the batch\n",
    "        indices = np.random.choice(num_images, batch_size, replace=(batch_size > num_images))\n",
    "        batch_images = np.array([images[i] for i in indices])\n",
    "\n",
    "        # Reshape for the model\n",
    "        batch_x = batch_images.reshape(batch_size, height, width, 1)\n",
    "        batch_y = np.copy(batch_x)\n",
    "\n",
    "        # Create blind spots\n",
    "        mask = create_blind_spot_mask(batch_size, height, width, blind_spot_percentage)\n",
    "\n",
    "        # Replace blind spot pixels with neighborhood mean in input\n",
    "        for i in range(batch_size):\n",
    "            for y, x in zip(*np.where(mask[i, :, :, 0])):\n",
    "                # Define neighborhood (excluding center pixel)\n",
    "                y_min, y_max = max(0, y-1), min(height, y+2)\n",
    "                x_min, x_max = max(0, x-1), min(width, x+2)\n",
    "\n",
    "                # Get neighborhood values (excluding center)\n",
    "                neighborhood = batch_x[i, y_min:y_max, x_min:x_max, 0].copy()\n",
    "                if y_min <= y < y_max and x_min <= x < x_max:  # Check if center pixel is in neighborhood\n",
    "                    # Create mask to exclude center pixel\n",
    "                    center_y, center_x = y - y_min, x - x_min\n",
    "                    mask_2d = np.ones_like(neighborhood, dtype=bool)\n",
    "                    mask_2d[center_y, center_x] = False\n",
    "                    neighborhood = neighborhood[mask_2d]\n",
    "\n",
    "                # Replace with random neighbor or mean\n",
    "                if len(neighborhood) > 0:\n",
    "                    #batch_x[i, y, x, 0] = neighborhood[np.random.randint(len(neighborhood))]  # Random neighbor\n",
    "                    batch_x[i, y, x, 0] = np.mean(neighborhood)  # Mean of neighbors\n",
    "\n",
    "        yield batch_x, batch_y\n",
    "\n",
    "# Function to extract training data from H5 file\n",
    "def extract_training_data(h5_file, max_images_per_excitation=20):\n",
    "    \"\"\"Extract training images from hyperspectral data\"\"\"\n",
    "    training_images = []\n",
    "\n",
    "    with h5py.File(h5_file, 'r') as f:\n",
    "        for group_name in f:\n",
    "            if group_name.startswith('excitation_'):\n",
    "                print(f\"Processing {group_name} for training data...\")\n",
    "\n",
    "                # Get the average cube for this excitation\n",
    "                if 'average_cube' in f[group_name]:\n",
    "                    avg_cube = f[group_name]['average_cube'][:]\n",
    "\n",
    "                    # Take a limited number of bands\n",
    "                    num_bands = min(avg_cube.shape[0], max_images_per_excitation)\n",
    "                    indices = np.linspace(0, avg_cube.shape[0]-1, num_bands, dtype=int)\n",
    "\n",
    "                    for band_idx in indices:\n",
    "                        # Normalize to 0-1 range for better training\n",
    "                        band = avg_cube[band_idx]\n",
    "                        if np.max(band) > np.min(band):\n",
    "                            band = (band - np.min(band)) / (np.max(band) - np.min(band))\n",
    "                        training_images.append(band)\n",
    "\n",
    "                # Also use individual cubes if available\n",
    "                for key in f[group_name]:\n",
    "                    if key.startswith('cube_'):\n",
    "                        cube = f[group_name][key]['data'][:]\n",
    "\n",
    "                        # Take a limited number of bands\n",
    "                        num_bands = min(cube.shape[0], max_images_per_excitation // 2)\n",
    "                        indices = np.linspace(0, cube.shape[0]-1, num_bands, dtype=int)\n",
    "\n",
    "                        for band_idx in indices:\n",
    "                            band = cube[band_idx]\n",
    "                            if np.max(band) > np.min(band):\n",
    "                                band = (band - np.min(band)) / (np.max(band) - np.min(band))\n",
    "                            training_images.append(band)\n",
    "\n",
    "    print(f\"Extracted {len(training_images)} training images\")\n",
    "    return training_images\n",
    "\n",
    "# Train Noise2Void model\n",
    "def train_noise2void(h5_file, output_model_path='n2v_model.h5', epochs=1, batch_size=8):\n",
    "    \"\"\"Train a Noise2Void model on hyperspectral data\"\"\"\n",
    "    # Extract training images\n",
    "    training_images = extract_training_data(h5_file)\n",
    "\n",
    "    if not training_images:\n",
    "        print(\"No training images found!\")\n",
    "        return None\n",
    "\n",
    "    # Get image dimensions\n",
    "    height, width = training_images[0].shape\n",
    "\n",
    "    # Build model\n",
    "    model = build_n2v_model((height, width, 1))\n",
    "    print(model.summary())\n",
    "\n",
    "    # Create data generator\n",
    "    train_gen = n2v_data_generator(training_images, batch_size=batch_size)\n",
    "\n",
    "    # Create directory for model if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(output_model_path) if os.path.dirname(output_model_path) else '.', exist_ok=True)\n",
    "\n",
    "    # Train model\n",
    "    steps_per_epoch = max(1, len(training_images) // batch_size)\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Save the model\n",
    "    model.save(output_model_path)\n",
    "    print(f\"Model saved to {output_model_path}\")\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('Noise2Void Training Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.savefig(output_model_path.replace('.h5', '_loss.png'))\n",
    "    plt.close()\n",
    "\n",
    "    return model\n",
    "\n",
    "# Apply Noise2Void model to denoise images\n",
    "def apply_noise2void(model, images):\n",
    "    \"\"\"Apply trained Noise2Void model to denoise images\"\"\"\n",
    "    height, width = images[0].shape\n",
    "    denoised_images = []\n",
    "\n",
    "    for img in tqdm(images, desc=\"Denoising images\"):\n",
    "        # Normalize\n",
    "        img_min, img_max = np.min(img), np.max(img)\n",
    "        img_norm = (img - img_min) / (img_max - img_min) if img_max > img_min else img\n",
    "\n",
    "        # Reshape for model\n",
    "        img_input = img_norm.reshape(1, height, width, 1)\n",
    "\n",
    "        # Get denoised image\n",
    "        denoised = model.predict(img_input)[0, :, :, 0]\n",
    "\n",
    "        # Rescale back to original range\n",
    "        denoised = denoised * (img_max - img_min) + img_min\n",
    "\n",
    "        denoised_images.append(denoised)\n",
    "\n",
    "    return np.array(denoised_images)\n",
    "\n",
    "# Process entire dataset with Noise2Void\n",
    "def denoise_dataset_with_noise2void(input_file, output_file, model_path=None):\n",
    "    \"\"\"Denoise entire hyperspectral dataset with Noise2Void\"\"\"\n",
    "    # Train or load model\n",
    "    if model_path and os.path.exists(model_path):\n",
    "        print(f\"Loading model from {model_path}\")\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "    else:\n",
    "        print(\"Training new Noise2Void model...\")\n",
    "        model = train_noise2void(input_file, output_model_path=model_path if model_path else 'n2v_model.h5')\n",
    "\n",
    "    if model is None:\n",
    "        print(\"Failed to create or load model!\")\n",
    "        return\n",
    "\n",
    "    # Open input and output files\n",
    "    with h5py.File(input_file, 'r') as f_in, h5py.File(output_file, 'w') as f_out:\n",
    "        # Copy metadata\n",
    "        if 'metadata' in f_in:\n",
    "            metadata_group = f_out.create_group('metadata')\n",
    "            for key, value in f_in['metadata'].attrs.items():\n",
    "                metadata_group.attrs[key] = value\n",
    "            metadata_group.attrs['denoising_method'] = 'Noise2Void'\n",
    "            metadata_group.attrs['denoising_date'] = str(np.datetime64('now'))\n",
    "\n",
    "        # Process each excitation group\n",
    "        for group_name in f_in:\n",
    "            if group_name.startswith('excitation_'):\n",
    "                print(f\"Processing {group_name}...\")\n",
    "\n",
    "                # Create corresponding group in output\n",
    "                group_out = f_out.create_group(group_name)\n",
    "\n",
    "                # Copy wavelengths\n",
    "                if 'wavelengths' in f_in[group_name]:\n",
    "                    group_out.create_dataset('wavelengths', data=f_in[group_name]['wavelengths'][:])\n",
    "\n",
    "                # Process average cube if present\n",
    "                if 'average_cube' in f_in[group_name]:\n",
    "                    avg_cube = f_in[group_name]['average_cube'][:]\n",
    "                    print(f\"  Denoising average cube of shape {avg_cube.shape}...\")\n",
    "\n",
    "                    # Apply denoising\n",
    "                    denoised_cube = np.zeros_like(avg_cube)\n",
    "                    for i in range(avg_cube.shape[0]):\n",
    "                        band = avg_cube[i]\n",
    "                        # Apply model to this band\n",
    "                        denoised_band = apply_noise2void(model, [band])[0]\n",
    "                        denoised_cube[i] = denoised_band\n",
    "\n",
    "                    # Save denoised cube\n",
    "                    group_out.create_dataset('average_cube', data=denoised_cube,\n",
    "                                           compression='gzip', chunks=True)\n",
    "\n",
    "                # Optionally process individual cubes (can be time-consuming)\n",
    "                for dataset_name in f_in[group_name]:\n",
    "                    if dataset_name.startswith('cube_'):\n",
    "                        # Just copy individual cubes without denoising\n",
    "                        f_in[group_name][dataset_name].copy(source=f_in[group_name][dataset_name],\n",
    "                                                           dest=group_out)\n",
    "\n",
    "                # Copy mask if present\n",
    "                if 'mask' in f_in[group_name]:\n",
    "                    f_in[group_name]['mask'].copy(source=f_in[group_name]['mask'],\n",
    "                                                dest=group_out)\n",
    "\n",
    "    print(f\"Denoised dataset saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "# denoise_dataset_with_noise2void('kiwi_hyperspectral_4d_data.h5',\n",
    "#                               'kiwi_hyperspectral_4d_data_n2v_denoised.h5',\n",
    "#                               model_path='n2v_model.h5')"
   ],
   "id": "d0a5866270328c3c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:05:28.401307Z",
     "start_time": "2025-04-09T15:57:16.334218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "denoise_dataset_with_noise2void('../kiwi_hyperspectral_4d_data.h5',\n",
    "                              'kiwi_hyperspectral_4d_data_n2v_denoised.h5',\n",
    "                              model_path='n2v_model.h5')"
   ],
   "id": "880f086238c3c95f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training new Noise2Void model...\n",
      "Processing excitation_300 for training data...\n",
      "Processing excitation_310 for training data...\n",
      "Processing excitation_320 for training data...\n",
      "Processing excitation_330 for training data...\n",
      "Processing excitation_340 for training data...\n",
      "Processing excitation_350 for training data...\n",
      "Processing excitation_360 for training data...\n",
      "Processing excitation_370 for training data...\n",
      "Processing excitation_380 for training data...\n",
      "Processing excitation_390 for training data...\n",
      "Processing excitation_400 for training data...\n",
      "Processing excitation_410 for training data...\n",
      "Processing excitation_420 for training data...\n",
      "Processing excitation_430 for training data...\n",
      "Processing excitation_440 for training data...\n",
      "Processing excitation_450 for training data...\n",
      "Processing excitation_460 for training data...\n",
      "Processing excitation_470 for training data...\n",
      "Processing excitation_480 for training data...\n",
      "Processing excitation_490 for training data...\n",
      "Processing excitation_500 for training data...\n",
      "Extracted 2520 training images\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m, \u001B[38;5;34m640\u001B[0m,  │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │ \u001B[38;5;34m1\u001B[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001B[38;5;33mConv2D\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m, \u001B[38;5;34m640\u001B[0m,  │        \u001B[38;5;34m640\u001B[0m │ input_layer[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] │\n",
       "│                     │ \u001B[38;5;34m64\u001B[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001B[38;5;33mConv2D\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m, \u001B[38;5;34m640\u001B[0m,  │     \u001B[38;5;34m36,928\u001B[0m │ conv2d[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]      │\n",
       "│                     │ \u001B[38;5;34m64\u001B[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m, \u001B[38;5;34m320\u001B[0m,  │          \u001B[38;5;34m0\u001B[0m │ conv2d_1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "│ (\u001B[38;5;33mMaxPooling2D\u001B[0m)      │ \u001B[38;5;34m64\u001B[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001B[38;5;33mConv2D\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m, \u001B[38;5;34m320\u001B[0m,  │     \u001B[38;5;34m73,856\u001B[0m │ max_pooling2d[\u001B[38;5;34m0\u001B[0m]… │\n",
       "│                     │ \u001B[38;5;34m128\u001B[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001B[38;5;33mConv2D\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m, \u001B[38;5;34m320\u001B[0m,  │    \u001B[38;5;34m147,584\u001B[0m │ conv2d_2[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "│                     │ \u001B[38;5;34m128\u001B[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m160\u001B[0m,  │          \u001B[38;5;34m0\u001B[0m │ conv2d_3[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "│ (\u001B[38;5;33mMaxPooling2D\u001B[0m)      │ \u001B[38;5;34m128\u001B[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001B[38;5;33mConv2D\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m160\u001B[0m,  │    \u001B[38;5;34m295,168\u001B[0m │ max_pooling2d_1[\u001B[38;5;34m…\u001B[0m │\n",
       "│                     │ \u001B[38;5;34m256\u001B[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001B[38;5;33mConv2D\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m160\u001B[0m,  │    \u001B[38;5;34m590,080\u001B[0m │ conv2d_4[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "│                     │ \u001B[38;5;34m256\u001B[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ up_sampling2d       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m, \u001B[38;5;34m320\u001B[0m,  │          \u001B[38;5;34m0\u001B[0m │ conv2d_5[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "│ (\u001B[38;5;33mUpSampling2D\u001B[0m)      │ \u001B[38;5;34m256\u001B[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m, \u001B[38;5;34m320\u001B[0m,  │          \u001B[38;5;34m0\u001B[0m │ up_sampling2d[\u001B[38;5;34m0\u001B[0m]… │\n",
       "│ (\u001B[38;5;33mConcatenate\u001B[0m)       │ \u001B[38;5;34m384\u001B[0m)              │            │ conv2d_3[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001B[38;5;33mConv2D\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m, \u001B[38;5;34m320\u001B[0m,  │    \u001B[38;5;34m442,496\u001B[0m │ concatenate[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] │\n",
       "│                     │ \u001B[38;5;34m128\u001B[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001B[38;5;33mConv2D\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m, \u001B[38;5;34m320\u001B[0m,  │    \u001B[38;5;34m147,584\u001B[0m │ conv2d_6[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "│                     │ \u001B[38;5;34m128\u001B[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ up_sampling2d_1     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m, \u001B[38;5;34m640\u001B[0m,  │          \u001B[38;5;34m0\u001B[0m │ conv2d_7[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "│ (\u001B[38;5;33mUpSampling2D\u001B[0m)      │ \u001B[38;5;34m128\u001B[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m, \u001B[38;5;34m640\u001B[0m,  │          \u001B[38;5;34m0\u001B[0m │ up_sampling2d_1[\u001B[38;5;34m…\u001B[0m │\n",
       "│ (\u001B[38;5;33mConcatenate\u001B[0m)       │ \u001B[38;5;34m192\u001B[0m)              │            │ conv2d_1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (\u001B[38;5;33mConv2D\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m, \u001B[38;5;34m640\u001B[0m,  │    \u001B[38;5;34m110,656\u001B[0m │ concatenate_1[\u001B[38;5;34m0\u001B[0m]… │\n",
       "│                     │ \u001B[38;5;34m64\u001B[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (\u001B[38;5;33mConv2D\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m, \u001B[38;5;34m640\u001B[0m,  │     \u001B[38;5;34m36,928\u001B[0m │ conv2d_8[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "│                     │ \u001B[38;5;34m64\u001B[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (\u001B[38;5;33mConv2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m, \u001B[38;5;34m640\u001B[0m,  │         \u001B[38;5;34m65\u001B[0m │ conv2d_9[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "│                     │ \u001B[38;5;34m1\u001B[0m)                │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>,  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>,  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>,  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ up_sampling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ up_sampling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              │            │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>,  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">442,496</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>,  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ up_sampling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ up_sampling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>,  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">110,656</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,881,985\u001B[0m (7.18 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,881,985</span> (7.18 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,881,985\u001B[0m (7.18 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,881,985</span> (7.18 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\u001B[1m 46/315\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m39:10\u001B[0m 9s/step - loss: 0.0049"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mdenoise_dataset_with_noise2void\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m../kiwi_hyperspectral_4d_data.h5\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[43m                              \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mkiwi_hyperspectral_4d_data_n2v_denoised.h5\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m                              \u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mn2v_model.h5\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 228\u001B[39m, in \u001B[36mdenoise_dataset_with_noise2void\u001B[39m\u001B[34m(input_file, output_file, model_path)\u001B[39m\n\u001B[32m    226\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    227\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mTraining new Noise2Void model...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m228\u001B[39m     model = \u001B[43mtrain_noise2void\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_model_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mn2v_model.h5\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    230\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m model \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    231\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mFailed to create or load model!\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 173\u001B[39m, in \u001B[36mtrain_noise2void\u001B[39m\u001B[34m(h5_file, output_model_path, epochs, batch_size)\u001B[39m\n\u001B[32m    171\u001B[39m \u001B[38;5;66;03m# Train model\u001B[39;00m\n\u001B[32m    172\u001B[39m steps_per_epoch = \u001B[38;5;28mmax\u001B[39m(\u001B[32m1\u001B[39m, \u001B[38;5;28mlen\u001B[39m(training_images) // batch_size)\n\u001B[32m--> \u001B[39m\u001B[32m173\u001B[39m history = \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    174\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_gen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    175\u001B[39m \u001B[43m    \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m=\u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    176\u001B[39m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    177\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\n\u001B[32m    178\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    180\u001B[39m \u001B[38;5;66;03m# Save the model\u001B[39;00m\n\u001B[32m    181\u001B[39m model.save(output_model_path)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Capstone\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    115\u001B[39m filtered_tb = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    116\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m117\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    119\u001B[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Capstone\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001B[39m, in \u001B[36mTensorFlowTrainer.fit\u001B[39m\u001B[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[39m\n\u001B[32m    369\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator:\n\u001B[32m    370\u001B[39m     callbacks.on_train_batch_begin(step)\n\u001B[32m--> \u001B[39m\u001B[32m371\u001B[39m     logs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    372\u001B[39m     callbacks.on_train_batch_end(step, logs)\n\u001B[32m    373\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.stop_training:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Capstone\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001B[39m, in \u001B[36mTensorFlowTrainer._make_function.<locals>.function\u001B[39m\u001B[34m(iterator)\u001B[39m\n\u001B[32m    215\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfunction\u001B[39m(iterator):\n\u001B[32m    216\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[32m    217\u001B[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001B[32m    218\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m219\u001B[39m         opt_outputs = \u001B[43mmulti_step_on_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    220\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m opt_outputs.has_value():\n\u001B[32m    221\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Capstone\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    148\u001B[39m filtered_tb = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    149\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m150\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    151\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    152\u001B[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Capstone\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001B[39m, in \u001B[36mFunction.__call__\u001B[39m\u001B[34m(self, *args, **kwds)\u001B[39m\n\u001B[32m    830\u001B[39m compiler = \u001B[33m\"\u001B[39m\u001B[33mxla\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mnonXla\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    832\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m._jit_compile):\n\u001B[32m--> \u001B[39m\u001B[32m833\u001B[39m   result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    835\u001B[39m new_tracing_count = \u001B[38;5;28mself\u001B[39m.experimental_get_tracing_count()\n\u001B[32m    836\u001B[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Capstone\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001B[39m, in \u001B[36mFunction._call\u001B[39m\u001B[34m(self, *args, **kwds)\u001B[39m\n\u001B[32m    875\u001B[39m \u001B[38;5;28mself\u001B[39m._lock.release()\n\u001B[32m    876\u001B[39m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[32m    877\u001B[39m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m878\u001B[39m results = \u001B[43mtracing_compilation\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    879\u001B[39m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[32m    880\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    881\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._created_variables:\n\u001B[32m    882\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mCreating variables on a non-first call to a function\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    883\u001B[39m                    \u001B[33m\"\u001B[39m\u001B[33m decorated with tf.function.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Capstone\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[39m, in \u001B[36mcall_function\u001B[39m\u001B[34m(args, kwargs, tracing_options)\u001B[39m\n\u001B[32m    137\u001B[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001B[32m    138\u001B[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001B[32m--> \u001B[39m\u001B[32m139\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[32m    140\u001B[39m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[32m    141\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Capstone\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001B[39m, in \u001B[36mConcreteFunction._call_flat\u001B[39m\u001B[34m(self, tensor_inputs, captured_inputs)\u001B[39m\n\u001B[32m   1318\u001B[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001B[32m   1319\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001B[32m   1320\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[32m   1321\u001B[39m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1322\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_inference_function\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1323\u001B[39m forward_backward = \u001B[38;5;28mself\u001B[39m._select_forward_and_backward_functions(\n\u001B[32m   1324\u001B[39m     args,\n\u001B[32m   1325\u001B[39m     possible_gradient_type,\n\u001B[32m   1326\u001B[39m     executing_eagerly)\n\u001B[32m   1327\u001B[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Capstone\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001B[39m, in \u001B[36mAtomicFunction.call_preflattened\u001B[39m\u001B[34m(self, args)\u001B[39m\n\u001B[32m    214\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core.Tensor]) -> Any:\n\u001B[32m    215\u001B[39m \u001B[38;5;250m  \u001B[39m\u001B[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m216\u001B[39m   flat_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    217\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.function_type.pack_output(flat_outputs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Capstone\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001B[39m, in \u001B[36mAtomicFunction.call_flat\u001B[39m\u001B[34m(self, *args)\u001B[39m\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m record.stop_recording():\n\u001B[32m    250\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._bound_context.executing_eagerly():\n\u001B[32m--> \u001B[39m\u001B[32m251\u001B[39m     outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_bound_context\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    252\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    253\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    254\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunction_type\u001B[49m\u001B[43m.\u001B[49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    255\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    256\u001B[39m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    257\u001B[39m     outputs = make_call_op_in_graph(\n\u001B[32m    258\u001B[39m         \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    259\u001B[39m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[32m    260\u001B[39m         \u001B[38;5;28mself\u001B[39m._bound_context.function_call_options.as_attrs(),\n\u001B[32m    261\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Capstone\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001B[39m, in \u001B[36mContext.call_function\u001B[39m\u001B[34m(self, name, tensor_inputs, num_outputs)\u001B[39m\n\u001B[32m   1686\u001B[39m cancellation_context = cancellation.context()\n\u001B[32m   1687\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1688\u001B[39m   outputs = \u001B[43mexecute\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1689\u001B[39m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mutf-8\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1690\u001B[39m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1691\u001B[39m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1692\u001B[39m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1693\u001B[39m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1694\u001B[39m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1695\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1696\u001B[39m   outputs = execute.execute_with_cancellation(\n\u001B[32m   1697\u001B[39m       name.decode(\u001B[33m\"\u001B[39m\u001B[33mutf-8\u001B[39m\u001B[33m\"\u001B[39m),\n\u001B[32m   1698\u001B[39m       num_outputs=num_outputs,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1702\u001B[39m       cancellation_manager=cancellation_context,\n\u001B[32m   1703\u001B[39m   )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Capstone\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[39m, in \u001B[36mquick_execute\u001B[39m\u001B[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[39m\n\u001B[32m     51\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     52\u001B[39m   ctx.ensure_initialized()\n\u001B[32m---> \u001B[39m\u001B[32m53\u001B[39m   tensors = \u001B[43mpywrap_tfe\u001B[49m\u001B[43m.\u001B[49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     54\u001B[39m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     55\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m core._NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m     56\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7dab71cb00085e15"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
