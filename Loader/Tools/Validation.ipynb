{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import copy\n",
    "import traceback\n",
    "\n",
    "\n",
    "def load_data_and_mask(data_path, mask_path):\n",
    "    \"\"\"\n",
    "    Load hyperspectral data and mask.\n",
    "\n",
    "    Args:\n",
    "        data_path: Path to the hyperspectral data pickle file\n",
    "        mask_path: Path to the mask npy file\n",
    "\n",
    "    Returns:\n",
    "        data_dict: The loaded hyperspectral data dictionary\n",
    "        mask: The loaded mask array\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    with open(data_path, 'rb') as f:\n",
    "        data_dict = pickle.load(f)\n",
    "\n",
    "    # Load the mask\n",
    "    mask = np.load(mask_path)\n",
    "\n",
    "    print(f\"Data loaded from: {os.path.basename(data_path)}\")\n",
    "    print(f\"Mask loaded from: {os.path.basename(mask_path)}\")\n",
    "    print(f\"Mask shape: {mask.shape}, {np.sum(mask)} pixels selected ({np.sum(mask)/mask.size*100:.2f}%)\")\n",
    "\n",
    "    return data_dict, mask\n",
    "\n",
    "def find_data_cubes(data_dict):\n",
    "    \"\"\"Find all 3D data cubes in the data structure.\"\"\"\n",
    "    cubes = {}\n",
    "\n",
    "    def _find_cubes(data, path='', max_depth=5, current_depth=0):\n",
    "        if current_depth >= max_depth:\n",
    "            return\n",
    "\n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items():\n",
    "                current_path = f\"{path}.{key}\" if path else key\n",
    "\n",
    "                # Check if this is a data cube (3D numpy array)\n",
    "                if isinstance(value, np.ndarray) and len(value.shape) == 3:\n",
    "                    # Store the cube\n",
    "                    cubes[current_path] = value\n",
    "                    print(f\"Found data cube at {current_path}: shape={value.shape}\")\n",
    "\n",
    "                # Recursively search nested structures\n",
    "                if isinstance(value, (dict, list)):\n",
    "                    _find_cubes(value, current_path, max_depth, current_depth + 1)\n",
    "\n",
    "        elif isinstance(data, list) and len(data) > 0:\n",
    "            # For lists, check the first item\n",
    "            current_path = f\"{path}[0]\"\n",
    "            if isinstance(data[0], (dict, list, np.ndarray)):\n",
    "                _find_cubes(data[0], current_path, max_depth, current_depth + 1)\n",
    "\n",
    "    _find_cubes(data_dict)\n",
    "    return cubes\n",
    "\n",
    "def create_rgb_image(cube, method='rgb', percentile=99):\n",
    "    \"\"\"\n",
    "    Create an RGB representation from a hyperspectral data cube.\n",
    "\n",
    "    Args:\n",
    "        cube: The data cube\n",
    "        method: Method for creating RGB ('rgb', 'max', 'mean')\n",
    "        percentile: Percentile for scaling\n",
    "\n",
    "    Returns:\n",
    "        RGB image as numpy array\n",
    "    \"\"\"\n",
    "    # Check cube dimensions\n",
    "    if len(cube.shape) == 3:\n",
    "        # Identify which dimension is the spectral dimension\n",
    "        if cube.shape[0] < cube.shape[1] and cube.shape[0] < cube.shape[2]:\n",
    "            # First dimension is smallest, likely spectral bands\n",
    "            bands_dim = 0\n",
    "            height_dim = 1\n",
    "            width_dim = 2\n",
    "            print(\"Cube format: (bands, height, width)\")\n",
    "        elif cube.shape[2] < cube.shape[0] and cube.shape[2] < cube.shape[1]:\n",
    "            # Last dimension is smallest, likely spectral bands\n",
    "            bands_dim = 2\n",
    "            height_dim = 0\n",
    "            width_dim = 1\n",
    "            print(\"Cube format: (height, width, bands)\")\n",
    "        else:\n",
    "            # Assume standard format\n",
    "            bands_dim = 0\n",
    "            height_dim = 1\n",
    "            width_dim = 2\n",
    "            print(\"Assuming cube format: (bands, height, width)\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected cube shape: {cube.shape}. Expected 3D array.\")\n",
    "\n",
    "    # Replace NaN values\n",
    "    cube = np.nan_to_num(cube)\n",
    "\n",
    "    # Create RGB based on method\n",
    "    if method == 'rgb':\n",
    "        # Use three wavelengths as RGB channels\n",
    "        num_bands = cube.shape[bands_dim]\n",
    "        if num_bands >= 3:\n",
    "            indices = [int(num_bands * 0.2), int(num_bands * 0.5), int(num_bands * 0.8)]\n",
    "            r_idx, g_idx, b_idx = indices\n",
    "\n",
    "            # Extract band images\n",
    "            if bands_dim == 0:\n",
    "                r_band = cube[r_idx, :, :]\n",
    "                g_band = cube[g_idx, :, :]\n",
    "                b_band = cube[b_idx, :, :]\n",
    "            else:  # bands_dim == 2\n",
    "                r_band = cube[:, :, r_idx]\n",
    "                g_band = cube[:, :, g_idx]\n",
    "                b_band = cube[:, :, b_idx]\n",
    "\n",
    "            # Normalize to range [0, 1]\n",
    "            r_scaled = r_band / np.percentile(r_band, percentile)\n",
    "            g_scaled = g_band / np.percentile(g_band, percentile)\n",
    "            b_scaled = b_band / np.percentile(b_band, percentile)\n",
    "\n",
    "            # Clip to [0, 1] range\n",
    "            r_scaled = np.clip(r_scaled, 0, 1)\n",
    "            g_scaled = np.clip(g_scaled, 0, 1)\n",
    "            b_scaled = np.clip(b_scaled, 0, 1)\n",
    "\n",
    "            # Create RGB image\n",
    "            rgb = np.stack([r_scaled, g_scaled, b_scaled], axis=2)\n",
    "        else:\n",
    "            # Default to max projection if not enough bands\n",
    "            method = 'max'\n",
    "\n",
    "    if method in ['max', 'mean']:\n",
    "        # Generate a projection\n",
    "        if bands_dim == 0:\n",
    "            if method == 'max':\n",
    "                proj = np.max(cube, axis=0)\n",
    "            else:  # mean\n",
    "                proj = np.mean(cube, axis=0)\n",
    "        else:  # bands_dim == 2\n",
    "            if method == 'max':\n",
    "                proj = np.max(cube, axis=2)\n",
    "            else:  # mean\n",
    "                proj = np.mean(cube, axis=2)\n",
    "\n",
    "        # Scale and clip\n",
    "        max_val = np.percentile(proj[~np.isnan(proj)], percentile)  # Exclude NaNs for percentile\n",
    "        scaled = proj / max_val if max_val > 0 else proj\n",
    "        scaled = np.clip(scaled, 0, 1)\n",
    "\n",
    "        # Replace NaNs with zeros\n",
    "        scaled = np.nan_to_num(scaled)\n",
    "\n",
    "        # Create RGB by duplicating the channel\n",
    "        rgb = np.stack([scaled, scaled, scaled], axis=2)\n",
    "\n",
    "    return rgb\n",
    "\n",
    "def visualize_with_mask(data_dict, mask, excitation_key=None, method='rgb',\n",
    "                        overlay_color='red', overlay_alpha=0.5, figsize=(18, 6)):\n",
    "    \"\"\"\n",
    "    Create a visualization of the data with mask.\n",
    "\n",
    "    Args:\n",
    "        data_dict: The hyperspectral data dictionary\n",
    "        mask: The mask array\n",
    "        excitation_key: The excitation key to visualize (if None, uses the first one found)\n",
    "        method: Method for creating RGB ('rgb', 'max', 'mean')\n",
    "        overlay_color: Color of the mask overlay ('red', 'green', 'blue', 'yellow')\n",
    "        overlay_alpha: Transparency of the mask overlay (0-1)\n",
    "        figsize: Figure size\n",
    "\n",
    "    Returns:\n",
    "        fig, axes: The matplotlib figure and axes\n",
    "    \"\"\"\n",
    "    # Find data cubes\n",
    "    cubes = find_data_cubes(data_dict)\n",
    "\n",
    "    if not cubes:\n",
    "        raise ValueError(\"No suitable data cubes found in the data\")\n",
    "\n",
    "    # Select excitation key if not provided\n",
    "    if excitation_key is None or excitation_key not in cubes:\n",
    "        excitation_key = next(iter(cubes))\n",
    "        print(f\"Using excitation key: {excitation_key}\")\n",
    "\n",
    "    # Get the data cube\n",
    "    cube = cubes[excitation_key]\n",
    "\n",
    "    # Create RGB visualization\n",
    "    rgb_image = create_rgb_image(cube, method=method)\n",
    "\n",
    "    # Check mask dimensions\n",
    "    if mask.shape[0] != rgb_image.shape[0] or mask.shape[1] != rgb_image.shape[1]:\n",
    "        raise ValueError(f\"Mask shape {mask.shape} doesn't match image shape {rgb_image.shape[:2]}\")\n",
    "\n",
    "    # Create figure with three subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "\n",
    "    # 1. Original data\n",
    "    axes[0].imshow(rgb_image)\n",
    "    axes[0].set_title(\"Original Data\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # 2. Data with mask overlay\n",
    "    axes[1].imshow(rgb_image)\n",
    "\n",
    "    # Create mask overlay\n",
    "    mask_overlay = np.zeros((*mask.shape, 4), dtype=np.float32)\n",
    "\n",
    "    # Set color based on selection\n",
    "    if overlay_color == 'red':\n",
    "        mask_overlay[mask == 1, 0] = 1.0  # Red channel\n",
    "    elif overlay_color == 'green':\n",
    "        mask_overlay[mask == 1, 1] = 1.0  # Green channel\n",
    "    elif overlay_color == 'blue':\n",
    "        mask_overlay[mask == 1, 2] = 1.0  # Blue channel\n",
    "    elif overlay_color == 'yellow':\n",
    "        mask_overlay[mask == 1, 0] = 1.0  # Red channel\n",
    "        mask_overlay[mask == 1, 1] = 1.0  # Green channel\n",
    "\n",
    "    # Set transparency\n",
    "    mask_overlay[mask == 1, 3] = overlay_alpha\n",
    "\n",
    "    # Show overlay\n",
    "    axes[1].imshow(mask_overlay)\n",
    "    axes[1].set_title(\"Data with Mask Overlay\")\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # 3. Masked data only\n",
    "    masked_image = np.copy(rgb_image)\n",
    "\n",
    "    # Set pixels outside mask to black\n",
    "    for i in range(3):  # R, G, B channels\n",
    "        channel = masked_image[:, :, i]\n",
    "        channel[mask == 0] = 0\n",
    "\n",
    "    axes[2].imshow(masked_image)\n",
    "    axes[2].set_title(\"Masked Data Only\")\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig, axes\n",
    "\n",
    "data_path = r'C:\\Users\\meloy\\PycharmProjects\\Capstone\\Loader\\Data\\Lime Experiment\\processed\\data_cutoff_30nm_exposure_max_power_min.pkl'\n",
    "mask_path = r'C:\\Users\\meloy\\PycharmProjects\\Capstone\\Loader\\Data\\Lime Experiment\\processed\\mask.npy'\n",
    "\n",
    "data_dict, mask = load_data_and_mask(data_path, mask_path)\n",
    "\n",
    "fig, axes = visualize_with_mask(data_dict, mask, method='rgb', overlay_color='red')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_masked_pickle(data_path, mask_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Create a new pickle file with masked hyperspectral data.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): Path to the original hyperspectral data pickle file\n",
    "        mask_path (str): Path to the mask .npy file\n",
    "        output_path (str, optional): Output path for the masked data pickle file.\n",
    "                                    If None, will use original filename + \"_masked.pkl\"\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the saved masked data file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Loading data from {os.path.basename(data_path)}...\")\n",
    "        # Load the original data\n",
    "        with open(data_path, 'rb') as f:\n",
    "            data_dict = pickle.load(f)\n",
    "\n",
    "        print(f\"Loading mask from {os.path.basename(mask_path)}...\")\n",
    "        # Load the mask\n",
    "        mask = np.load(mask_path)\n",
    "\n",
    "        # Create a deep copy to avoid modifying the original\n",
    "        masked_data = copy.deepcopy(data_dict)\n",
    "\n",
    "        # Find data cubes in the structure\n",
    "        print(\"Finding and masking data cubes...\")\n",
    "        cubes = find_data_cubes_with_paths(masked_data)\n",
    "\n",
    "        # Check if mask is binary (0s and 1s)\n",
    "        if not np.all(np.isin(mask, [0, 1])):\n",
    "            print(\"Warning: Mask is not binary. Converting non-zero values to 1.\")\n",
    "            mask = (mask != 0).astype(np.uint8)\n",
    "\n",
    "        # Get mask info\n",
    "        masked_pixels = np.sum(mask)\n",
    "        total_pixels = mask.size\n",
    "        percent_masked = (masked_pixels / total_pixels) * 100\n",
    "        print(f\"Mask selects {masked_pixels} out of {total_pixels} pixels ({percent_masked:.2f}%)\")\n",
    "\n",
    "        # Apply mask to all data cubes\n",
    "        masked_cubes = 0\n",
    "        for cube_path, cube_info in cubes.items():\n",
    "            try:\n",
    "                # Apply mask to this cube\n",
    "                apply_mask_to_cube(masked_data, cube_path, cube_info, mask)\n",
    "                masked_cubes += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error masking cube at {cube_path}: {str(e)}\")\n",
    "\n",
    "        print(f\"Successfully masked {masked_cubes} data cubes\")\n",
    "\n",
    "        # Add mask information to metadata (if metadata exists)\n",
    "        if isinstance(masked_data, dict) and 'metadata' in masked_data:\n",
    "            masked_data['metadata']['mask_applied'] = True\n",
    "            masked_data['metadata']['mask_path'] = mask_path\n",
    "            masked_data['metadata']['mask_shape'] = mask.shape\n",
    "            masked_data['metadata']['mask_sum'] = int(masked_pixels)\n",
    "            masked_data['metadata']['mask_percentage'] = float(percent_masked)\n",
    "\n",
    "        # Determine output path if not provided\n",
    "        if output_path is None:\n",
    "            base_path = os.path.splitext(data_path)[0]\n",
    "            output_path = f\"{base_path}_masked.pkl\"\n",
    "\n",
    "        # Save the masked data\n",
    "        print(f\"Saving masked data to {os.path.basename(output_path)}...\")\n",
    "        with open(output_path, 'wb') as f:\n",
    "            pickle.dump(masked_data, f)\n",
    "\n",
    "        print(f\"Masked data saved successfully to {output_path}\")\n",
    "        return output_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating masked pickle: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def find_data_cubes_with_paths(data, path='', max_depth=5, current_depth=0):\n",
    "    \"\"\"\n",
    "    Find all 3D data cubes in the nested data structure and return them with their paths.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary mapping paths to cube information\n",
    "              {path: {'parent': parent_object, 'key': key, 'shape': shape}}\n",
    "    \"\"\"\n",
    "    cubes = {}\n",
    "\n",
    "    if current_depth >= max_depth:\n",
    "        return cubes\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            current_path = f\"{path}.{key}\" if path else key\n",
    "\n",
    "            # Check if this is a data cube (3D numpy array)\n",
    "            if isinstance(value, np.ndarray) and len(value.shape) == 3:\n",
    "                # Store the cube with its path and parent object for easy access later\n",
    "                cubes[current_path] = {\n",
    "                    'parent': data,\n",
    "                    'key': key,\n",
    "                    'shape': value.shape,\n",
    "                    'is_list': False,\n",
    "                    'list_index': None\n",
    "                }\n",
    "                print(f\"Found data cube at {current_path}: shape={value.shape}\")\n",
    "\n",
    "            # Recursively search nested structures\n",
    "            if isinstance(value, (dict, list)):\n",
    "                nested_cubes = find_data_cubes_with_paths(value, current_path, max_depth, current_depth + 1)\n",
    "                cubes.update(nested_cubes)\n",
    "\n",
    "    elif isinstance(data, list) and len(data) > 0:\n",
    "        for i, item in enumerate(data):\n",
    "            current_path = f\"{path}[{i}]\"\n",
    "\n",
    "            # Check if this item is a data cube\n",
    "            if isinstance(item, np.ndarray) and len(item.shape) == 3:\n",
    "                cubes[current_path] = {\n",
    "                    'parent': data,\n",
    "                    'key': i,\n",
    "                    'shape': item.shape,\n",
    "                    'is_list': True,\n",
    "                    'list_index': i\n",
    "                }\n",
    "                print(f\"Found data cube at {current_path}: shape={item.shape}\")\n",
    "\n",
    "            # Recursively search nested structures\n",
    "            if isinstance(item, (dict, list)):\n",
    "                nested_cubes = find_data_cubes_with_paths(item, current_path, max_depth, current_depth + 1)\n",
    "                cubes.update(nested_cubes)\n",
    "\n",
    "    return cubes\n",
    "\n",
    "def apply_mask_to_cube(data_dict, cube_path, cube_info, mask):\n",
    "    \"\"\"Apply mask to a specific data cube in the data structure.\"\"\"\n",
    "    parent = cube_info['parent']\n",
    "    key = cube_info['key']\n",
    "    is_list = cube_info.get('is_list', False)\n",
    "\n",
    "    if is_list:\n",
    "        # Get the cube from the list\n",
    "        cube = parent[key]\n",
    "    else:\n",
    "        # Get the cube from the dictionary\n",
    "        cube = parent[key]\n",
    "\n",
    "    # Check the cube's shape\n",
    "    if len(cube.shape) != 3:\n",
    "        raise ValueError(f\"Expected 3D array, got shape {cube.shape}\")\n",
    "\n",
    "    # Check if the cube might be transposed (common issue)\n",
    "    # We expect the cube to have shape (bands, height, width) or (height, width, bands)\n",
    "    if cube.shape[0] < cube.shape[1] and cube.shape[0] < cube.shape[2]:\n",
    "        # First dimension is smallest, likely spectral bands - (bands, height, width)\n",
    "        bands_dim = 0\n",
    "        height_dim = 1\n",
    "        width_dim = 2\n",
    "    elif cube.shape[2] < cube.shape[0] and cube.shape[2] < cube.shape[1]:\n",
    "        # Last dimension is smallest, likely spectral bands - (height, width, bands)\n",
    "        bands_dim = 2\n",
    "        height_dim = 0\n",
    "        width_dim = 1\n",
    "    else:\n",
    "        # Hard to tell, assume standard (bands, height, width)\n",
    "        bands_dim = 0\n",
    "        height_dim = 1\n",
    "        width_dim = 2\n",
    "\n",
    "    # Check mask dimensions match spatial dimensions of the cube\n",
    "    cube_height = cube.shape[height_dim]\n",
    "    cube_width = cube.shape[width_dim]\n",
    "\n",
    "    if mask.shape[0] != cube_height or mask.shape[1] != cube_width:\n",
    "        raise ValueError(f\"Mask shape {mask.shape} doesn't match cube spatial dimensions ({cube_height}, {cube_width})\")\n",
    "\n",
    "    # Create masked version\n",
    "    masked_cube = np.copy(cube)\n",
    "\n",
    "    # Apply mask (set non-masked values to NaN)\n",
    "    if bands_dim == 0:\n",
    "        # For each band, apply mask to the 2D image\n",
    "        for i in range(cube.shape[bands_dim]):\n",
    "            # Set values outside mask to NaN\n",
    "            masked_cube[i][mask == 0] = np.nan\n",
    "    elif bands_dim == 2:\n",
    "        # For (height, width, bands) format\n",
    "        for i in range(cube.shape[bands_dim]):\n",
    "            # Need to use advanced indexing for this format\n",
    "            mask_indices = np.where(mask == 0)\n",
    "            masked_cube[mask_indices[0], mask_indices[1], i] = np.nan\n",
    "\n",
    "    # Update the cube in the data structure\n",
    "    if is_list:\n",
    "        parent[key] = masked_cube\n",
    "    else:\n",
    "        parent[key] = masked_cube\n",
    "\n",
    "    return True\n",
    "\n",
    "data_path = r'C:\\Users\\meloy\\PycharmProjects\\Capstone\\Loader\\Data\\Kiwi Experiment\\pickles\\KiwiData_normalized_exposure_down.pkl'\n",
    "mask_path = r'C:\\Users\\meloy\\PycharmProjects\\Capstone\\Loader\\Data\\Kiwi Experiment\\pickles\\mask.npy'\n",
    "\n",
    "masked_file = create_masked_pickle(data_path, mask_path, output_path='../Data/Kiwi Experiment/pickles/masked_KiwiData_normalized_exposure_down.pkl')"
   ],
   "id": "bc99a51a294679d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "69f871a8370a959d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
