{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# File paths\n",
    "data_path = \"../Data/Lime Experiment/processed/masked_data_cutoff_30nm_exposure_max_power_min.pkl\"\n",
    "mask_path = \"../Data/Lime Experiment/processed/mask.npy\"\n",
    "output_dir = \"Lime\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "print(\"Loading hyperspectral data...\")\n",
    "with open(data_path, 'rb') as f:\n",
    "    data_dict = pickle.load(f)\n",
    "\n",
    "print(\"Data Summary:\")\n",
    "print(f\"Number of excitation wavelengths: {len(data_dict['excitation_wavelengths'])}\")\n",
    "print(f\"Excitation wavelengths: {data_dict['excitation_wavelengths']}\")\n",
    "\n",
    "# Load mask\n",
    "print(\"Loading mask...\")\n",
    "mask = np.load(mask_path)\n",
    "valid_pixels = np.sum(mask)\n",
    "total_pixels = mask.size\n",
    "print(f\"Mask loaded: {valid_pixels}/{total_pixels} valid pixels ({valid_pixels/total_pixels*100:.2f}%)\")\n",
    "\n",
    "# Create dataset\n",
    "from AutoencoderPipeline import MaskedHyperspectralDataset\n",
    "\n",
    "dataset = MaskedHyperspectralDataset(\n",
    "    data_dict=data_dict,\n",
    "    mask=mask,\n",
    "    normalize=True,\n",
    "    downscale_factor=1\n",
    ")\n",
    "\n",
    "# Get spatial dimensions\n",
    "height, width = dataset.get_spatial_dimensions()\n",
    "print(f\"Data dimensions after processing: {height}x{width}\")\n",
    "\n",
    "# Get all data\n",
    "all_data = dataset.get_all_data()"
   ],
   "id": "96e838f5b4fcc4b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from AutoencoderPipeline import HyperspectralCAEWithMasking\n",
    "\n",
    "model = HyperspectralCAEWithMasking(\n",
    "    excitations_data={ex: data.numpy() for ex, data in all_data.items()},\n",
    "    k1=20,\n",
    "    k3=20,\n",
    "    filter_size=5,\n",
    "    sparsity_target=0.1,\n",
    "    sparsity_weight=1.0,\n",
    "    dropout_rate=0.5\n",
    ")\n",
    "\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "model = model.to(device)"
   ],
   "id": "e48fd017e671642a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# IMPORTANT FIX: Make sure parameter names match\n",
    "# The error you encountered was because 'chunk_overlap' should be 'overlap'\n",
    "# Let's define a function to create spatial chunks with the correct parameter names\n",
    "\n",
    "def create_chunks(data_tensor, chunk_size=96, overlap=32):\n",
    "    \"\"\"\n",
    "    Split a large spatial hyperspectral tensor into overlapping chunks.\n",
    "\n",
    "    Args:\n",
    "        data_tensor: Input tensor of shape [height, width, emission_bands]\n",
    "        chunk_size: Size of each spatial chunk\n",
    "        overlap: Overlap between adjacent chunks\n",
    "\n",
    "    Returns:\n",
    "        List of chunk tensors and their positions\n",
    "    \"\"\"\n",
    "    # Determine input shape\n",
    "    if len(data_tensor.shape) == 4:  # [num_excitations, height, width, emission_bands]\n",
    "        height, width = data_tensor.shape[1], data_tensor.shape[2]\n",
    "    else:  # [height, width, emission_bands]\n",
    "        height, width = data_tensor.shape[0], data_tensor.shape[1]\n",
    "\n",
    "    # Calculate stride\n",
    "    stride = chunk_size - overlap\n",
    "\n",
    "    # Calculate number of chunks in each dimension\n",
    "    num_chunks_y = max(1, (height - overlap) // stride)\n",
    "    num_chunks_x = max(1, (width - overlap) // stride)\n",
    "\n",
    "    # Adjust to ensure we cover the entire image\n",
    "    if stride * num_chunks_y + overlap < height:\n",
    "        num_chunks_y += 1\n",
    "    if stride * num_chunks_x + overlap < width:\n",
    "        num_chunks_x += 1\n",
    "\n",
    "    # Create list to store chunks and their positions\n",
    "    chunks = []\n",
    "    positions = []\n",
    "\n",
    "    # Extract chunks\n",
    "    for i in range(num_chunks_y):\n",
    "        for j in range(num_chunks_x):\n",
    "            # Calculate start and end positions\n",
    "            y_start = i * stride\n",
    "            x_start = j * stride\n",
    "            y_end = min(y_start + chunk_size, height)\n",
    "            x_end = min(x_start + chunk_size, width)\n",
    "\n",
    "            # Handle edge cases by adjusting start positions\n",
    "            if y_end == height:\n",
    "                y_start = max(0, height - chunk_size)\n",
    "            if x_end == width:\n",
    "                x_start = max(0, width - chunk_size)\n",
    "\n",
    "            # Extract chunk based on input shape\n",
    "            if len(data_tensor.shape) == 4:  # [num_excitations, height, width, emission_bands]\n",
    "                chunk = data_tensor[:, y_start:y_end, x_start:x_end, :]\n",
    "            else:  # [height, width, emission_bands]\n",
    "                chunk = data_tensor[y_start:y_end, x_start:x_end, :]\n",
    "\n",
    "            # Add to lists\n",
    "            chunks.append(chunk)\n",
    "            positions.append((y_start, y_end, x_start, x_end))\n",
    "\n",
    "    print(f\"Created {len(chunks)} chunks of size up to {chunk_size}x{chunk_size} with {overlap} overlap\")\n",
    "    return chunks, positions"
   ],
   "id": "4a90d939feadda47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Now let's implement a custom training function that uses our fixed chunk creation\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    dataset,\n",
    "    num_epochs=30,\n",
    "    learning_rate=0.001,\n",
    "    chunk_size=96,\n",
    "    overlap=32,\n",
    "    device='cuda'\n",
    "):\n",
    "    # Create output directory for models\n",
    "    model_dir = os.path.join(output_dir, \"model\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Setup optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "\n",
    "    # Get data and mask\n",
    "    all_data = dataset.get_all_data()\n",
    "    mask_tensor = torch.tensor(dataset.processed_mask, dtype=torch.float32, device=device)\n",
    "\n",
    "    # Create chunks for mask\n",
    "    mask_expanded = dataset.processed_mask[..., np.newaxis]  # Add dummy dimension\n",
    "    mask_chunks, mask_positions = create_chunks(mask_expanded, chunk_size, overlap)\n",
    "    mask_chunks = [torch.tensor(chunk[..., 0], dtype=torch.float32).to(device) for chunk in mask_chunks]\n",
    "\n",
    "    # Create chunks for each excitation\n",
    "    print(\"Creating chunks for each excitation wavelength...\")\n",
    "    chunks_dict = {}\n",
    "    positions_dict = {}\n",
    "\n",
    "    for ex in all_data:\n",
    "        data_np = all_data[ex].numpy()\n",
    "        chunks, positions = create_chunks(data_np, chunk_size, overlap)\n",
    "        chunks_dict[ex] = chunks\n",
    "        positions_dict[ex] = positions\n",
    "\n",
    "    # Get number of chunks\n",
    "    num_chunks = len(next(iter(chunks_dict.values())))\n",
    "\n",
    "    # Create batches\n",
    "    batches = []\n",
    "    mask_batches = []\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        # Data batch\n",
    "        batch = {}\n",
    "        for ex in chunks_dict:\n",
    "            chunk = chunks_dict[ex][i]\n",
    "            batch[ex] = torch.tensor(chunk, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        batches.append(batch)\n",
    "\n",
    "        # Mask batch\n",
    "        mask_batches.append(mask_chunks[i].unsqueeze(0))  # Add batch dimension\n",
    "\n",
    "    # Training loop\n",
    "    print(f\"Training for {num_epochs} epochs with {len(batches)} batches...\")\n",
    "    train_losses = []\n",
    "    best_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    no_improvement_count = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        epoch_recon_loss = 0.0\n",
    "        epoch_sparsity_loss = 0.0\n",
    "\n",
    "        # Train on each batch\n",
    "        for i, (batch, mask_batch) in enumerate(zip(batches, mask_batches)):\n",
    "            # Forward pass\n",
    "            output = model(batch)\n",
    "\n",
    "            # Compute masked reconstruction loss\n",
    "            recon_loss = model.compute_masked_loss(\n",
    "                output_dict=output,\n",
    "                target_dict=batch,\n",
    "                spatial_mask=mask_batch\n",
    "            )\n",
    "\n",
    "            # Compute sparsity loss\n",
    "            encoded = model.encode(batch)\n",
    "            sparsity_loss = model.compute_sparsity_loss(encoded)\n",
    "\n",
    "            # Total loss\n",
    "            loss = recon_loss + model.sparsity_weight * sparsity_loss\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_recon_loss += recon_loss.item()\n",
    "            epoch_sparsity_loss += sparsity_loss.item()\n",
    "\n",
    "            # Print progress\n",
    "            if (i + 1) % 10 == 0 or i == len(batches) - 1:\n",
    "                print(f\"  Batch {i+1}/{len(batches)}\", end=\"\\r\")\n",
    "\n",
    "        # Record average loss\n",
    "        avg_loss = epoch_loss / len(batches)\n",
    "        avg_recon_loss = epoch_recon_loss / len(batches)\n",
    "        avg_sparsity_loss = epoch_sparsity_loss / len(batches)\n",
    "        train_losses.append(avg_loss)\n",
    "\n",
    "        # Update scheduler\n",
    "        scheduler.step(avg_loss)\n",
    "\n",
    "        # Report progress\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f} \"\n",
    "              f\"(Recon: {avg_recon_loss:.4f}, Sparsity: {avg_sparsity_loss:.4f}), \"\n",
    "              f\"Time: {epoch_time:.2f}s\")\n",
    "\n",
    "        # Check if this is the best epoch\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            best_epoch = epoch\n",
    "            no_improvement_count = 0\n",
    "\n",
    "            # Save best model\n",
    "            model_path = os.path.join(model_dir, \"best_model.pth\")\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"  New best model saved to {model_path}\")\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "            print(f\"  No improvement for {no_improvement_count} epochs (best: {best_loss:.4f} at epoch {best_epoch+1})\")\n",
    "\n",
    "            # Early stopping\n",
    "            if no_improvement_count >= 5:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "                break\n",
    "\n",
    "    # Save final model\n",
    "    model_path = os.path.join(model_dir, \"final_model.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Final model saved to {model_path}\")\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(os.path.join(model_dir, \"best_model.pth\")))\n",
    "\n",
    "    return model, train_losses\n",
    "\n",
    "# Run training\n",
    "model, losses = train_model(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    num_epochs=30,\n",
    "    learning_rate=0.001,\n",
    "    chunk_size=256,\n",
    "    overlap=128,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses, marker='o')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "plt.savefig(os.path.join(output_dir, \"training_loss.png\"))\n",
    "plt.close()"
   ],
   "id": "c127aa8cf9a56f5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def merge_chunk_reconstructions(chunks, positions, full_height, full_width):\n",
    "    \"\"\"\n",
    "    Merge the reconstructed chunks back into a full image.\n",
    "    \"\"\"\n",
    "    # Determine shape from the first chunk\n",
    "    first_chunk = chunks[0]\n",
    "\n",
    "    if len(first_chunk.shape) == 4:  # [batch, height, width, emission_bands]\n",
    "        batch_size, _, _, num_bands = first_chunk.shape\n",
    "        merged = torch.zeros((batch_size, full_height, full_width, num_bands),\n",
    "                         device=first_chunk.device)\n",
    "        weights = torch.zeros((batch_size, full_height, full_width, num_bands),\n",
    "                          device=first_chunk.device)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected chunk shape: {first_chunk.shape}\")\n",
    "\n",
    "    # Merge chunks\n",
    "    for chunk, (y_start, y_end, x_start, x_end) in zip(chunks, positions):\n",
    "        merged[:, y_start:y_end, x_start:x_end, :] += chunk\n",
    "        weights[:, y_start:y_end, x_start:x_end, :] += 1\n",
    "\n",
    "    # Average overlapping regions\n",
    "    merged = merged / torch.clamp(weights, min=1.0)\n",
    "\n",
    "    return merged\n",
    "\n",
    "def evaluate_model(model, dataset, chunk_size=96, overlap=32, device='cuda'):\n",
    "    \"\"\"\n",
    "    Evaluate the model by generating reconstructions and calculating metrics.\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    eval_dir = os.path.join(output_dir, \"evaluation\")\n",
    "    os.makedirs(eval_dir, exist_ok=True)\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Get data and mask\n",
    "    all_data = dataset.get_all_data()\n",
    "    mask = dataset.processed_mask\n",
    "\n",
    "    # Store results\n",
    "    results = {\n",
    "        'metrics': {},\n",
    "        'reconstructions': {}\n",
    "    }\n",
    "\n",
    "    print(\"Evaluating model...\")\n",
    "    with torch.no_grad():\n",
    "        overall_mse = 0.0\n",
    "        overall_mae = 0.0\n",
    "        num_excitations = 0\n",
    "\n",
    "        for ex in all_data:\n",
    "            data = all_data[ex]\n",
    "\n",
    "            # Create chunks for this excitation\n",
    "            chunks, positions = create_chunks(data.numpy(), chunk_size, overlap)\n",
    "\n",
    "            # Process chunks\n",
    "            reconstructed_chunks = []\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                # Convert to tensor and add batch dimension\n",
    "                chunk_tensor = torch.tensor(chunk, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "                # Create input dictionary for this excitation only\n",
    "                chunk_dict = {ex: chunk_tensor}\n",
    "\n",
    "                # Generate reconstruction\n",
    "                output = model(chunk_dict)\n",
    "\n",
    "                # Add to reconstructed chunks\n",
    "                if ex in output:\n",
    "                    reconstructed_chunks.append(output[ex])\n",
    "\n",
    "                # Print progress\n",
    "                if (i + 1) % 20 == 0 or i == len(chunks) - 1:\n",
    "                    print(f\"  Chunk {i+1}/{len(chunks)} for Ex={ex}nm\", end=\"\\r\")\n",
    "\n",
    "            # Skip if no valid reconstructions\n",
    "            if not reconstructed_chunks:\n",
    "                print(f\"Warning: No valid reconstructions for excitation {ex}\")\n",
    "                continue\n",
    "\n",
    "            # Merge chunks\n",
    "            full_reconstruction = merge_chunk_reconstructions(\n",
    "                reconstructed_chunks, positions, height, width\n",
    "            )\n",
    "\n",
    "            # Remove batch dimension\n",
    "            full_reconstruction = full_reconstruction[0]\n",
    "\n",
    "            # Store reconstruction\n",
    "            results['reconstructions'][ex] = full_reconstruction\n",
    "\n",
    "            # Apply mask for metric calculation\n",
    "            if mask is not None:\n",
    "                mask_tensor = torch.tensor(mask, dtype=torch.float32, device=device)\n",
    "                mask_expanded = mask_tensor.unsqueeze(-1).expand_as(data.to(device))\n",
    "\n",
    "                # Calculate metrics only on valid pixels\n",
    "                valid_pixels = mask_expanded.sum().item()\n",
    "\n",
    "                if valid_pixels > 0:\n",
    "                    # Calculate masked metrics\n",
    "                    masked_squared_error = ((full_reconstruction - data.to(device)) ** 2) * mask_expanded\n",
    "                    masked_abs_error = torch.abs(full_reconstruction - data.to(device)) * mask_expanded\n",
    "\n",
    "                    mse = masked_squared_error.sum().item() / valid_pixels\n",
    "                    mae = masked_abs_error.sum().item() / valid_pixels\n",
    "                    psnr = 10 * np.log10(1.0 / mse) if mse > 0 else float('inf')\n",
    "\n",
    "                    results['metrics'][ex] = {\n",
    "                        'mse': mse,\n",
    "                        'mae': mae,\n",
    "                        'psnr': psnr,\n",
    "                        'valid_pixels': valid_pixels\n",
    "                    }\n",
    "\n",
    "                    overall_mse += mse\n",
    "                    overall_mae += mae\n",
    "                    num_excitations += 1\n",
    "\n",
    "                    print(f\"Excitation {ex}nm - MSE: {mse:.4f}, PSNR: {psnr:.2f} dB\")\n",
    "            else:\n",
    "                # If no mask, use all pixels\n",
    "                mse = F.mse_loss(full_reconstruction, data.to(device)).item()\n",
    "                mae = torch.mean(torch.abs(full_reconstruction - data.to(device))).item()\n",
    "                psnr = 10 * np.log10(1.0 / mse) if mse > 0 else float('inf')\n",
    "\n",
    "                results['metrics'][ex] = {\n",
    "                    'mse': mse,\n",
    "                    'mae': mae,\n",
    "                    'psnr': psnr,\n",
    "                }\n",
    "\n",
    "                overall_mse += mse\n",
    "                overall_mae += mae\n",
    "                num_excitations += 1\n",
    "\n",
    "                print(f\"Excitation {ex}nm - MSE: {mse:.4f}, PSNR: {psnr:.2f} dB\")\n",
    "\n",
    "        # Calculate overall metrics\n",
    "        if num_excitations > 0:\n",
    "            results['metrics']['overall'] = {\n",
    "                'mse': overall_mse / num_excitations,\n",
    "                'mae': overall_mae / num_excitations,\n",
    "                'psnr': 10 * np.log10(1.0 / (overall_mse / num_excitations))\n",
    "            }\n",
    "\n",
    "            print(f\"Overall - MSE: {results['metrics']['overall']['mse']:.4f}, \"\n",
    "                  f\"PSNR: {results['metrics']['overall']['psnr']:.2f} dB\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run evaluation\n",
    "evaluation_results = evaluate_model(model, dataset, chunk_size=256, overlap=128, device=device)"
   ],
   "id": "4a78eb970c9d5cb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_rgb_visualization(data_dict, emission_wavelengths, mask=None, output_dir=None):\n",
    "    \"\"\"\n",
    "    Create RGB visualizations from hyperspectral data.\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    vis_dir = os.path.join(output_dir, \"visualizations\")\n",
    "    os.makedirs(vis_dir, exist_ok=True)\n",
    "\n",
    "    # Default RGB bands (adjust as needed)\n",
    "    r_band, g_band, b_band = 650, 550, 450\n",
    "\n",
    "    # Choose excitations to visualize (first 3 for example)\n",
    "    excitations = list(data_dict.keys())[:3]\n",
    "\n",
    "    # Create a figure for comparison\n",
    "    fig, axes = plt.subplots(1, len(excitations), figsize=(len(excitations) * 6, 5))\n",
    "    if len(excitations) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Store RGB images\n",
    "    rgb_dict = {}\n",
    "\n",
    "    # Find global min/max for consistent normalization\n",
    "    global_min, global_max = float('inf'), float('-inf')\n",
    "\n",
    "    for ex in excitations:\n",
    "        # Get data\n",
    "        if isinstance(data_dict[ex], torch.Tensor):\n",
    "            data = data_dict[ex].cpu().numpy()\n",
    "        else:\n",
    "            data = data_dict[ex]\n",
    "\n",
    "        # Get band indices (find closest to target wavelengths)\n",
    "        if ex in emission_wavelengths:\n",
    "            wavelengths = emission_wavelengths[ex]\n",
    "            r_idx = np.argmin(np.abs(np.array(wavelengths) - r_band))\n",
    "            g_idx = np.argmin(np.abs(np.array(wavelengths) - g_band))\n",
    "            b_idx = np.argmin(np.abs(np.array(wavelengths) - b_band))\n",
    "        else:\n",
    "            # Use indices proportionally if wavelengths not available\n",
    "            num_bands = data.shape[2]\n",
    "            r_idx = int(num_bands * 0.8)\n",
    "            g_idx = int(num_bands * 0.5)\n",
    "            b_idx = int(num_bands * 0.2)\n",
    "\n",
    "        # Get channel data\n",
    "        r_values = data[:, :, r_idx].flatten()\n",
    "        g_values = data[:, :, g_idx].flatten()\n",
    "        b_values = data[:, :, b_idx].flatten()\n",
    "\n",
    "        # Apply mask if provided\n",
    "        if mask is not None:\n",
    "            mask_flat = mask.flatten()\n",
    "            r_values = r_values[mask_flat > 0]\n",
    "            g_values = g_values[mask_flat > 0]\n",
    "            b_values = b_values[mask_flat > 0]\n",
    "\n",
    "        # Update global min/max\n",
    "        if not np.all(np.isnan(r_values)) and not np.all(np.isnan(g_values)) and not np.all(np.isnan(b_values)):\n",
    "            local_min = min(np.nanmin(r_values), np.nanmin(g_values), np.nanmin(b_values))\n",
    "            local_max = max(np.nanmax(r_values), np.nanmax(g_values), np.nanmax(b_values))\n",
    "            global_min = min(global_min, local_min)\n",
    "            global_max = max(global_max, local_max)\n",
    "\n",
    "    # Create RGB images\n",
    "    for i, ex in enumerate(excitations):\n",
    "        # Get data\n",
    "        if isinstance(data_dict[ex], torch.Tensor):\n",
    "            data = data_dict[ex].cpu().numpy()\n",
    "        else:\n",
    "            data = data_dict[ex]\n",
    "\n",
    "        # Get band indices\n",
    "        if ex in emission_wavelengths:\n",
    "            wavelengths = emission_wavelengths[ex]\n",
    "            r_idx = np.argmin(np.abs(np.array(wavelengths) - r_band))\n",
    "            g_idx = np.argmin(np.abs(np.array(wavelengths) - g_band))\n",
    "            b_idx = np.argmin(np.abs(np.array(wavelengths) - b_band))\n",
    "        else:\n",
    "            num_bands = data.shape[2]\n",
    "            r_idx = int(num_bands * 0.8)\n",
    "            g_idx = int(num_bands * 0.5)\n",
    "            b_idx = int(num_bands * 0.2)\n",
    "\n",
    "        # Create RGB image\n",
    "        rgb = np.stack([\n",
    "            data[:, :, r_idx],  # R channel\n",
    "            data[:, :, g_idx],  # G channel\n",
    "            data[:, :, b_idx]   # B channel\n",
    "        ], axis=2)\n",
    "\n",
    "        # Apply mask if provided\n",
    "        if mask is not None:\n",
    "            # Create mask with 3 channels\n",
    "            mask_rgb = np.stack([mask, mask, mask], axis=2)\n",
    "            rgb = rgb * mask_rgb\n",
    "\n",
    "        # Normalize to [0,1] range\n",
    "        rgb_normalized = np.clip((rgb - global_min) / (global_max - global_min + 1e-8), 0, 1)\n",
    "\n",
    "        # Replace NaNs with zeros\n",
    "        rgb_normalized = np.nan_to_num(rgb_normalized, nan=0.0)\n",
    "\n",
    "        # Store and plot\n",
    "        rgb_dict[ex] = rgb_normalized\n",
    "        axes[i].imshow(rgb_normalized)\n",
    "        axes[i].set_title(f'Excitation {ex}nm')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    # Save figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(vis_dir, \"rgb_comparison.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Save individual RGB images\n",
    "    for ex, rgb in rgb_dict.items():\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(rgb)\n",
    "        plt.title(f'Excitation {ex}nm')\n",
    "        plt.axis('off')\n",
    "        plt.savefig(os.path.join(vis_dir, f\"rgb_ex{ex}.png\"), dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    return rgb_dict\n",
    "\n",
    "# Create visualizations for original and reconstructed data\n",
    "original_rgb = create_rgb_visualization(\n",
    "    all_data,\n",
    "    dataset.emission_wavelengths,\n",
    "    mask=dataset.processed_mask,\n",
    "    output_dir=output_dir\n",
    ")\n",
    "\n",
    "reconstructions = evaluation_results['reconstructions']\n",
    "recon_rgb = create_rgb_visualization(\n",
    "    reconstructions,\n",
    "    dataset.emission_wavelengths,\n",
    "    mask=dataset.processed_mask,\n",
    "    output_dir=output_dir\n",
    ")\n",
    "\n",
    "# Create comparison for a specific excitation\n",
    "def create_comparison(original_data, reconstructed_data, excitation, emission_wavelengths=None, mask=None):\n",
    "    \"\"\"\n",
    "    Create comparison of original vs reconstructed data.\n",
    "    \"\"\"\n",
    "    vis_dir = os.path.join(output_dir, \"visualizations\")\n",
    "\n",
    "    # Convert tensors to numpy\n",
    "    if isinstance(original_data, torch.Tensor):\n",
    "        original_data = original_data.cpu().numpy()\n",
    "    if isinstance(reconstructed_data, torch.Tensor):\n",
    "        reconstructed_data = reconstructed_data.cpu().numpy()\n",
    "\n",
    "    # Create figure\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    # RGB comparison\n",
    "    num_bands = original_data.shape[2]\n",
    "\n",
    "    # Determine RGB indices\n",
    "    if emission_wavelengths is not None:\n",
    "        r_band, g_band, b_band = 650, 550, 450\n",
    "        r_idx = np.argmin(np.abs(np.array(emission_wavelengths) - r_band))\n",
    "        g_idx = np.argmin(np.abs(np.array(emission_wavelengths) - g_band))\n",
    "        b_idx = np.argmin(np.abs(np.array(emission_wavelengths) - b_band))\n",
    "    else:\n",
    "        r_idx = int(num_bands * 0.8)\n",
    "        g_idx = int(num_bands * 0.5)\n",
    "        b_idx = int(num_bands * 0.2)\n",
    "\n",
    "    # Create RGB images\n",
    "    rgb_original = np.stack([\n",
    "        original_data[:, :, r_idx],\n",
    "        original_data[:, :, g_idx],\n",
    "        original_data[:, :, b_idx]\n",
    "    ], axis=2)\n",
    "\n",
    "    rgb_recon = np.stack([\n",
    "        reconstructed_data[:, :, r_idx],\n",
    "        reconstructed_data[:, :, g_idx],\n",
    "        reconstructed_data[:, :, b_idx]\n",
    "    ], axis=2)\n",
    "\n",
    "    # Apply mask\n",
    "    if mask is not None:\n",
    "        mask_rgb = np.stack([mask, mask, mask], axis=2)\n",
    "        rgb_original = rgb_original * mask_rgb\n",
    "        rgb_recon = rgb_recon * mask_rgb\n",
    "\n",
    "    # Normalize\n",
    "    min_val = min(np.nanmin(rgb_original), np.nanmin(rgb_recon))\n",
    "    max_val = max(np.nanmax(rgb_original), np.nanmax(rgb_recon))\n",
    "\n",
    "    rgb_original_norm = np.clip((rgb_original - min_val) / (max_val - min_val + 1e-8), 0, 1)\n",
    "    rgb_recon_norm = np.clip((rgb_recon - min_val) / (max_val - min_val + 1e-8), 0, 1)\n",
    "\n",
    "    # Calculate difference\n",
    "    diff = np.abs(rgb_original_norm - rgb_recon_norm)\n",
    "    diff_enhanced = np.clip(diff * 5, 0, 1)  # Enhance for visibility\n",
    "\n",
    "    # Plot\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(rgb_original_norm)\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(rgb_recon_norm)\n",
    "    plt.title('Reconstructed')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(diff_enhanced)\n",
    "    plt.title('Difference (enhanced 5x)')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.suptitle(f'Reconstruction Comparison - Excitation {excitation}nm')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(vis_dir, f\"comparison_ex{excitation}.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    return {\n",
    "        'original': rgb_original_norm,\n",
    "        'reconstructed': rgb_recon_norm,\n",
    "        'difference': diff_enhanced\n",
    "    }\n",
    "\n",
    "# Create comparisons for first 3 excitations\n",
    "for ex in all_data.keys():\n",
    "    if ex in reconstructions:\n",
    "        create_comparison(\n",
    "            all_data[ex],\n",
    "            reconstructions[ex],\n",
    "            ex,\n",
    "            emission_wavelengths=dataset.emission_wavelengths.get(ex, None),\n",
    "            mask=dataset.processed_mask\n",
    "        )"
   ],
   "id": "9e6f82d0ae220831",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_encoded_features(model, data_dict, mask=None, chunk_size=64, overlap=8, device='cuda'):\n",
    "    \"\"\"\n",
    "    Extract encoded features from the model for all excitations.\n",
    "    \"\"\"\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Get dimensions from first excitation\n",
    "    first_ex = next(iter(data_dict.keys()))\n",
    "    height, width = data_dict[first_ex].shape[:2]\n",
    "\n",
    "    # Store features and shapes\n",
    "    encoded_features = {}\n",
    "    spatial_shapes = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for ex, data in data_dict.items():\n",
    "            print(f\"Extracting features for excitation {ex}...\")\n",
    "\n",
    "            # Create chunks\n",
    "            chunks, positions = create_chunks(data.numpy(), chunk_size, overlap)\n",
    "\n",
    "            # Initialize feature maps\n",
    "            all_features = None\n",
    "\n",
    "            # Process chunks\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                # Convert to tensor and add batch dimension\n",
    "                chunk_tensor = torch.tensor(chunk, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "                # Create input dictionary for this excitation only\n",
    "                chunk_dict = {ex: chunk_tensor}\n",
    "\n",
    "                # Extract encoded representation\n",
    "                encoded = model.encode(chunk_dict)\n",
    "                features = encoded.cpu().numpy()[0]  # Remove batch dimension\n",
    "\n",
    "                # Initialize feature array on first chunk\n",
    "                if all_features is None:\n",
    "                    all_features = []\n",
    "                    for feat_idx in range(features.shape[0]):\n",
    "                        all_features.append(np.zeros((height, width)))\n",
    "\n",
    "                # Store features in appropriate positions\n",
    "                y_start, y_end, x_start, x_end = positions[i]\n",
    "\n",
    "                # Remove emission dimension (which is 1)\n",
    "                spatial_features = features.squeeze(1)\n",
    "\n",
    "                # Store features\n",
    "                for feat_idx in range(spatial_features.shape[0]):\n",
    "                    feature_chunk = spatial_features[feat_idx]\n",
    "                    current = all_features[feat_idx][y_start:y_end, x_start:x_end]\n",
    "\n",
    "                    # Handle overlapping regions\n",
    "                    overlap_mask = current != 0\n",
    "\n",
    "                    # Set new areas directly\n",
    "                    new_areas = ~overlap_mask\n",
    "                    current[new_areas] = feature_chunk[new_areas]\n",
    "\n",
    "                    # Average overlapping areas\n",
    "                    if np.any(overlap_mask):\n",
    "                        current[overlap_mask] = (current[overlap_mask] + feature_chunk[overlap_mask]) / 2\n",
    "\n",
    "                    all_features[feat_idx][y_start:y_end, x_start:x_end] = current\n",
    "\n",
    "                # Print progress\n",
    "                if (i + 1) % 20 == 0 or i == len(chunks) - 1:\n",
    "                    print(f\"  Processed {i+1}/{len(chunks)} chunks\", end=\"\\r\")\n",
    "\n",
    "            # Stack features\n",
    "            features_array = np.stack(all_features)\n",
    "\n",
    "            # Store results\n",
    "            encoded_features[ex] = features_array\n",
    "            spatial_shapes[ex] = (height, width)\n",
    "\n",
    "            print(f\"\\nExtracted {features_array.shape[0]} features for excitation {ex}\")\n",
    "\n",
    "    return encoded_features, spatial_shapes\n",
    "\n",
    "def run_kmeans_clustering(features, n_clusters=10, random_state=42):\n",
    "    \"\"\"\n",
    "    Run K-means clustering on the extracted features.\n",
    "    \"\"\"\n",
    "    print(f\"Running K-means clustering with {n_clusters} clusters...\")\n",
    "\n",
    "    # Get shape of featuresa\n",
    "    n_features, height, width = features.shape\n",
    "\n",
    "    # Reshape to [pixels, features]\n",
    "    features_reshaped = features.reshape(n_features, -1).T\n",
    "    print(f\"Feature matrix shape: {features_reshaped.shape}\")\n",
    "\n",
    "    # Apply PCA if dimensionality is very high\n",
    "    # if n_features > 50:\n",
    "    #     from sklearn.decomposition import PCA\n",
    "    #     print(\"Applying PCA to reduce dimensions...\")\n",
    "    #     pca = PCA(n_components=min(50, n_features-1))\n",
    "    #     features_reshaped = pca.fit_transform(features_reshaped)\n",
    "    #     print(f\"Reduced features shape: {features_reshaped.shape}\")\n",
    "\n",
    "    # Use MiniBatchKMeans for better performance\n",
    "    kmeans = MiniBatchKMeans(\n",
    "        n_clusters=n_clusters,\n",
    "        batch_size=1000,\n",
    "        max_iter=300,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    print(\"Fitting K-means model...\")\n",
    "    labels = kmeans.fit_predict(features_reshaped)\n",
    "\n",
    "    # Reshape labels back to spatial dimensions\n",
    "    cluster_map = labels.reshape(height, width)\n",
    "    print(f\"Clustering complete. Found {len(np.unique(labels))} unique clusters\")\n",
    "\n",
    "    return cluster_map, kmeans"
   ],
   "id": "a2a69cd70dcc021c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cluster_dir = os.path.join(output_dir, \"clustering\")\n",
    "os.makedirs(cluster_dir, exist_ok=True)\n",
    "\n",
    "print(\"Starting feature extraction...\")\n",
    "encoded_features, spatial_shapes = extract_encoded_features(\n",
    "    model=model,\n",
    "    data_dict=all_data,\n",
    "    mask=dataset.processed_mask,\n",
    "    chunk_size=256,\n",
    "    overlap=128,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Choose excitation for clustering (use first excitation by default)\n",
    "excitation_to_use = list(encoded_features.keys())[0]\n",
    "print(f\"Using excitation {excitation_to_use} for clustering\")\n",
    "\n",
    "# Run clustering\n",
    "cluster_labels, clustering_model = run_kmeans_clustering(\n",
    "    features=encoded_features[excitation_to_use],\n",
    "    n_clusters=5\n",
    ")\n",
    "\n",
    "# Apply mask to cluster labels\n",
    "if dataset.processed_mask is not None:\n",
    "    cluster_labels[dataset.processed_mask == 0] = -1\n",
    "\n",
    "# Visualize cluster map\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cluster_labels, cmap='tab10', interpolation='nearest')\n",
    "plt.colorbar(label='Cluster ID')\n",
    "plt.title(f'Pixel-wise Clustering (Ex={excitation_to_use}nm, K=10)')\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(cluster_dir, f\"cluster_map_ex{excitation_to_use}.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Save cluster labels\n",
    "np.save(os.path.join(cluster_dir, f\"cluster_labels_ex{excitation_to_use}.npy\"), cluster_labels)\n",
    "\n",
    "# Visualize cluster overlay on RGB image\n",
    "def create_cluster_overlay(cluster_labels, rgb_image, alpha=0.5, output_path=None):\n",
    "    \"\"\"\n",
    "    Create overlay of cluster labels on RGB image.\n",
    "    \"\"\"\n",
    "    # Get unique clusters (excluding -1 which is for masked areas)\n",
    "    unique_clusters = sorted([c for c in np.unique(cluster_labels) if c >= 0])\n",
    "    n_clusters = len(unique_clusters)\n",
    "\n",
    "    # Create a colormap for clusters - FIX FOR DEPRECATION WARNING\n",
    "    # Replace plt.cm.get_cmap with plt.colormaps\n",
    "    cluster_cmap = plt.colormaps['tab10'].resampled(max(10, n_clusters))\n",
    "\n",
    "    # Create empty overlay (RGBA)\n",
    "    overlay = np.zeros((*cluster_labels.shape, 4))\n",
    "\n",
    "    # Fill with cluster colors\n",
    "    for i, cluster_id in enumerate(unique_clusters):\n",
    "        mask_cluster = cluster_labels == cluster_id\n",
    "        color = cluster_cmap(i % 10)\n",
    "        overlay[mask_cluster] = (*color[:3], alpha)\n",
    "\n",
    "    # Set transparent for masked areas\n",
    "    mask = cluster_labels < 0\n",
    "    overlay[mask] = (0, 0, 0, 0)\n",
    "\n",
    "    # Create figure\n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "    # Show RGB image\n",
    "    plt.imshow(rgb_image)\n",
    "\n",
    "    # Add overlay\n",
    "    plt.imshow(overlay, alpha=overlay[..., 3])\n",
    "\n",
    "    # Add colorbar - FIX FOR COLORBAR ERROR\n",
    "    # Get the current axes to pass to colorbar\n",
    "    ax = plt.gca()\n",
    "    sm = plt.cm.ScalarMappable(cmap=cluster_cmap)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax, ticks=np.arange(n_clusters))\n",
    "    cbar.set_ticklabels([f'Cluster {c}' for c in unique_clusters])\n",
    "\n",
    "    plt.title('Cluster Overlay on RGB Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Save figure\n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    return overlay\n",
    "# Create cluster overlay\n",
    "if excitation_to_use in original_rgb:\n",
    "    overlay = create_cluster_overlay(\n",
    "        cluster_labels=cluster_labels,\n",
    "        rgb_image=original_rgb[excitation_to_use],\n",
    "        alpha=0.5,\n",
    "        output_path=os.path.join(cluster_dir, \"cluster_overlay.png\")\n",
    "    )"
   ],
   "id": "730f2ded87af6e5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def analyze_cluster_profiles(cluster_labels, all_data, emission_wavelengths):\n",
    "    \"\"\"\n",
    "    Analyze spectral profiles for each cluster.\n",
    "    \"\"\"\n",
    "    cluster_dir = os.path.join(output_dir, \"clustering\")\n",
    "\n",
    "    # Get unique clusters (excluding -1 which is for masked areas)\n",
    "    unique_clusters = sorted([c for c in np.unique(cluster_labels) if c >= 0])\n",
    "    print(f\"Analyzing profiles for {len(unique_clusters)} clusters\")\n",
    "\n",
    "    # Create figure for profiles\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Store stats for each cluster\n",
    "    cluster_stats = {}\n",
    "\n",
    "    # Process each excitation wavelength\n",
    "    for i, ex in enumerate(all_data.keys()):\n",
    "        # Get data for this excitation\n",
    "        if isinstance(all_data[ex], torch.Tensor):\n",
    "            data = all_data[ex].cpu().numpy()\n",
    "        else:\n",
    "            data = all_data[ex]\n",
    "\n",
    "        # Get emission wavelengths\n",
    "        if ex in emission_wavelengths:\n",
    "            wavelengths = emission_wavelengths[ex]\n",
    "        else:\n",
    "            wavelengths = np.arange(data.shape[2])\n",
    "\n",
    "        # Use different markers for each excitation\n",
    "        markers = ['o', 's', '^', 'D', 'v']\n",
    "        marker = markers[i % len(markers)]\n",
    "\n",
    "        # Process each cluster\n",
    "        for cluster_id in unique_clusters:\n",
    "            # Create mask for this cluster\n",
    "            mask = cluster_labels == cluster_id\n",
    "\n",
    "            # Skip if no pixels in this cluster\n",
    "            if not np.any(mask):\n",
    "                continue\n",
    "\n",
    "            # Get data for this cluster\n",
    "            cluster_data = data[mask]\n",
    "\n",
    "            # Calculate mean spectrum (ignore NaNs)\n",
    "            mean_spectrum = np.nanmean(cluster_data, axis=0)\n",
    "\n",
    "            # Calculate standard deviation\n",
    "            std_spectrum = np.nanstd(cluster_data, axis=0)\n",
    "\n",
    "            # Store statistics\n",
    "            if cluster_id not in cluster_stats:\n",
    "                cluster_stats[cluster_id] = {}\n",
    "\n",
    "            cluster_stats[cluster_id][ex] = {\n",
    "                'mean': mean_spectrum,\n",
    "                'std': std_spectrum,\n",
    "                'count': np.sum(mask)\n",
    "            }\n",
    "\n",
    "            # Plot mean spectrum\n",
    "            if i == 0:  # Only add to legend for first excitation\n",
    "                plt.plot(wavelengths, mean_spectrum, marker=marker,\n",
    "                         label=f\"Cluster {cluster_id}\",\n",
    "                         color=plt.cm.tab10(cluster_id % 10))\n",
    "            else:\n",
    "                plt.plot(wavelengths, mean_spectrum, marker=marker,\n",
    "                         color=plt.cm.tab10(cluster_id % 10))\n",
    "\n",
    "    # Finish plot\n",
    "    plt.xlabel('Emission Wavelength (nm)' if len(emission_wavelengths) > 0 else 'Emission Band Index')\n",
    "    plt.ylabel('Intensity')\n",
    "    plt.title('Spectral Profiles by Cluster')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(os.path.join(cluster_dir, \"cluster_profiles.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Create bar chart of cluster sizes\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Count pixels in each cluster\n",
    "    cluster_sizes = [np.sum(cluster_labels == c) for c in unique_clusters]\n",
    "\n",
    "    # Create bar chart\n",
    "    plt.bar(\n",
    "        [f\"Cluster {c}\" for c in unique_clusters],\n",
    "        cluster_sizes,\n",
    "        color=[plt.cm.tab10(c % 10) for c in unique_clusters]\n",
    "    )\n",
    "\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel('Number of Pixels')\n",
    "    plt.title('Cluster Sizes')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(os.path.join(cluster_dir, \"cluster_sizes.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    return cluster_stats\n",
    "\n",
    "# Analyze cluster profiles\n",
    "cluster_stats = analyze_cluster_profiles(\n",
    "    cluster_labels=cluster_labels,\n",
    "    all_data=all_data,\n",
    "    emission_wavelengths=dataset.emission_wavelengths\n",
    ")\n",
    "\n",
    "print(\"Pipeline complete! All results saved to\", output_dir)"
   ],
   "id": "5dff802643ab32fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# APPROACH 2: FEATURE CONCATENATION (preserves more information but increases dimensions)\n",
    "print(f\"Concatenating features from all {len(encoded_features)} excitations...\")\n",
    "all_excitation_features = np.concatenate([encoded_features[ex] for ex in encoded_features.keys()], axis=0)\n",
    "print(f\"Concatenated feature shape: {all_excitation_features.shape}\")\n",
    "\n",
    "# Run clustering on concatenated features\n",
    "cluster_labels, clustering_model = run_kmeans_clustering(\n",
    "    features=all_excitation_features,\n",
    "    n_clusters=10\n",
    ")"
   ],
   "id": "6feb82ed666f610f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "18f28fef54ff9840",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cluster_stats = analyze_cluster_profiles(\n",
    "    cluster_labels=cluster_labels,\n",
    "    all_data=all_data,\n",
    "    emission_wavelengths=dataset.emission_wavelengths\n",
    ")"
   ],
   "id": "115882b394262f23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract features\n",
    "cluster_dir = os.path.join(output_dir, \"clustering\")\n",
    "os.makedirs(cluster_dir, exist_ok=True)\n",
    "\n",
    "print(\"Starting feature extraction...\")\n",
    "encoded_features, spatial_shapes = extract_encoded_features(\n",
    "    model=model,\n",
    "    data_dict=all_data,\n",
    "    mask=dataset.processed_mask,\n",
    "    chunk_size=256,\n",
    "    overlap=128,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# APPROACH 1: FEATURE AVERAGING (combines excitations while keeping the same dimensionality)\n",
    "print(f\"Combining features from all {len(encoded_features)} excitations...\")\n",
    "all_excitation_features = np.stack([encoded_features[ex] for ex in encoded_features.keys()])\n",
    "combined_features = np.mean(all_excitation_features, axis=0)\n",
    "print(f\"Combined feature shape: {combined_features.shape}\")\n",
    "\n",
    "# Run clustering on combined features from ALL excitations\n",
    "print(\"Running clustering on features from all excitations...\")\n",
    "cluster_labels, clustering_model = run_kmeans_clustering(\n",
    "    features=combined_features,\n",
    "    n_clusters=10\n",
    ")\n",
    "\n",
    "# Apply mask to cluster labels\n",
    "if dataset.processed_mask is not None:\n",
    "    cluster_labels[dataset.processed_mask == 0] = -1\n",
    "\n",
    "# Visualize cluster map\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cluster_labels, cmap='tab10', interpolation='nearest')\n",
    "plt.colorbar(label='Cluster ID')\n",
    "plt.title(f'Pixel-wise Clustering (ALL Excitations, K=10)')\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(cluster_dir, \"cluster_map_all_excitations.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Save cluster labels\n",
    "np.save(os.path.join(cluster_dir, \"cluster_labels_all_excitations.npy\"), cluster_labels)\n",
    "\n",
    "# Create cluster overlay (choose one excitation for background visualization only)\n",
    "excitation_for_viz = list(original_rgb.keys())[0]\n",
    "overlay = create_cluster_overlay(\n",
    "    cluster_labels=cluster_labels,\n",
    "    rgb_image=original_rgb[excitation_for_viz],\n",
    "    alpha=0.5,\n",
    "    output_path=os.path.join(cluster_dir, \"cluster_overlay_all_excitations.png\")\n",
    ")"
   ],
   "id": "7d8495ba99e61a7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract features\n",
    "cluster_dir = os.path.join(output_dir, \"clustering\")\n",
    "os.makedirs(cluster_dir, exist_ok=True)\n",
    "\n",
    "print(\"Starting feature extraction...\")\n",
    "encoded_features, spatial_shapes = extract_encoded_features(\n",
    "    model=model,\n",
    "    data_dict=all_data,\n",
    "    mask=dataset.processed_mask,\n",
    "    chunk_size=256,\n",
    "    overlap=128,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# APPROACH 2: FEATURE CONCATENATION (preserves more information but increases dimensions)\n",
    "print(f\"Concatenating features from all {len(encoded_features)} excitations...\")\n",
    "all_excitation_features = np.concatenate([encoded_features[ex] for ex in encoded_features.keys()], axis=0)\n",
    "print(f\"Concatenated feature shape: {all_excitation_features.shape}\")\n",
    "\n",
    "# Run clustering on concatenated features\n",
    "cluster_labels, clustering_model = run_kmeans_clustering(\n",
    "    features=all_excitation_features,\n",
    "    n_clusters=10\n",
    ")\n",
    "# Apply mask to cluster labels\n",
    "if dataset.processed_mask is not None:\n",
    "    cluster_labels[dataset.processed_mask == 0] = -1\n",
    "\n",
    "# Visualize cluster map\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cluster_labels, cmap='tab10', interpolation='nearest')\n",
    "plt.colorbar(label='Cluster ID')\n",
    "plt.title(f'Pixel-wise Clustering (ALL Excitations, K=10)')\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(cluster_dir, \"cluster_map_all_excitations_concat.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Save cluster labels\n",
    "np.save(os.path.join(cluster_dir, \"cluster_map_all_excitations_concat.npy\"), cluster_labels)\n",
    "\n",
    "# Create cluster overlay (choose one excitation for background visualization only)\n",
    "excitation_for_viz = list(original_rgb.keys())[0]\n",
    "overlay = create_cluster_overlay(\n",
    "    cluster_labels=cluster_labels,\n",
    "    rgb_image=original_rgb[excitation_for_viz],\n",
    "    alpha=0.5,\n",
    "    output_path=os.path.join(cluster_dir, \"cluster_map_all_excitations_concat.png\")\n",
    ")"
   ],
   "id": "64fc8e726a856d28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Add after clustering in both approaches to calculate validation metrics\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "def evaluate_clustering(features, cluster_labels, mask=None):\n",
    "    \"\"\"Calculate clustering quality metrics.\"\"\"\n",
    "    # Reshape features for metric calculation\n",
    "    if len(features.shape) == 3:  # [n_features, height, width]\n",
    "        n_features, height, width = features.shape\n",
    "        features_reshaped = features.reshape(n_features, -1).T\n",
    "    else:\n",
    "        features_reshaped = features\n",
    "\n",
    "    # Reshape labels\n",
    "    if len(cluster_labels.shape) == 2:  # [height, width]\n",
    "        labels_flat = cluster_labels.flatten()\n",
    "    else:\n",
    "        labels_flat = cluster_labels\n",
    "\n",
    "    # Get valid indices (exclude masked areas)\n",
    "    valid_indices = labels_flat >= 0\n",
    "    valid_features = features_reshaped[valid_indices]\n",
    "    valid_labels = labels_flat[valid_indices]\n",
    "\n",
    "    # Skip if only one cluster\n",
    "    if len(np.unique(valid_labels)) <= 1:\n",
    "        return {\"error\": \"Not enough clusters for evaluation\"}\n",
    "\n",
    "    # Calculate standard metrics\n",
    "    metrics = {\n",
    "        \"silhouette_score\": silhouette_score(valid_features, valid_labels),\n",
    "        \"davies_bouldin_score\": davies_bouldin_score(valid_features, valid_labels),\n",
    "        \"calinski_harabasz_score\": calinski_harabasz_score(valid_features, valid_labels),\n",
    "    }\n",
    "\n",
    "    # Calculate spatial coherence (how many neighbors have the same label)\n",
    "    if len(cluster_labels.shape) == 2:\n",
    "        spatial_coherence = 0\n",
    "        for cluster_id in np.unique(cluster_labels[cluster_labels >= 0]):\n",
    "            # Create binary mask for this cluster\n",
    "            cluster_mask = (cluster_labels == cluster_id).astype(np.int32)\n",
    "\n",
    "            # Count neighbors with same label (3x3 kernel minus center)\n",
    "            kernel = np.ones((3, 3), dtype=np.int32)\n",
    "            kernel[1, 1] = 0  # Remove center\n",
    "            neighbor_count = ndimage.convolve(cluster_mask, kernel, mode='constant', cval=0)\n",
    "\n",
    "            # Calculate average neighbor ratio (max is 8 neighbors)\n",
    "            neighbor_ratio = np.mean(neighbor_count[cluster_labels == cluster_id] / 8.0)\n",
    "            spatial_coherence += neighbor_ratio\n",
    "\n",
    "        # Average across clusters\n",
    "        metrics[\"spatial_coherence\"] = spatial_coherence / len(np.unique(cluster_labels[cluster_labels >= 0]))\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Calculate metrics for concatenation approach\n",
    "concat_metrics = evaluate_clustering(all_excitation_features, cluster_labels, dataset.processed_mask)\n",
    "print(\"Metrics for feature concatenation approach:\")\n",
    "for metric, value in concat_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "# Save metrics\n",
    "with open(os.path.join(cluster_dir, \"concat_metrics.json\"), \"w\") as f:\n",
    "    import json\n",
    "    json.dump(concat_metrics, f, indent=2)\n",
    "\n",
    "# Create comparison visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "metrics_to_plot = [\"silhouette_score\", \"spatial_coherence\"]\n",
    "colors = ['#3498db', '#2ecc71']\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    if metric in concat_metrics:\n",
    "        plt.bar(i, concat_metrics[metric], color=colors[i])\n",
    "plt.xticks(range(len(metrics_to_plot)), metrics_to_plot)\n",
    "plt.ylabel('Score')\n",
    "plt.title('Clustering Quality Metrics')\n",
    "plt.savefig(os.path.join(cluster_dir, \"clustering_metrics.png\"), dpi=300)\n",
    "# plt.close()"
   ],
   "id": "b54db174f11a0dc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from scipy import ndimage\n",
    "import pandas as pd\n",
    "\n",
    "# Create a dedicated folder for comparison visualizations\n",
    "comparison_dir = os.path.join(output_dir, \"clustering_comparison\")\n",
    "os.makedirs(comparison_dir, exist_ok=True)\n",
    "\n",
    "# Get the actual available excitation wavelengths from your data\n",
    "# Instead of hardcoding specific values\n",
    "available_excitations = list(encoded_features.keys())\n",
    "print(f\"Available excitations: {available_excitations}\")\n",
    "\n",
    "# Select a subset of excitations to compare (choose 4 if possible)\n",
    "excitations_to_compare = []\n",
    "if len(available_excitations) <= 4:\n",
    "    excitations_to_compare = available_excitations\n",
    "else:\n",
    "    # Try to select evenly spaced excitations\n",
    "    step = len(available_excitations) // 4\n",
    "    excitations_to_compare = [available_excitations[i*step] for i in range(4)]\n",
    "\n",
    "print(f\"Using excitations for comparison: {excitations_to_compare}\")\n",
    "\n",
    "# Function to evaluate clustering quality\n",
    "def evaluate_clustering(features, cluster_labels, mask=None):\n",
    "    \"\"\"Calculate clustering quality metrics.\"\"\"\n",
    "    # Reshape features for metric calculation\n",
    "    if len(features.shape) == 3:  # [n_features, height, width]\n",
    "        n_features, height, width = features.shape\n",
    "        features_reshaped = features.reshape(n_features, -1).T\n",
    "    else:\n",
    "        features_reshaped = features\n",
    "\n",
    "    # Reshape labels\n",
    "    if len(cluster_labels.shape) == 2:  # [height, width]\n",
    "        labels_flat = cluster_labels.flatten()\n",
    "    else:\n",
    "        labels_flat = cluster_labels\n",
    "\n",
    "    # Get valid indices (exclude masked areas)\n",
    "    valid_indices = labels_flat >= 0\n",
    "    features_reshaped = features_reshaped[valid_indices]\n",
    "    labels_flat = labels_flat[valid_indices]\n",
    "\n",
    "    # Skip if only one cluster\n",
    "    if len(np.unique(labels_flat)) <= 1:\n",
    "        return {\"error\": \"Not enough clusters for evaluation\"}\n",
    "\n",
    "    # Calculate standard metrics\n",
    "    metrics = {}\n",
    "    try:\n",
    "        metrics[\"silhouette_score\"] = silhouette_score(features_reshaped, labels_flat)\n",
    "        metrics[\"davies_bouldin_score\"] = davies_bouldin_score(features_reshaped, labels_flat)\n",
    "        metrics[\"calinski_harabasz_score\"] = calinski_harabasz_score(features_reshaped, labels_flat)\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating metrics: {str(e)}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "    # Calculate spatial coherence\n",
    "    if len(cluster_labels.shape) == 2:\n",
    "        spatial_coherence = 0\n",
    "        for cluster_id in np.unique(cluster_labels[cluster_labels >= 0]):\n",
    "            # Create binary mask for this cluster\n",
    "            cluster_mask = (cluster_labels == cluster_id).astype(np.int32)\n",
    "\n",
    "            # Count neighbors with same label (3x3 kernel minus center)\n",
    "            kernel = np.ones((3, 3), dtype=np.int32)\n",
    "            kernel[1, 1] = 0  # Remove center\n",
    "            neighbor_count = ndimage.convolve(cluster_mask, kernel, mode='constant', cval=0)\n",
    "\n",
    "            # Calculate average neighbor ratio (max is 8 neighbors)\n",
    "            neighbor_ratio = np.mean(neighbor_count[cluster_labels == cluster_id] / 8.0)\n",
    "            spatial_coherence += neighbor_ratio\n",
    "\n",
    "        # Average across clusters\n",
    "        metrics[\"spatial_coherence\"] = spatial_coherence / len(np.unique(cluster_labels[cluster_labels >= 0]))\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Store all clustering results and metrics\n",
    "all_results = {}\n",
    "\n",
    "# First, ensure we have the combined clustering result\n",
    "print(\"1. Processing combined 4D clustering result...\")\n",
    "all_results['combined'] = {\n",
    "    'features': all_excitation_features,\n",
    "    'labels': cluster_labels,\n",
    "    'metrics': evaluate_clustering(all_excitation_features, cluster_labels, dataset.processed_mask),\n",
    "    'name': 'Combined 4D'\n",
    "}\n",
    "\n",
    "# Save the combined overlay separately\n",
    "excitation_for_viz = list(original_rgb.keys())[0]\n",
    "plt.figure(figsize=(10, 8))\n",
    "overlay = create_cluster_overlay(\n",
    "    cluster_labels=cluster_labels,\n",
    "    rgb_image=original_rgb[excitation_for_viz],\n",
    "    alpha=0.5,\n",
    "    output_path=os.path.join(comparison_dir, \"overlay_combined.png\")\n",
    ")\n",
    "plt.close()\n",
    "\n",
    "# 2. Run clustering on individual excitations\n",
    "print(\"2. Processing individual excitation wavelengths...\")\n",
    "for ex in excitations_to_compare:\n",
    "    print(f\"  Processing excitation {ex}...\")\n",
    "\n",
    "    # Run clustering on this excitation's features\n",
    "    ex_cluster_labels, _ = run_kmeans_clustering(\n",
    "        features=encoded_features[ex],\n",
    "        n_clusters=10  # Use same number as for combined\n",
    "    )\n",
    "\n",
    "    # Apply mask\n",
    "    if dataset.processed_mask is not None:\n",
    "        ex_cluster_labels[dataset.processed_mask == 0] = -1\n",
    "\n",
    "    # Calculate metrics\n",
    "    ex_metrics = evaluate_clustering(encoded_features[ex], ex_cluster_labels)\n",
    "\n",
    "    # Store results\n",
    "    all_results[ex] = {\n",
    "        'features': encoded_features[ex],\n",
    "        'labels': ex_cluster_labels,\n",
    "        'metrics': ex_metrics,\n",
    "        'name': f'Excitation {ex}'\n",
    "    }\n",
    "\n",
    "    # Save individual cluster map\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(ex_cluster_labels, cmap='tab10', interpolation='nearest')\n",
    "    plt.colorbar(label='Cluster ID')\n",
    "    plt.title(f'Clustering on Excitation {ex}')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(comparison_dir, f\"cluster_map_ex{ex}.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Save individual overlay\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    overlay = create_cluster_overlay(\n",
    "        cluster_labels=ex_cluster_labels,\n",
    "        rgb_image=original_rgb[excitation_for_viz], # Use same image for consistency\n",
    "        alpha=0.5,\n",
    "        output_path=os.path.join(comparison_dir, f\"overlay_ex{ex}.png\")\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "# 3. Create side-by-side comparison of all overlays (this is your main poster visual)\n",
    "print(\"3. Creating side-by-side comparison visualization...\")\n",
    "n_methods = len(all_results)\n",
    "fig, axes = plt.subplots(1, n_methods, figsize=(n_methods*5, 5))\n",
    "\n",
    "for i, (key, result) in enumerate(all_results.items()):\n",
    "    ax = axes[i] if n_methods > 1 else axes\n",
    "    # Create cluster overlay\n",
    "    overlay = create_cluster_overlay(\n",
    "        cluster_labels=result['labels'],\n",
    "        rgb_image=original_rgb[excitation_for_viz],\n",
    "        alpha=0.5\n",
    "    )\n",
    "    # Display the overlay\n",
    "    ax.imshow(overlay)\n",
    "    ax.set_title(result['name'])\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(comparison_dir, \"all_overlays_comparison.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 4. Create metrics comparison table and visualization\n",
    "print(\"4. Creating metrics comparison...\")\n",
    "metrics_table = []\n",
    "for key, result in all_results.items():\n",
    "    row = {'Method': result['name']}\n",
    "    row.update(result['metrics'])\n",
    "    metrics_table.append(row)\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_table)\n",
    "\n",
    "# Save metrics to CSV\n",
    "metrics_df.to_csv(os.path.join(comparison_dir, \"clustering_metrics.csv\"), index=False)\n",
    "\n",
    "# Create normalized metrics plot (perfect for poster)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Define metrics and their interpretation\n",
    "metrics_info = {\n",
    "    \"silhouette_score\": {\"name\": \"Silhouette Score\", \"higher_better\": True, \"color\": \"#3498db\"},\n",
    "    \"davies_bouldin_score\": {\"name\": \"Davies-Bouldin Index\", \"higher_better\": False, \"color\": \"#e74c3c\"},\n",
    "    \"spatial_coherence\": {\"name\": \"Spatial Coherence\", \"higher_better\": True, \"color\": \"#2ecc71\"}\n",
    "}\n",
    "\n",
    "# Set up for grouped bar chart\n",
    "methods = list(all_results.keys())\n",
    "x = np.arange(len(methods))\n",
    "width = 0.25\n",
    "multiplier = 0\n",
    "\n",
    "# Create normalized scores (0-1 range) for easier comparison\n",
    "normalized_scores = {}\n",
    "for metric, info in metrics_info.items():\n",
    "    if metric not in metrics_df.columns:\n",
    "        continue  # Skip metrics that we don't have\n",
    "\n",
    "    values = [all_results[m]['metrics'].get(metric, 0) for m in methods]\n",
    "\n",
    "    # Handle error case\n",
    "    if any(isinstance(v, dict) and 'error' in v for v in values):\n",
    "        continue\n",
    "\n",
    "    if not info[\"higher_better\"]:\n",
    "        # Invert the score if lower is better\n",
    "        max_val = max(values) if max(values) > 0 else 1\n",
    "        normalized_scores[metric] = [1 - (v / max_val) for v in values]\n",
    "    else:\n",
    "        # Normalize to 0-1 range\n",
    "        max_val = max(values) if max(values) > 0 else 1\n",
    "        normalized_scores[metric] = [v / max_val for v in values]\n",
    "\n",
    "# Plot each metric as a group of bars\n",
    "for metric, info in metrics_info.items():\n",
    "    if metric not in normalized_scores:\n",
    "        continue\n",
    "\n",
    "    offset = width * multiplier\n",
    "    plt.bar(x + offset, normalized_scores[metric], width, label=info[\"name\"], color=info[\"color\"])\n",
    "    multiplier += 1\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Clustering Method')\n",
    "plt.ylabel('Normalized Score (higher is better)')\n",
    "plt.title('Clustering Quality Metrics Comparison')\n",
    "plt.xticks(x + width, [all_results[m]['name'] for m in methods])\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(comparison_dir, \"normalized_metrics.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 5. Create individual plots with metrics text underneath\n",
    "print(\"5. Creating individual visualizations with metrics...\")\n",
    "for key, result in all_results.items():\n",
    "    # Create figure with 2 rows: top for image, bottom for metrics\n",
    "    fig = plt.figure(figsize=(8, 10))\n",
    "\n",
    "    # Top plot: overlay\n",
    "    ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "    overlay = create_cluster_overlay(\n",
    "        cluster_labels=result['labels'],\n",
    "        rgb_image=original_rgb[excitation_for_viz],\n",
    "        alpha=0.5\n",
    "    )\n",
    "    ax1.imshow(overlay)\n",
    "    ax1.set_title(f\"Cluster Overlay: {result['name']}\")\n",
    "    ax1.axis('off')\n",
    "\n",
    "    # Bottom plot: metrics as text\n",
    "    ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "    ax2.axis('off')\n",
    "\n",
    "    # Format metrics text\n",
    "    metrics_text = \"Metrics:\\n\"\n",
    "    if isinstance(result['metrics'], dict) and 'error' not in result['metrics']:\n",
    "        for metric, value in result['metrics'].items():\n",
    "            # Format the metric name to be more readable\n",
    "            nice_name = metric.replace('_', ' ').title()\n",
    "            metrics_text += f\"{nice_name}: {value:.4f}\\n\"\n",
    "    else:\n",
    "        metrics_text += \"Metrics calculation failed\"\n",
    "\n",
    "    ax2.text(0.5, 0.5, metrics_text, ha='center', va='center', fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(comparison_dir, f\"overlay_with_metrics_{key}.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Also save without metrics for flexibility\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    overlay = create_cluster_overlay(\n",
    "        cluster_labels=result['labels'],\n",
    "        rgb_image=original_rgb[excitation_for_viz],\n",
    "        alpha=0.5\n",
    "    )\n",
    "    plt.imshow(overlay)\n",
    "    plt.title(f\"Cluster Overlay: {result['name']}\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(comparison_dir, f\"overlay_only_{key}.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "print(f\"All comparison visualizations saved to: {comparison_dir}\")"
   ],
   "id": "6ab7e54f663773a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import NMF\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch  # Added this import that was missing\n",
    "\n",
    "# Create directory for NMF comparison\n",
    "nmf_dir = os.path.join(output_dir, \"nmf_comparison\")\n",
    "os.makedirs(nmf_dir, exist_ok=True)\n",
    "\n",
    "print(\"Running Non-negative Matrix Factorization (NMF) for comparison...\")\n",
    "\n",
    "# 1. Prepare the data for NMF\n",
    "def prepare_hyperspectral_data_for_nmf(all_data, mask=None):\n",
    "    \"\"\"\n",
    "    Prepare hyperspectral data for NMF by flattening and stacking all excitations\n",
    "    \"\"\"\n",
    "    # Get first excitation to determine spatial dimensions\n",
    "    first_ex = next(iter(all_data.keys()))\n",
    "    if isinstance(all_data[first_ex], torch.Tensor):\n",
    "        first_data = all_data[first_ex].cpu().numpy()\n",
    "    else:\n",
    "        first_data = all_data[first_ex]\n",
    "\n",
    "    height, width, _ = first_data.shape\n",
    "\n",
    "    # Create list to hold all spectral data\n",
    "    all_spectra = []\n",
    "    wavelength_labels = []\n",
    "\n",
    "    # Process each excitation\n",
    "    for ex in all_data.keys():\n",
    "        if isinstance(all_data[ex], torch.Tensor):\n",
    "            data = all_data[ex].cpu().numpy()\n",
    "        else:\n",
    "            data = all_data[ex]\n",
    "\n",
    "        # Get the number of emission bands\n",
    "        _, _, n_bands = data.shape\n",
    "\n",
    "        # Reshape to [pixels, bands]\n",
    "        reshaped = data.reshape(height * width, n_bands)\n",
    "\n",
    "        # Add to list\n",
    "        all_spectra.append(reshaped)\n",
    "\n",
    "        # Add wavelength labels for tracking\n",
    "        for b in range(n_bands):\n",
    "            wavelength_labels.append(f\"Ex{ex}_Em{b}\")\n",
    "\n",
    "    # Concatenate along spectral dimension\n",
    "    X = np.hstack(all_spectra)\n",
    "\n",
    "    # Apply mask if provided\n",
    "    if mask is not None:\n",
    "        mask_flat = mask.flatten()\n",
    "        X = X[mask_flat > 0]\n",
    "        pixel_indices = np.where(mask_flat > 0)[0]\n",
    "    else:\n",
    "        pixel_indices = np.arange(height * width)\n",
    "\n",
    "    return X, pixel_indices, (height, width), wavelength_labels\n",
    "\n",
    "# 2. Run NMF with same number of components as clusters\n",
    "n_components = 10  # Same as n_clusters used in K-means\n",
    "\n",
    "# Prepare data\n",
    "print(\"Preparing data for NMF...\")\n",
    "X, pixel_indices, spatial_dims, wavelength_labels = prepare_hyperspectral_data_for_nmf(\n",
    "    all_data, dataset.processed_mask)\n",
    "height, width = spatial_dims\n",
    "\n",
    "print(f\"Data shape for NMF: {X.shape}\")\n",
    "\n",
    "# Initialize and fit NMF model\n",
    "print(f\"Fitting NMF with {n_components} components...\")\n",
    "model = NMF(\n",
    "    n_components=n_components,\n",
    "    init='random',\n",
    "    random_state=42,\n",
    "    max_iter=200,\n",
    "    solver='cd',  # Coordinate descent usually works well for this\n",
    ")\n",
    "\n",
    "# Fit model and get components (endmembers) and coefficients (abundances)\n",
    "W = model.fit_transform(X)  # abundance coefficients [pixels, components]\n",
    "H = model.components_      # endmembers [components, wavelengths]\n",
    "\n",
    "print(f\"NMF model fit complete.\")\n",
    "\n",
    "# 3. Create abundance maps\n",
    "print(\"Creating abundance maps...\")\n",
    "abundance_maps = np.zeros((height, width, n_components))\n",
    "\n",
    "# Fill in the valid pixels\n",
    "for i, pixel_idx in enumerate(pixel_indices):\n",
    "    y, x = pixel_idx // width, pixel_idx % width\n",
    "    abundance_maps[y, x, :] = W[i, :]\n",
    "\n",
    "# 4. Visualize abundance maps\n",
    "print(\"Visualizing abundance maps...\")\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(n_components):\n",
    "    ax = axes[i]\n",
    "    im = ax.imshow(abundance_maps[:, :, i], cmap='viridis')\n",
    "    ax.set_title(f'Component {i+1}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.colorbar(im, ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(nmf_dir, \"abundance_maps.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 5. Visualize endmember spectra\n",
    "print(\"Visualizing endmember spectra...\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i in range(n_components):\n",
    "    plt.plot(H[i], label=f'Component {i+1}')\n",
    "\n",
    "plt.xlabel('Wavelength Index')\n",
    "plt.ylabel('Intensity')\n",
    "plt.title('NMF Endmember Spectra')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig(os.path.join(nmf_dir, \"endmember_spectra.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 6. Compare with clustering by creating dominant component map\n",
    "print(\"Creating dominant component map...\")\n",
    "dominant_component = np.argmax(abundance_maps, axis=2)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(dominant_component, cmap='tab10')\n",
    "plt.colorbar(label='Dominant Component')\n",
    "plt.title('Dominant NMF Component Map')\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(nmf_dir, \"dominant_component_map.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 7. Create RGB overlay for dominant component\n",
    "print(\"Creating RGB overlay for dominant component...\")\n",
    "excitation_for_viz = list(original_rgb.keys())[0]\n",
    "overlay = create_cluster_overlay(\n",
    "    cluster_labels=dominant_component,\n",
    "    rgb_image=original_rgb[excitation_for_viz],\n",
    "    alpha=0.5,\n",
    "    output_path=os.path.join(nmf_dir, \"dominant_component_overlay.png\")\n",
    ")\n",
    "\n",
    "# 8. Quantitatively compare NMF dominant components with clustering\n",
    "print(\"Comparing NMF with clustering results...\")\n",
    "\n",
    "# Compute overlap between dominant NMF components and cluster labels\n",
    "def compute_component_cluster_overlap(components, clusters, n_components, n_clusters):\n",
    "    \"\"\"\n",
    "    Compute overlap between NMF components and cluster assignments\n",
    "    \"\"\"\n",
    "    # Flatten both maps\n",
    "    components_flat = components.flatten()\n",
    "    clusters_flat = clusters.flatten()\n",
    "\n",
    "    # Consider only pixels with valid assignments in both\n",
    "    valid_mask = (clusters_flat >= 0)\n",
    "    components_flat = components_flat[valid_mask]\n",
    "    clusters_flat = clusters_flat[valid_mask]\n",
    "\n",
    "    # Create confusion matrix\n",
    "    confusion = np.zeros((n_components, n_clusters))\n",
    "\n",
    "    for i in range(len(components_flat)):\n",
    "        component = components_flat[i]\n",
    "        cluster = clusters_flat[i]\n",
    "        confusion[component, cluster] += 1\n",
    "\n",
    "    # Normalize by cluster size\n",
    "    cluster_sizes = np.sum(confusion, axis=0)\n",
    "    normalized_confusion = confusion / (cluster_sizes + 1e-10)\n",
    "\n",
    "    return confusion, normalized_confusion\n",
    "\n",
    "confusion, normalized_confusion = compute_component_cluster_overlap(\n",
    "    dominant_component, cluster_labels, n_components, 10)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(normalized_confusion, cmap='Blues', interpolation='nearest')\n",
    "plt.colorbar(label='Overlap Ratio')\n",
    "plt.xlabel('Cluster ID')\n",
    "plt.ylabel('NMF Component ID')\n",
    "plt.title('NMF Component vs K-means Cluster Overlap')\n",
    "for i in range(n_components):\n",
    "    for j in range(10):\n",
    "        plt.text(j, i, f'{normalized_confusion[i, j]:.2f}',\n",
    "                ha='center', va='center', color='white' if normalized_confusion[i, j] > 0.3 else 'black')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(nmf_dir, \"component_cluster_overlap.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 9. Calculate overall agreement (assigned to same group)\n",
    "print(\"Calculating overall agreement...\")\n",
    "\n",
    "# Create a mapping from NMF components to best matching clusters\n",
    "component_to_cluster = np.argmax(normalized_confusion, axis=1)\n",
    "\n",
    "# Create a remapped NMF component map to match clusters\n",
    "remapped_component = np.zeros_like(dominant_component)\n",
    "for i in range(n_components):\n",
    "    remapped_component[dominant_component == i] = component_to_cluster[i]\n",
    "\n",
    "# Calculate agreement\n",
    "valid_mask = (cluster_labels >= 0)\n",
    "agreement = np.sum(remapped_component[valid_mask] == cluster_labels[valid_mask]) / np.sum(valid_mask)\n",
    "\n",
    "print(f\"Overall agreement between NMF and clustering: {agreement:.4f} ({agreement*100:.1f}%)\")\n",
    "\n",
    "# 10. Side-by-side comparison of clustering and NMF\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(cluster_labels, cmap='tab10')\n",
    "plt.title('K-means Clustering')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(dominant_component, cmap='tab10')\n",
    "plt.title('NMF Dominant Component')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(nmf_dir, \"clustering_vs_nmf.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 11. Summary table for poster\n",
    "summary = {\n",
    "    'Method': ['K-means Clustering', 'NMF Decomposition'],\n",
    "    'Approach': ['Hard assignment to clusters', 'Soft assignment (abundance weights)'],\n",
    "    'Number of Groups': [10, n_components],\n",
    "    'Features Used': ['Autoencoder latent space', 'Raw spectral data'],\n",
    "    'Agreement': ['-', f'{agreement*100:.1f}%']\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_df.to_csv(os.path.join(nmf_dir, \"method_comparison.csv\"), index=False)\n",
    "\n",
    "print(f\"NMF analysis complete. Results saved to: {nmf_dir}\")"
   ],
   "id": "4ba1354a78751849",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from scipy import ndimage\n",
    "import pandas as pd\n",
    "\n",
    "# Create a dedicated folder for spectral profiles\n",
    "profiles_dir = os.path.join(output_dir, \"spectral_profiles\")\n",
    "os.makedirs(profiles_dir, exist_ok=True)\n",
    "\n",
    "# 1. MODIFY SIDE-BY-SIDE COMPARISON TO INCLUDE ORIGINAL IMAGE\n",
    "print(\"3. Creating side-by-side comparison visualization with original image...\")\n",
    "n_methods = len(all_results) + 1  # +1 for the original image\n",
    "fig, axes = plt.subplots(1, n_methods, figsize=(n_methods*5, 5))\n",
    "\n",
    "# First plot: original RGB image\n",
    "axes[0].imshow(original_rgb[excitation_for_viz])\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Then plot all clustering results\n",
    "for i, (key, result) in enumerate(all_results.items()):\n",
    "    ax = axes[i+1]  # +1 because the original image takes the first position\n",
    "    # Create cluster overlay\n",
    "    overlay = create_cluster_overlay(\n",
    "        cluster_labels=result['labels'],\n",
    "        rgb_image=original_rgb[excitation_for_viz],\n",
    "        alpha=0.5\n",
    "    )\n",
    "    # Display the overlay\n",
    "    ax.imshow(overlay)\n",
    "    ax.set_title(result['name'])\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(comparison_dir, \"all_overlays_comparison_with_original.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 2. EXTRACT SPECTRAL PROFILES FOR EACH CLUSTER\n",
    "print(\"6. Extracting and plotting spectral profiles for each clustering approach...\")\n",
    "\n",
    "# Function to extract spectral profiles for a specific excitation\n",
    "def extract_spectral_profiles(excitation, cluster_labels, all_data, mask=None):\n",
    "    \"\"\"\n",
    "    Extract average spectral profiles for each cluster in a specific excitation.\n",
    "\n",
    "    Args:\n",
    "        excitation: Excitation wavelength\n",
    "        cluster_labels: Cluster assignment for each pixel\n",
    "        all_data: Dictionary containing hyperspectral data\n",
    "        mask: Optional binary mask to apply\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping cluster IDs to average spectra\n",
    "    \"\"\"\n",
    "    # Get data for this excitation\n",
    "    ex_str = str(excitation)\n",
    "    if ex_str not in all_data:\n",
    "        print(f\"Warning: Excitation {excitation} not found in data.\")\n",
    "        return {}\n",
    "\n",
    "    # Get data and convert to numpy if needed\n",
    "    if isinstance(all_data[ex_str], torch.Tensor):\n",
    "        data = all_data[ex_str].cpu().numpy()\n",
    "    else:\n",
    "        data = all_data[ex_str]\n",
    "\n",
    "    # Get emission bands\n",
    "    n_bands = data.shape[2]\n",
    "\n",
    "    # Get unique cluster IDs (excluding -1 which is for masked areas)\n",
    "    unique_clusters = sorted([c for c in np.unique(cluster_labels) if c >= 0])\n",
    "\n",
    "    # Calculate average spectrum for each cluster\n",
    "    cluster_spectra = {}\n",
    "\n",
    "    for cluster_id in unique_clusters:\n",
    "        # Create mask for this cluster\n",
    "        cluster_mask = cluster_labels == cluster_id\n",
    "\n",
    "        # Apply additional mask if provided\n",
    "        if mask is not None:\n",
    "            cluster_mask = cluster_mask & (mask > 0)\n",
    "\n",
    "        # Skip if no pixels in this cluster\n",
    "        if not np.any(cluster_mask):\n",
    "            continue\n",
    "\n",
    "        # Extract spectra for all pixels in this cluster\n",
    "        cluster_data = data[cluster_mask]\n",
    "\n",
    "        # Calculate mean spectrum (ignore NaNs)\n",
    "        mean_spectrum = np.nanmean(cluster_data, axis=0)\n",
    "\n",
    "        # Calculate standard deviation for error bars\n",
    "        std_spectrum = np.nanstd(cluster_data, axis=0)\n",
    "\n",
    "        # Store in dictionary\n",
    "        cluster_spectra[cluster_id] = {\n",
    "            'mean': mean_spectrum,\n",
    "            'std': std_spectrum,\n",
    "            'count': np.sum(cluster_mask)\n",
    "        }\n",
    "\n",
    "    return cluster_spectra\n",
    "\n",
    "# For each excitation, plot clusters from individual and combined clustering\n",
    "for ex in excitations_to_compare:\n",
    "    print(f\"  Extracting spectral profiles for excitation {ex}...\")\n",
    "    ex_str = str(ex)\n",
    "\n",
    "    # Create a directory for this excitation\n",
    "    ex_dir = os.path.join(profiles_dir, f\"excitation_{ex}\")\n",
    "    os.makedirs(ex_dir, exist_ok=True)\n",
    "\n",
    "    # Get individual clustering result for this excitation\n",
    "    individual_labels = all_results[ex]['labels']\n",
    "\n",
    "    # Extract spectral profiles for individual clustering\n",
    "    individual_spectra = extract_spectral_profiles(\n",
    "        ex, individual_labels, all_data, dataset.processed_mask)\n",
    "\n",
    "    # Get wavelengths if available\n",
    "    if hasattr(dataset, 'emission_wavelengths') and ex in dataset.emission_wavelengths:\n",
    "        wavelengths = dataset.emission_wavelengths[ex]\n",
    "    else:\n",
    "        wavelengths = np.arange(all_data[ex_str].shape[2])\n",
    "\n",
    "    # 1. Plot individual clustering spectra\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    for cluster_id, spectrum in individual_spectra.items():\n",
    "        plt.plot(wavelengths, spectrum['mean'],\n",
    "                 label=f'Cluster {cluster_id} (n={spectrum[\"count\"]})',\n",
    "                 linewidth=2)\n",
    "\n",
    "        # Add error bands (1 standard deviation)\n",
    "        plt.fill_between(wavelengths,\n",
    "                          spectrum['mean'] - spectrum['std'],\n",
    "                          spectrum['mean'] + spectrum['std'],\n",
    "                          alpha=0.2)\n",
    "\n",
    "    plt.xlabel('Wavelength (nm)' if isinstance(wavelengths[0], (int, float)) else 'Emission Band Index')\n",
    "    plt.ylabel('Normalized Intensity')\n",
    "    plt.title(f'Spectral Profiles by Cluster - Individual Clustering (Ex {ex}nm)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ex_dir, f\"individual_spectra_{ex}.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # 2. Extract spectral profiles for combined clustering in this excitation\n",
    "    combined_labels = all_results['combined']['labels']\n",
    "    combined_spectra = extract_spectral_profiles(\n",
    "        ex, combined_labels, all_data, dataset.processed_mask)\n",
    "\n",
    "    # Plot combined clustering spectra\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    for cluster_id, spectrum in combined_spectra.items():\n",
    "        plt.plot(wavelengths, spectrum['mean'],\n",
    "                 label=f'Cluster {cluster_id} (n={spectrum[\"count\"]})',\n",
    "                 linewidth=2)\n",
    "\n",
    "        # Add error bands\n",
    "        plt.fill_between(wavelengths,\n",
    "                          spectrum['mean'] - spectrum['std'],\n",
    "                          spectrum['mean'] + spectrum['std'],\n",
    "                          alpha=0.2)\n",
    "\n",
    "    plt.xlabel('Wavelength (nm)' if isinstance(wavelengths[0], (int, float)) else 'Emission Band Index')\n",
    "    plt.ylabel('Normalized Intensity')\n",
    "    plt.title(f'Spectral Profiles by Cluster - Combined 4D Clustering (Ex {ex}nm)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ex_dir, f\"combined_spectra_{ex}.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # 3. Direct comparison between individual and combined for key clusters\n",
    "    # Choose top clusters by size (top 3 for clarity)\n",
    "    individual_top = sorted(individual_spectra.items(),\n",
    "                           key=lambda x: x[1]['count'],\n",
    "                           reverse=True)[:3]\n",
    "    combined_top = sorted(combined_spectra.items(),\n",
    "                         key=lambda x: x[1]['count'],\n",
    "                         reverse=True)[:3]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot individual top clusters with solid lines\n",
    "    for i, (cluster_id, spectrum) in enumerate(individual_top):\n",
    "        plt.plot(wavelengths, spectrum['mean'],\n",
    "                 label=f'Individual Cluster {cluster_id}',\n",
    "                 linestyle='-', linewidth=2)\n",
    "\n",
    "    # Plot combined top clusters with dashed lines\n",
    "    for i, (cluster_id, spectrum) in enumerate(combined_top):\n",
    "        plt.plot(wavelengths, spectrum['mean'],\n",
    "                 label=f'Combined Cluster {cluster_id}',\n",
    "                 linestyle='--', linewidth=2)\n",
    "\n",
    "    plt.xlabel('Wavelength (nm)' if isinstance(wavelengths[0], (int, float)) else 'Emission Band Index')\n",
    "    plt.ylabel('Normalized Intensity')\n",
    "    plt.title(f'Comparison of Top Clusters - Individual vs Combined (Ex {ex}nm)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ex_dir, f\"comparison_spectra_{ex}.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# 3. CREATE SUMMARY VISUALIZATION WITH ALL EXCITATIONS\n",
    "# For the poster, create a compact visualization showing key spectral differences\n",
    "print(\"7. Creating summary spectral profile visualization...\")\n",
    "\n",
    "# Select a single representative excitation for clarity\n",
    "representative_ex = excitations_to_compare[0]\n",
    "rep_ex_str = str(representative_ex)\n",
    "\n",
    "# Get wavelengths\n",
    "if hasattr(dataset, 'emission_wavelengths') and representative_ex in dataset.emission_wavelengths:\n",
    "    wavelengths = dataset.emission_wavelengths[representative_ex]\n",
    "else:\n",
    "    wavelengths = np.arange(all_data[rep_ex_str].shape[2])\n",
    "\n",
    "# Create a 2x2 grid: Individual vs Combined, Cluster Maps vs Spectra\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Top row: Cluster maps\n",
    "# Top left: Individual clustering\n",
    "ax1 = plt.subplot2grid((2, 2), (0, 0))\n",
    "ax1.imshow(all_results[representative_ex]['labels'], cmap='tab10')\n",
    "ax1.set_title(f'Individual Clustering (Ex {representative_ex}nm)')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Top right: Combined clustering\n",
    "ax2 = plt.subplot2grid((2, 2), (0, 1))\n",
    "ax2.imshow(all_results['combined']['labels'], cmap='tab10')\n",
    "ax2.set_title('Combined 4D Clustering')\n",
    "ax2.axis('off')\n",
    "\n",
    "# Bottom row: Spectral profiles\n",
    "# Bottom left: Individual spectra\n",
    "ax3 = plt.subplot2grid((2, 2), (1, 0))\n",
    "individual_spectra = extract_spectral_profiles(\n",
    "    representative_ex, all_results[representative_ex]['labels'],\n",
    "    all_data, dataset.processed_mask)\n",
    "\n",
    "for cluster_id, spectrum in individual_spectra.items():\n",
    "    ax3.plot(wavelengths, spectrum['mean'],\n",
    "             label=f'Cluster {cluster_id}')\n",
    "\n",
    "ax3.set_xlabel('Wavelength (nm)' if isinstance(wavelengths[0], (int, float)) else 'Emission Band')\n",
    "ax3.set_ylabel('Normalized Intensity')\n",
    "ax3.set_title('Individual Clustering Spectra')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.legend()\n",
    "\n",
    "# Bottom right: Combined spectra\n",
    "ax4 = plt.subplot2grid((2, 2), (1, 1))\n",
    "combined_spectra = extract_spectral_profiles(\n",
    "    representative_ex, all_results['combined']['labels'],\n",
    "    all_data, dataset.processed_mask)\n",
    "\n",
    "for cluster_id, spectrum in combined_spectra.items():\n",
    "    ax4.plot(wavelengths, spectrum['mean'],\n",
    "             label=f'Cluster {cluster_id}')\n",
    "\n",
    "ax4.set_xlabel('Wavelength (nm)' if isinstance(wavelengths[0], (int, float)) else 'Emission Band')\n",
    "ax4.set_ylabel('Normalized Intensity')\n",
    "ax4.set_title('Combined 4D Clustering Spectra')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(profiles_dir, \"summary_comparison.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Spectral profiles saved to: {profiles_dir}\")"
   ],
   "id": "46aa42b845bfd73a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_and_plot_spectral_profiles():\n",
    "    \"\"\"\n",
    "    Create spectral profile plots for both individual excitation clustering\n",
    "    and combined 4D clustering.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import torch  # Add this import to handle tensor conversion\n",
    "    from matplotlib.colors import Normalize\n",
    "\n",
    "    # Create a dedicated folder for spectral profiles\n",
    "    profiles_dir = os.path.join(output_dir, \"spectral_profiles\")\n",
    "    os.makedirs(profiles_dir, exist_ok=True)\n",
    "\n",
    "    print(\"\\n=== Extracting and plotting spectral profiles ===\")\n",
    "\n",
    "    # Print what's actually in all_data to identify the correct keys\n",
    "    print(\"Keys in all_data:\")\n",
    "    if isinstance(all_data, dict):\n",
    "        all_data_keys = list(all_data.keys())\n",
    "        print(f\"  all_data contains {len(all_data_keys)} keys: {all_data_keys[:5]}...\")\n",
    "    else:\n",
    "        print(f\"  all_data is not a dictionary, it's a {type(all_data)}\")\n",
    "\n",
    "    # Get list of all excitations\n",
    "    available_excitations = list(encoded_features.keys())\n",
    "    print(f\"Available excitations: {available_excitations}\")\n",
    "\n",
    "    # Map encoded_features keys to all_data keys - THIS IS THE CRITICAL FIX\n",
    "    # Since the issue is that we have excitation values as floats but all_data might be using them as strings\n",
    "    # Or the actual mapping might be different\n",
    "    ex_to_data_key = {}\n",
    "\n",
    "    # Try different formats to match the keys\n",
    "    for ex in available_excitations:\n",
    "        # Try as is (float)\n",
    "        if ex in all_data:\n",
    "            ex_to_data_key[ex] = ex\n",
    "        # Try as string\n",
    "        elif str(ex) in all_data:\n",
    "            ex_to_data_key[ex] = str(ex)\n",
    "        # Try as integer\n",
    "        elif int(ex) in all_data:\n",
    "            ex_to_data_key[ex] = int(ex)\n",
    "        # Try with different float precision\n",
    "        elif f\"{ex:.1f}\" in all_data:\n",
    "            ex_to_data_key[ex] = f\"{ex:.1f}\"\n",
    "\n",
    "    print(f\"Found matching keys for {len(ex_to_data_key)} excitations\")\n",
    "\n",
    "    # Function to extract spectral profiles for a specific excitation\n",
    "    def extract_spectral_profiles(excitation, cluster_labels, all_data, ex_to_data_key, mask=None):\n",
    "        \"\"\"Extract average spectral profiles for each cluster in a specific excitation.\"\"\"\n",
    "        # Map to the right key\n",
    "        if excitation not in ex_to_data_key:\n",
    "            print(f\"WARNING: No matching key found for excitation {excitation}\")\n",
    "            return {}\n",
    "\n",
    "        data_key = ex_to_data_key[excitation]\n",
    "        print(f\"Using data_key '{data_key}' for excitation {excitation}\")\n",
    "\n",
    "        # Get data and convert to numpy if needed\n",
    "        if isinstance(all_data[data_key], torch.Tensor):\n",
    "            data = all_data[data_key].cpu().numpy()\n",
    "        else:\n",
    "            data = all_data[data_key]\n",
    "\n",
    "        print(f\"Processing excitation {excitation} data shape: {data.shape}\")\n",
    "\n",
    "        # Get emission bands\n",
    "        n_bands = data.shape[2]\n",
    "\n",
    "        # Get unique cluster IDs (excluding -1 which is for masked areas)\n",
    "        unique_clusters = sorted([c for c in np.unique(cluster_labels) if c >= 0])\n",
    "        print(f\"Found {len(unique_clusters)} unique clusters\")\n",
    "\n",
    "        # Calculate average spectrum for each cluster\n",
    "        cluster_spectra = {}\n",
    "\n",
    "        for cluster_id in unique_clusters:\n",
    "            # Create mask for this cluster\n",
    "            cluster_mask = cluster_labels == cluster_id\n",
    "\n",
    "            # Apply additional mask if provided\n",
    "            if mask is not None:\n",
    "                cluster_mask = cluster_mask & (mask > 0)\n",
    "\n",
    "            # Count pixels in this cluster\n",
    "            pixel_count = np.sum(cluster_mask)\n",
    "\n",
    "            # Skip if no pixels in this cluster\n",
    "            if pixel_count == 0:\n",
    "                continue\n",
    "\n",
    "            # Extract spectra for all pixels in this cluster\n",
    "            cluster_data = data[cluster_mask]\n",
    "\n",
    "            # Calculate mean spectrum (ignore NaNs)\n",
    "            mean_spectrum = np.nanmean(cluster_data, axis=0)\n",
    "\n",
    "            # Calculate standard deviation for error bars\n",
    "            std_spectrum = np.nanstd(cluster_data, axis=0)\n",
    "\n",
    "            # Store in dictionary\n",
    "            cluster_spectra[cluster_id] = {\n",
    "                'mean': mean_spectrum,\n",
    "                'std': std_spectrum,\n",
    "                'count': pixel_count\n",
    "            }\n",
    "\n",
    "        return cluster_spectra\n",
    "\n",
    "    # Process each excitation that has a mapping\n",
    "    for ex in available_excitations:\n",
    "        if ex not in ex_to_data_key:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nProcessing excitation {ex}...\")\n",
    "\n",
    "        # Create a directory for this excitation\n",
    "        ex_dir = os.path.join(profiles_dir, f\"excitation_{ex}\")\n",
    "        os.makedirs(ex_dir, exist_ok=True)\n",
    "\n",
    "        # Get individual clustering result for this excitation\n",
    "        if ex in all_results:\n",
    "            individual_labels = all_results[ex]['labels']\n",
    "        else:\n",
    "            print(f\"Individual clustering not found for excitation {ex}\")\n",
    "            continue\n",
    "\n",
    "        # Get combined clustering labels\n",
    "        combined_labels = all_results['combined']['labels']\n",
    "\n",
    "        # Get wavelengths if available\n",
    "        if hasattr(dataset, 'emission_wavelengths') and ex in dataset.emission_wavelengths:\n",
    "            wavelengths = dataset.emission_wavelengths[ex]\n",
    "        else:\n",
    "            data_key = ex_to_data_key[ex]\n",
    "            wavelengths = np.arange(all_data[data_key].shape[2])\n",
    "\n",
    "        # Extract spectral profiles for individual clustering\n",
    "        print(\"Extracting individual clustering spectra...\")\n",
    "        individual_spectra = extract_spectral_profiles(\n",
    "            ex, individual_labels, all_data, ex_to_data_key, dataset.processed_mask)\n",
    "\n",
    "        # Plot individual clustering spectra\n",
    "        if individual_spectra:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "\n",
    "            for cluster_id, spectrum in individual_spectra.items():\n",
    "                plt.plot(wavelengths, spectrum['mean'],\n",
    "                        label=f'Cluster {cluster_id} (n={spectrum[\"count\"]})',\n",
    "                        linewidth=2)\n",
    "\n",
    "                # Add error bands (1 standard deviation)\n",
    "                plt.fill_between(wavelengths,\n",
    "                                spectrum['mean'] - spectrum['std'],\n",
    "                                spectrum['mean'] + spectrum['std'],\n",
    "                                alpha=0.2)\n",
    "\n",
    "            plt.xlabel('Wavelength (nm)' if isinstance(wavelengths[0], (int, float)) else 'Emission Band Index')\n",
    "            plt.ylabel('Normalized Intensity')\n",
    "            plt.title(f'Spectral Profiles by Cluster - Individual Clustering (Ex {ex}nm)')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(ex_dir, f\"individual_spectra_{ex}.png\"), dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "        # Extract spectral profiles for combined clustering in this excitation\n",
    "        print(\"Extracting combined 4D clustering spectra...\")\n",
    "        combined_spectra = extract_spectral_profiles(\n",
    "            ex, combined_labels, all_data, ex_to_data_key, dataset.processed_mask)\n",
    "\n",
    "        # Plot combined clustering spectra\n",
    "        if combined_spectra:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "\n",
    "            for cluster_id, spectrum in combined_spectra.items():\n",
    "                plt.plot(wavelengths, spectrum['mean'],\n",
    "                        label=f'Cluster {cluster_id} (n={spectrum[\"count\"]})',\n",
    "                        linewidth=2)\n",
    "\n",
    "                # Add error bands\n",
    "                plt.fill_between(wavelengths,\n",
    "                                spectrum['mean'] - spectrum['std'],\n",
    "                                spectrum['mean'] + spectrum['std'],\n",
    "                                alpha=0.2)\n",
    "\n",
    "            plt.xlabel('Wavelength (nm)' if isinstance(wavelengths[0], (int, float)) else 'Emission Band Index')\n",
    "            plt.ylabel('Normalized Intensity')\n",
    "            plt.title(f'Spectral Profiles by Cluster - Combined 4D Clustering (Ex {ex}nm)')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(ex_dir, f\"combined_spectra_{ex}.png\"), dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "        # If both individual and combined profiles are available, create comparison\n",
    "        if individual_spectra and combined_spectra:\n",
    "            # Choose top clusters by size (top 3 for clarity)\n",
    "            individual_top = sorted(individual_spectra.items(),\n",
    "                                key=lambda x: x[1]['count'],\n",
    "                                reverse=True)[:3]\n",
    "            combined_top = sorted(combined_spectra.items(),\n",
    "                                key=lambda x: x[1]['count'],\n",
    "                                reverse=True)[:3]\n",
    "\n",
    "            plt.figure(figsize=(12, 6))\n",
    "\n",
    "            # Plot individual top clusters with solid lines\n",
    "            for i, (cluster_id, spectrum) in enumerate(individual_top):\n",
    "                plt.plot(wavelengths, spectrum['mean'],\n",
    "                        label=f'Individual Cluster {cluster_id}',\n",
    "                        linestyle='-', linewidth=2)\n",
    "\n",
    "            # Plot combined top clusters with dashed lines\n",
    "            for i, (cluster_id, spectrum) in enumerate(combined_top):\n",
    "                plt.plot(wavelengths, spectrum['mean'],\n",
    "                        label=f'Combined Cluster {cluster_id}',\n",
    "                        linestyle='--', linewidth=2)\n",
    "\n",
    "            plt.xlabel('Wavelength (nm)' if isinstance(wavelengths[0], (int, float)) else 'Emission Band Index')\n",
    "            plt.ylabel('Normalized Intensity')\n",
    "            plt.title(f'Comparison of Top Clusters - Individual vs Combined (Ex {ex}nm)')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(ex_dir, f\"comparison_spectra_{ex}.png\"), dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "    print(f\"Spectral profiles saved to: {profiles_dir}\")\n",
    "\n",
    "# Run the function\n",
    "extract_and_plot_spectral_profiles()"
   ],
   "id": "8280cdaa3331e792",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_4d_cluster_profiles_by_excitation():\n",
    "    \"\"\"\n",
    "    Create spectral profiles for 4D clusters with separate lines for each excitation.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import torch\n",
    "    from matplotlib.colors import Normalize\n",
    "\n",
    "    # Create directory\n",
    "    profiles_dir = os.path.join(output_dir, \"spectral_profiles_4d\")\n",
    "    os.makedirs(profiles_dir, exist_ok=True)\n",
    "\n",
    "    print(\"\\n=== Creating 4D cluster profiles with separate lines for each excitation ===\")\n",
    "\n",
    "    # First, identify what keys are in all_data\n",
    "    if isinstance(all_data, dict):\n",
    "        all_data_keys = list(all_data.keys())\n",
    "        print(f\"all_data keys: {all_data_keys[:10]}...\")\n",
    "\n",
    "    # Get excitation wavelengths\n",
    "    available_excitations = []\n",
    "    for key in all_data_keys:\n",
    "        try:\n",
    "            # Try to convert to float\n",
    "            ex = float(key)\n",
    "            available_excitations.append(ex)\n",
    "        except (ValueError, TypeError):\n",
    "            # Not a numerical key\n",
    "            continue\n",
    "\n",
    "    available_excitations.sort()\n",
    "    print(f\"Available excitations: {available_excitations}\")\n",
    "\n",
    "    # Get combined clustering labels\n",
    "    combined_labels = all_results['combined']['labels']\n",
    "\n",
    "    # Get unique cluster IDs (excluding -1)\n",
    "    unique_clusters = sorted([c for c in np.unique(combined_labels) if c >= 0])\n",
    "    print(f\"Found {len(unique_clusters)} unique clusters\")\n",
    "\n",
    "    # Process each cluster\n",
    "    for cluster_id in unique_clusters:\n",
    "        print(f\"Processing cluster {cluster_id}...\")\n",
    "\n",
    "        # Create mask for this cluster\n",
    "        cluster_mask = combined_labels == cluster_id\n",
    "\n",
    "        # Apply additional mask if provided\n",
    "        if dataset.processed_mask is not None:\n",
    "            cluster_mask = cluster_mask & (dataset.processed_mask > 0)\n",
    "\n",
    "        # Count pixels in this cluster\n",
    "        pixel_count = np.sum(cluster_mask)\n",
    "        print(f\"  Cluster {cluster_id} has {pixel_count} pixels\")\n",
    "\n",
    "        # Skip if empty\n",
    "        if pixel_count == 0:\n",
    "            continue\n",
    "\n",
    "        # Create figure for this cluster\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Process each excitation\n",
    "        for ex in available_excitations:\n",
    "            # Get data for this excitation\n",
    "            ex_str = str(ex)\n",
    "            if ex_str not in all_data:\n",
    "                continue\n",
    "\n",
    "            # Get data\n",
    "            if isinstance(all_data[ex_str], torch.Tensor):\n",
    "                data = all_data[ex_str].cpu().numpy()\n",
    "            else:\n",
    "                data = all_data[ex_str]\n",
    "\n",
    "            # Get wavelengths\n",
    "            if hasattr(dataset, 'emission_wavelengths') and ex in dataset.emission_wavelengths:\n",
    "                wavelengths = dataset.emission_wavelengths[ex]\n",
    "            else:\n",
    "                wavelengths = np.arange(data.shape[2])\n",
    "\n",
    "            # Extract spectra for this cluster\n",
    "            cluster_data = data[cluster_mask]\n",
    "\n",
    "            # Skip if no data\n",
    "            if len(cluster_data) == 0:\n",
    "                continue\n",
    "\n",
    "            # Calculate mean spectrum\n",
    "            mean_spectrum = np.nanmean(cluster_data, axis=0)\n",
    "\n",
    "            # Plot with excitation in the label\n",
    "            plt.plot(wavelengths, mean_spectrum,\n",
    "                     label=f'Ex {ex}nm',\n",
    "                     linewidth=1.5)\n",
    "\n",
    "        plt.xlabel('Wavelength/Band Index')\n",
    "        plt.ylabel('Normalized Intensity')\n",
    "        plt.title(f'Cluster {cluster_id} Spectral Profile Across All Excitations (n={pixel_count})')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend(loc='best', ncol=3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(profiles_dir, f\"cluster_{cluster_id}_all_excitations.png\"), dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"4D cluster profiles saved to: {profiles_dir}\")\n",
    "\n",
    "def create_side_by_side_comparison():\n",
    "    \"\"\"\n",
    "    Create a side-by-side comparison of:\n",
    "    1. Original RGB image\n",
    "    2. Individual excitation clustering\n",
    "    3. Combined 4D clustering\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import torch\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    # Create directory\n",
    "    comparison_dir = os.path.join(output_dir, \"clustering_comparison_original\")\n",
    "    os.makedirs(comparison_dir, exist_ok=True)\n",
    "\n",
    "    print(\"\\n=== Creating side-by-side comparison ===\")\n",
    "\n",
    "    # 1. Find available excitations\n",
    "    if isinstance(all_data, dict):\n",
    "        all_data_keys = list(all_data.keys())\n",
    "        print(f\"all_data keys: {all_data_keys[:10]}...\")\n",
    "\n",
    "    # Get excitation wavelengths\n",
    "    available_excitations = []\n",
    "    for key in all_data_keys:\n",
    "        try:\n",
    "            # Try to convert to float\n",
    "            ex = float(key)\n",
    "            available_excitations.append(ex)\n",
    "        except (ValueError, TypeError):\n",
    "            # Not a numerical key\n",
    "            continue\n",
    "\n",
    "    available_excitations.sort()\n",
    "    print(f\"Available excitations: {available_excitations}\")\n",
    "\n",
    "    # 2. Select excitations for individual clustering (starting from ~300nm)\n",
    "    selected_excitations = []\n",
    "    for ex in available_excitations:\n",
    "        if ex >= 300 and len(selected_excitations) < 4:\n",
    "            selected_excitations.append(ex)\n",
    "\n",
    "    print(f\"Selected excitations for individual clustering: {selected_excitations}\")\n",
    "\n",
    "    # 3. Create RGB image from excitation ~350nm\n",
    "    reference_ex = min(available_excitations, key=lambda x: abs(x - 350))\n",
    "    print(f\"Using excitation {reference_ex}nm for RGB reference\")\n",
    "\n",
    "    if reference_ex not in all_data:\n",
    "        reference_ex = available_excitations[0]\n",
    "        print(f\"Fallback to excitation {reference_ex}nm\")\n",
    "\n",
    "    # Get reference data\n",
    "    if isinstance(all_data[str(reference_ex)], torch.Tensor):\n",
    "        reference_data = all_data[str(reference_ex)].cpu().numpy()\n",
    "    else:\n",
    "        reference_data = all_data[str(reference_ex)]\n",
    "\n",
    "    # Create RGB from reference data\n",
    "    n_bands = reference_data.shape[2]\n",
    "    r_idx = min(n_bands - 1, int(n_bands * 0.8))  # Use band at 80% for red\n",
    "    g_idx = min(n_bands - 1, int(n_bands * 0.5))  # Use band at 50% for green\n",
    "    b_idx = min(n_bands - 1, int(n_bands * 0.2))  # Use band at 20% for blue\n",
    "\n",
    "    rgb_image = np.stack([\n",
    "        reference_data[:, :, r_idx],\n",
    "        reference_data[:, :, g_idx],\n",
    "        reference_data[:, :, b_idx]\n",
    "    ], axis=2)\n",
    "\n",
    "    # Normalize RGB\n",
    "    rgb_min = np.nanmin(rgb_image)\n",
    "    rgb_max = np.nanmax(rgb_image)\n",
    "    rgb_image = (rgb_image - rgb_min) / (rgb_max - rgb_min)\n",
    "    rgb_image = np.clip(rgb_image, 0, 1)\n",
    "\n",
    "    # Save RGB image separately\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(rgb_image)\n",
    "    plt.title(f'RGB Composite (Ex {reference_ex}nm)')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(comparison_dir, \"original_rgb.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # 4. Run clustering on original data for selected excitations\n",
    "    original_cluster_results = {}\n",
    "\n",
    "    for ex in selected_excitations:\n",
    "        print(f\"Running clustering on original data for excitation {ex}nm...\")\n",
    "        ex_str = str(ex)\n",
    "\n",
    "        # Get data\n",
    "        if isinstance(all_data[ex_str], torch.Tensor):\n",
    "            data = all_data[ex_str].cpu().numpy()\n",
    "        else:\n",
    "            data = all_data[ex_str]\n",
    "\n",
    "        # Reshape for clustering [pixels, bands]\n",
    "        height, width, n_bands = data.shape\n",
    "        reshaped = data.reshape(-1, n_bands)\n",
    "\n",
    "        # Apply mask if available\n",
    "        valid_indices = None\n",
    "        if dataset.processed_mask is not None:\n",
    "            mask_flat = dataset.processed_mask.flatten()\n",
    "            valid_indices = np.where(mask_flat > 0)[0]\n",
    "            reshaped = reshaped[valid_indices]\n",
    "\n",
    "        # Run K-means\n",
    "        kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "        labels = kmeans.fit_predict(reshaped)\n",
    "\n",
    "        # Reshape labels back to image\n",
    "        cluster_map = np.ones((height, width)) * -1  # Default to -1 (masked)\n",
    "        if valid_indices is not None:\n",
    "            for i, idx in enumerate(valid_indices):\n",
    "                y, x = idx // width, idx % width\n",
    "                cluster_map[y, x] = labels[i]\n",
    "        else:\n",
    "            cluster_map = labels.reshape(height, width)\n",
    "\n",
    "        # Store result\n",
    "        original_cluster_results[ex] = cluster_map\n",
    "\n",
    "        # Save individual cluster map\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(cluster_map, cmap='tab10', interpolation='nearest')\n",
    "        plt.colorbar(label='Cluster')\n",
    "        plt.title(f'Original Data Clustering (Ex {ex}nm)')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(comparison_dir, f\"original_clustering_ex{ex}.png\"), dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # 5. Get combined 4D clustering result\n",
    "    combined_labels = all_results['combined']['labels']\n",
    "\n",
    "    # Save combined clustering\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(combined_labels, cmap='tab10', interpolation='nearest')\n",
    "    plt.colorbar(label='Cluster')\n",
    "    plt.title('Combined 4D Clustering')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(comparison_dir, \"combined_clustering.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # 6. Create side-by-side comparison\n",
    "    n_plots = len(selected_excitations) + 2  # +2 for original RGB and combined\n",
    "    fig, axes = plt.subplots(1, n_plots, figsize=(n_plots * 4, 5))\n",
    "\n",
    "    # Plot original RGB\n",
    "    axes[0].imshow(rgb_image)\n",
    "    axes[0].set_title(f'RGB Composite\\n(Ex {reference_ex}nm)')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Plot individual clusterings\n",
    "    for i, ex in enumerate(selected_excitations):\n",
    "        axes[i+1].imshow(original_cluster_results[ex], cmap='tab10')\n",
    "        axes[i+1].set_title(f'Clustering\\n(Ex {ex}nm)')\n",
    "        axes[i+1].axis('off')\n",
    "\n",
    "    # Plot combined clustering\n",
    "    axes[-1].imshow(combined_labels, cmap='tab10')\n",
    "    axes[-1].set_title('Combined 4D\\nClustering')\n",
    "    axes[-1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(comparison_dir, \"full_comparison.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Side-by-side comparison saved to: {comparison_dir}\")\n",
    "\n",
    "# Run both functions\n",
    "create_4d_cluster_profiles_by_excitation()\n",
    "create_side_by_side_comparison()"
   ],
   "id": "1ecb85c90827d594",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_side_by_side_comparison():\n",
    "    \"\"\"\n",
    "    Create a side-by-side comparison of:\n",
    "    1. Original RGB image\n",
    "    2. Individual excitation clustering\n",
    "    3. Combined 4D clustering\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import torch\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    # Create directory\n",
    "    comparison_dir = os.path.join(output_dir, \"clustering_comparison_original\")\n",
    "    os.makedirs(comparison_dir, exist_ok=True)\n",
    "\n",
    "    print(\"\\n=== Creating side-by-side comparison ===\")\n",
    "\n",
    "    # 1. Get all available excitation wavelengths\n",
    "    available_excitations = list(all_data.keys())\n",
    "    available_excitations.sort()\n",
    "    print(f\"Available excitations: {available_excitations[:5]}... (total: {len(available_excitations)})\")\n",
    "\n",
    "    # 2. Select excitations for individual clustering (4 excitations starting around 300nm)\n",
    "    selected_excitations = []\n",
    "    for ex in available_excitations:\n",
    "        if ex >= 300 and len(selected_excitations) < 4:\n",
    "            selected_excitations.append(ex)\n",
    "\n",
    "    print(f\"Selected excitations for individual clustering: {selected_excitations}\")\n",
    "\n",
    "    # 3. Create RGB image from reference excitation (~350nm)\n",
    "    reference_ex = min(available_excitations, key=lambda x: abs(x - 350))\n",
    "    print(f\"Using excitation {reference_ex}nm for RGB reference\")\n",
    "\n",
    "    # Get tensor data and convert to numpy\n",
    "    reference_data = all_data[reference_ex].cpu().numpy()\n",
    "    print(f\"Reference data shape: {reference_data.shape}\")\n",
    "\n",
    "    # Create RGB from reference data\n",
    "    n_bands = reference_data.shape[2]\n",
    "    r_idx = min(n_bands - 1, int(n_bands * 0.8))  # Use band at 80% for red\n",
    "    g_idx = min(n_bands - 1, int(n_bands * 0.5))  # Use band at 50% for green\n",
    "    b_idx = min(n_bands - 1, int(n_bands * 0.2))  # Use band at 20% for blue\n",
    "\n",
    "    print(f\"RGB bands from: R={r_idx}, G={g_idx}, B={b_idx}\")\n",
    "\n",
    "    rgb_image = np.stack([\n",
    "        reference_data[:, :, r_idx],\n",
    "        reference_data[:, :, g_idx],\n",
    "        reference_data[:, :, b_idx]\n",
    "    ], axis=2)\n",
    "\n",
    "    # Normalize RGB\n",
    "    rgb_min = np.nanmin(rgb_image)\n",
    "    rgb_max = np.nanmax(rgb_image)\n",
    "    rgb_image = (rgb_image - rgb_min) / (rgb_max - rgb_min)\n",
    "    rgb_image = np.clip(rgb_image, 0, 1)\n",
    "\n",
    "    # Save RGB image separately\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(rgb_image)\n",
    "    plt.title(f'RGB Composite (Ex {reference_ex}nm)')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(comparison_dir, \"original_rgb.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # 4. Run clustering on original data for selected excitations\n",
    "    original_cluster_results = {}\n",
    "\n",
    "    for ex in selected_excitations:\n",
    "        print(f\"Running clustering on original data for excitation {ex}nm...\")\n",
    "\n",
    "        # Get data and convert to numpy\n",
    "        data = all_data[ex].cpu().numpy()\n",
    "        print(f\"  Data shape: {data.shape}\")\n",
    "\n",
    "        # Reshape for clustering [pixels, bands]\n",
    "        height, width, n_bands = data.shape\n",
    "        reshaped = data.reshape(-1, n_bands)\n",
    "\n",
    "        # Apply mask if available\n",
    "        valid_indices = None\n",
    "        if dataset.processed_mask is not None:\n",
    "            mask_flat = dataset.processed_mask.flatten()\n",
    "            valid_indices = np.where(mask_flat > 0)[0]\n",
    "            reshaped = reshaped[valid_indices]\n",
    "\n",
    "        # Run K-means\n",
    "        kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "        labels = kmeans.fit_predict(reshaped)\n",
    "\n",
    "        # Reshape labels back to image\n",
    "        cluster_map = np.ones((height, width)) * -1  # Default to -1 (masked)\n",
    "        if valid_indices is not None:\n",
    "            for i, idx in enumerate(valid_indices):\n",
    "                y, x = idx // width, idx % width\n",
    "                cluster_map[y, x] = labels[i]\n",
    "        else:\n",
    "            cluster_map = labels.reshape(height, width)\n",
    "\n",
    "        # Store result\n",
    "        original_cluster_results[ex] = cluster_map\n",
    "\n",
    "        # Save individual cluster map\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(cluster_map, cmap='tab10', interpolation='nearest')\n",
    "        plt.colorbar(label='Cluster')\n",
    "        plt.title(f'Original Data Clustering (Ex {ex}nm)')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(comparison_dir, f\"original_clustering_ex{ex}.png\"), dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # 5. Get combined 4D clustering result\n",
    "    combined_labels = all_results['combined']['labels']\n",
    "\n",
    "    # Save combined clustering\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(combined_labels, cmap='tab10', interpolation='nearest')\n",
    "    plt.colorbar(label='Cluster')\n",
    "    plt.title('Combined 4D Clustering')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(comparison_dir, \"combined_clustering.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # 6. Create side-by-side comparison\n",
    "    n_plots = len(selected_excitations) + 2  # +2 for original RGB and combined\n",
    "    fig, axes = plt.subplots(1, n_plots, figsize=(n_plots * 4, 5))\n",
    "\n",
    "    # Plot original RGB\n",
    "    axes[0].imshow(rgb_image)\n",
    "    axes[0].set_title(f'RGB Composite\\n(Ex {reference_ex}nm)')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Plot individual clusterings\n",
    "    for i, ex in enumerate(selected_excitations):\n",
    "        axes[i+1].imshow(original_cluster_results[ex], cmap='tab10')\n",
    "        axes[i+1].set_title(f'Clustering\\n(Ex {ex}nm)')\n",
    "        axes[i+1].axis('off')\n",
    "\n",
    "    # Plot combined clustering\n",
    "    axes[-1].imshow(combined_labels, cmap='tab10')\n",
    "    axes[-1].set_title('Combined 4D\\nClustering')\n",
    "    axes[-1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(comparison_dir, \"full_comparison.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Side-by-side comparison saved to: {comparison_dir}\")\n",
    "\n",
    "# Run the function\n",
    "create_side_by_side_comparison()"
   ],
   "id": "eaaa8f2dbb47a478",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a0f9b10177df2832",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
