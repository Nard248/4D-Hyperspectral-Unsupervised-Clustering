{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperspectral Data Analysis with Convolutional Autoencoders\n",
    "\n",
    "This notebook demonstrates how to use the hyperspectral convolutional autoencoder modules to:\n",
    "1. Load and preprocess hyperspectral data\n",
    "2. Handle variable emission band lengths and masked (NaN) values\n",
    "3. Train and evaluate a convolutional autoencoder with sigmoid activations\n",
    "4. Visualize results with various methods"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Import our custom modules\n",
    "from hyperspectral_dataset import HyperspectralDataset, load_hyperspectral_data\n",
    "from hyperspectral_models import HyperspectralCAEVariable\n",
    "from hyperspectral_training import train_variable_cae, evaluate_model\n",
    "from hyperspectral_visualization import (\n",
    "    visualize_training_loss,\n",
    "    visualize_emission_spectrum,\n",
    "    visualize_multiple_spectra,\n",
    "    visualize_spatial_slice,\n",
    "    visualize_feature_maps,\n",
    "    visualize_reconstruction_comparison,\n",
    "    visualize_multiple_excitations,\n",
    "    visualize_all_spectral_bands\n",
    ")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Hyperspectral Data\n",
    "\n",
    "First, we load the data from a pickle file created by the HyperspectralDataLoader."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set the path to your data file\n",
    "data_path = \"../Data/Kiwi Experiment/pickles/masked_KiwiData.pkl\"\n",
    "\n",
    "# Load the data\n",
    "data_dict = load_hyperspectral_data(data_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Dataset with Global Normalization and NaN Handling\n",
    "\n",
    "Create a dataset that will handle NaN values and apply global normalization to the [0,1] range."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create dataset\n",
    "dataset = HyperspectralDataset(\n",
    "    data_dict,\n",
    "    normalize=True,  # Apply global normalization to [0,1]\n",
    "    downscale_factor=1  # Use full resolution (adjust based on memory constraints)\n",
    ")\n",
    "\n",
    "# Get all processed data\n",
    "all_data = dataset.get_all_data()\n",
    "spatial_height, spatial_width = dataset.get_spatial_dimensions()\n",
    "\n",
    "print(f\"Processed data dimensions: {spatial_height}x{spatial_width}\")\n",
    "\n",
    "# Print normalization parameters if available\n",
    "if hasattr(dataset, 'normalization_params'):\n",
    "    print(f\"Global normalization range: [{dataset.normalization_params['min']:.4f}, {dataset.normalization_params['max']:.4f}]\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create and Train the Convolutional Autoencoder Model\n",
    "\n",
    "Now we'll create our model and train it using chunking for memory efficiency."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create model\n",
    "model = HyperspectralCAEVariable(\n",
    "    excitations_data={ex: data.numpy() for ex, data in all_data.items()},\n",
    "    k1=20,  # Number of filters in first layer\n",
    "    k3=20,  # Number of filters in third layer\n",
    "    filter_size=5,\n",
    "    sparsity_target=0.1,  # Lower value for sigmoid activation\n",
    "    sparsity_weight=1.0,\n",
    "    dropout_rate=0.5,\n",
    "    debug=False\n",
    ")\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters())} parameters\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Train model (or load a previously trained model)\n",
    "train_new_model = True  # Set to False to load a previously saved model\n",
    "\n",
    "if train_new_model:\n",
    "    model, losses = train_variable_cae(\n",
    "        model,\n",
    "        dataset,\n",
    "        num_epochs=20,\n",
    "        learning_rate=0.01,\n",
    "        chunk_size=32,\n",
    "        chunk_overlap=8,\n",
    "        early_stopping_patience=5  # Stop if no improvement for 5 epochs\n",
    "    )\n",
    "    \n",
    "    # Save the final model (best model is saved during training)\n",
    "    torch.save(model.state_dict(), \"hyperspectral_cae_final_model.pth\")\n",
    "    print(\"Final model saved to hyperspectral_cae_final_model.pth\")\n",
    "    \n",
    "    # Visualize training loss\n",
    "    visualize_training_loss(losses)\n",
    "else:\n",
    "    # Load previously trained model\n",
    "    model_path = \"best_hyperspectral_model.pth\"\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    print(f\"Model loaded from {model_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the Model\n",
    "\n",
    "Generate reconstructions and evaluate the model performance."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Evaluate the model\n",
    "evaluation_results = evaluate_model(model, dataset, chunk_size=64, chunk_overlap=8, device=device)\n",
    "\n",
    "# Print overall metrics\n",
    "if 'overall' in evaluation_results['metrics']:\n",
    "    print(f\"\\nOverall Metrics:\")\n",
    "    for metric, value in evaluation_results['metrics']['overall'].items():\n",
    "        print(f\"  {metric.upper()}: {value:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Reconstructions for Visualization\n",
    "\n",
    "For visualization purposes, we'll generate reconstructions for all excitations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Generate reconstructions for all excitations\n",
    "model.eval()\n",
    "reconstructions = {}\n",
    "\n",
    "for ex, data in all_data.items():\n",
    "    # Add batch dimension\n",
    "    data_batch = {ex: data.unsqueeze(0).to(device)}\n",
    "    \n",
    "    # Generate reconstruction\n",
    "    with torch.no_grad():\n",
    "        output = model(data_batch)\n",
    "    \n",
    "    # Store reconstruction\n",
    "    if ex in output:\n",
    "        reconstructions[ex] = output[ex][0].cpu()  # Remove batch dimension\n",
    "        print(f\"Generated reconstruction for excitation {ex}nm. \"\n",
    "              f\"Shape: {reconstructions[ex].shape}, \"\n",
    "              f\"Range: [{reconstructions[ex].min().item():.4f}, {reconstructions[ex].max().item():.4f}]\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizations\n",
    "\n",
    "Now we'll create various visualizations to analyze the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Emission Spectrum Analysis\n",
    "\n",
    "First, let's visualize the emission spectrum at different spatial locations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Select a specific excitation wavelength to analyze\n",
    "excitation_to_analyze = list(all_data.keys())[0]  # Use first excitation\n",
    "print(f\"Analyzing excitation wavelength: {excitation_to_analyze}nm\")\n",
    "\n",
    "# Get original and reconstructed data\n",
    "original_data = all_data[excitation_to_analyze]\n",
    "reconstructed_data = reconstructions[excitation_to_analyze]\n",
    "\n",
    "# Get emission wavelengths if available\n",
    "emission_wavelengths = dataset.emission_wavelengths.get(excitation_to_analyze, None)\n",
    "if emission_wavelengths:\n",
    "    print(f\"Emission wavelength range: {min(emission_wavelengths)}nm - {max(emission_wavelengths)}nm\")\n",
    "\n",
    "# Visualize spectrum at center pixel\n",
    "center_y, center_x = spatial_height // 2, spatial_width // 2\n",
    "rmse = visualize_emission_spectrum(\n",
    "    original_data,\n",
    "    reconstructed_data,\n",
    "    excitation_to_analyze,\n",
    "    y=center_y,\n",
    "    x=center_x,\n",
    "    wavelengths=emission_wavelengths\n",
    ")\n",
    "print(f\"Center pixel RMSE: {rmse:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize multiple spectra at different positions\n",
    "h_quarter, w_quarter = spatial_height // 4, spatial_width // 4\n",
    "positions = [\n",
    "    (h_quarter, w_quarter),\n",
    "    (h_quarter, spatial_width - w_quarter),\n",
    "    (spatial_height - h_quarter, w_quarter),\n",
    "    (spatial_height - h_quarter, spatial_width - w_quarter)\n",
    "]\n",
    "\n",
    "rmse_values = visualize_multiple_spectra(\n",
    "    original_data,\n",
    "    reconstructed_data,\n",
    "    excitation_to_analyze,\n",
    "    positions=positions,\n",
    "    wavelengths=emission_wavelengths\n",
    ")\n",
    "print(f\"RMSE at different positions: {[f'{rmse:.4f}' for rmse in rmse_values]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Spatial Slice Analysis\n",
    "\n",
    "Now let's look at spatial slices for specific emission bands."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize a spatial slice for a specific emission band\n",
    "# Use the middle emission band\n",
    "middle_band = original_data.shape[2] // 2\n",
    "\n",
    "metrics = visualize_spatial_slice(\n",
    "    original_data,\n",
    "    reconstructed_data,\n",
    "    excitation_to_analyze,\n",
    "    emission_idx=middle_band,\n",
    "    cmap='viridis'\n",
    ")\n",
    "\n",
    "print(f\"Spatial metrics for emission band {middle_band}:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Feature Maps Visualization\n",
    "\n",
    "Let's examine what features the model is learning."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize feature maps\n",
    "feature_stats = visualize_feature_maps(\n",
    "    model,\n",
    "    {excitation_to_analyze: all_data[excitation_to_analyze]},\n",
    "    num_maps=16,\n",
    "    cmap='viridis',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Print feature activation statistics\n",
    "print(\"\\nFeature Map Statistics:\")\n",
    "print(f\"  Mean activation range: [{np.min(feature_stats['means']):.4f}, {np.max(feature_stats['means']):.4f}]\")\n",
    "print(f\"  Mean standard deviation: {np.mean(feature_stats['stds']):.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 RGB False Color Visualization\n",
    "\n",
    "Create false color visualizations to compare original and reconstructed data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# RGB false color visualization for a single excitation\n",
    "visualization_results = visualize_reconstruction_comparison(\n",
    "    original_data,\n",
    "    reconstructed_data,\n",
    "    emission_wavelengths,\n",
    "    excitation_to_analyze,\n",
    "    use_consistent_normalization=True\n",
    ")\n",
    "\n",
    "# Print RGB channel RMSE values\n",
    "print(\"\\nRGB Channel RMSE Values:\")\n",
    "for channel, value in visualization_results['rmse'].items():\n",
    "    print(f\"  {channel.upper()}: {value:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize multiple excitations\n",
    "rmse_values = visualize_multiple_excitations(\n",
    "    model,\n",
    "    all_data,\n",
    "    dataset.emission_wavelengths,\n",
    "    use_consistent_normalization=False,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Print RMSE for each excitation\n",
    "print(\"\\nRMSE for each excitation wavelength:\")\n",
    "for ex, rmse in sorted(rmse_values.items()):\n",
    "    print(f\"  Ex={ex}nm: {rmse:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Detailed Spectral Band Analysis\n",
    "\n",
    "Visualize all spectral bands for a specific excitation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize all spectral bands\n",
    "band_rmse = visualize_all_spectral_bands(\n",
    "    original_data,\n",
    "    reconstructed_data,\n",
    "    excitation_to_analyze,\n",
    "    emission_wavelengths=emission_wavelengths,\n",
    "    grid_size=4,  # Adjust based on number of bands\n",
    "    cmap='viridis'\n",
    ")\n",
    "\n",
    "# Find best and worst reconstructed bands\n",
    "best_band = min(band_rmse.items(), key=lambda x: x[1])\n",
    "worst_band = max(band_rmse.items(), key=lambda x: x[1])\n",
    "\n",
    "best_wavelength = emission_wavelengths[best_band[0]] if emission_wavelengths else best_band[0]\n",
    "worst_wavelength = emission_wavelengths[worst_band[0]] if emission_wavelengths else worst_band[0]\n",
    "\n",
    "print(f\"\\nBest reconstructed band: {best_wavelength}nm (RMSE: {best_band[1]:.4f})\")\n",
    "print(f\"Worst reconstructed band: {worst_wavelength}nm (RMSE: {worst_band[1]:.4f})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analysis Summary\n",
    "\n",
    "Create a summary of the model performance and visualization results."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Calculate overall metrics for all excitations\n",
    "overall_metrics = {}\n",
    "all_rmse = []\n",
    "\n",
    "for ex in reconstructions:\n",
    "    if ex in all_data:\n",
    "        orig = all_data[ex]\n",
    "        recon = reconstructions[ex]\n",
    "        \n",
    "        # MSE\n",
    "        mse = torch.mean((orig - recon) ** 2).item()\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # MAE\n",
    "        mae = torch.mean(torch.abs(orig - recon)).item()\n",
    "        \n",
    "        all_rmse.append(rmse)\n",
    "        \n",
    "        # Store metrics\n",
    "        overall_metrics[ex] = {\n",
    "            'mse': mse,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae\n",
    "        }\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "print(f\"Number of excitation wavelengths: {len(reconstructions)}\")\n",
    "print(f\"Average RMSE across all excitations: {np.mean(all_rmse):.4f}\")\n",
    "print(f\"Best excitation: {min(overall_metrics.items(), key=lambda x: x[1]['rmse'])[0]}\")\n",
    "print(f\"Worst excitation: {max(overall_metrics.items(), key=lambda x: x[1]['rmse'])[0]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
