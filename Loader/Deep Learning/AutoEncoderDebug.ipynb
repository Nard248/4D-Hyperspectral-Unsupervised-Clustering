{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create output directories\n",
    "output_dir = \"output\"\n",
    "model_dir = os.path.join(output_dir, 'models')\n",
    "results_dir = os.path.join(output_dir, 'results')\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MaskedHyperspectralDataset(Dataset):\n",
    "    def __init__(self, pickle_file, patch_size=None):\n",
    "        \"\"\"\n",
    "        Dataset for hyperspectral data with mask handling\n",
    "\n",
    "        Args:\n",
    "            pickle_file: Path to pickle file\n",
    "            patch_size: Size of patches to extract (None for full image)\n",
    "        \"\"\"\n",
    "        self.pickle_file = Path(pickle_file)\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        # Load the data\n",
    "        print(f\"Loading data from {self.pickle_file}...\")\n",
    "        with open(self.pickle_file, 'rb') as f:\n",
    "            self.data_dict = pickle.load(f)\n",
    "\n",
    "        # Get dimensions\n",
    "        self.excitation_wavelengths = sorted([float(ex) for ex in self.data_dict['data'].keys()])\n",
    "        print(f\"Found {len(self.excitation_wavelengths)} excitation wavelengths\")\n",
    "\n",
    "        # Get dimensions from first excitation\n",
    "        first_ex = str(self.excitation_wavelengths[0])\n",
    "        self.height, self.width, _ = self.data_dict['data'][first_ex]['cube'].shape\n",
    "        print(f\"Image dimensions: {self.height} x {self.width}\")\n",
    "\n",
    "        # Create data and mask tensors\n",
    "        self._create_data_and_mask()\n",
    "\n",
    "        # Setup patches if needed\n",
    "        if patch_size is not None:\n",
    "            self._setup_patches()\n",
    "\n",
    "    def _create_data_and_mask(self):\n",
    "        \"\"\"Create data tensor and corresponding mask\"\"\"\n",
    "        # Find maximum number of emission bands across all excitations\n",
    "        self.n_excitations = len(self.excitation_wavelengths)\n",
    "        self.max_emissions = max(len(self.data_dict['data'][str(ex)]['wavelengths'])\n",
    "                                for ex in self.excitation_wavelengths)\n",
    "        print(f\"Maximum emission bands: {self.max_emissions}\")\n",
    "\n",
    "        # Create tensors\n",
    "        self.data_tensor = np.zeros((self.n_excitations, self.max_emissions, self.height, self.width))\n",
    "        self.mask_tensor = np.zeros((self.n_excitations, self.max_emissions, self.height, self.width), dtype=bool)\n",
    "        self.wavelength_info = []\n",
    "\n",
    "        # Fill tensors\n",
    "        for ex_idx, ex in enumerate(self.excitation_wavelengths):\n",
    "            ex_str = str(ex)\n",
    "            cube = self.data_dict['data'][ex_str]['cube']\n",
    "            wavelengths = self.data_dict['data'][ex_str]['wavelengths']\n",
    "            self.wavelength_info.append(wavelengths)\n",
    "\n",
    "            # Transpose to [emissions, height, width]\n",
    "            transposed_cube = np.transpose(cube, (2, 0, 1))\n",
    "\n",
    "            # Fill data and mask\n",
    "            n_em = len(wavelengths)\n",
    "            self.data_tensor[ex_idx, :n_em, :, :] = transposed_cube\n",
    "            self.mask_tensor[ex_idx, :n_em, :, :] = ~np.isnan(transposed_cube)\n",
    "\n",
    "        # Replace NaNs with zeros for convenience\n",
    "        self.data_tensor = np.nan_to_num(self.data_tensor, nan=0.0)\n",
    "\n",
    "        # Report mask statistics\n",
    "        valid_percentage = self.mask_tensor.sum() / self.mask_tensor.size * 100\n",
    "        print(f\"Valid data percentage: {valid_percentage:.2f}%\")\n",
    "\n",
    "    def _setup_patches(self):\n",
    "        \"\"\"Setup patches for extraction\"\"\"\n",
    "        # Calculate number of patches\n",
    "        patches_y = max(1, (self.height - self.patch_size) // (self.patch_size // 4) + 1)\n",
    "        patches_x = max(1, (self.width - self.patch_size) // (self.patch_size // 4) + 1)\n",
    "\n",
    "        # Generate patch positions (with 50% overlap)\n",
    "        self.patch_positions = []\n",
    "        for i in range(patches_y):\n",
    "            y = min(i * (self.patch_size // 4), self.height - self.patch_size)\n",
    "            for j in range(patches_x):\n",
    "                x = min(j * (self.patch_size // 4), self.width - self.patch_size)\n",
    "                # Only add patches with some valid data\n",
    "                patch_mask = self.mask_tensor[:, :, y:y+self.patch_size, x:x+self.patch_size]\n",
    "                if patch_mask.sum() > 0:  # At least one valid point\n",
    "                    self.patch_positions.append((y, x))\n",
    "\n",
    "        print(f\"Created {len(self.patch_positions)} valid patches of size {self.patch_size}x{self.patch_size}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return dataset length\"\"\"\n",
    "        return len(self.patch_positions) if self.patch_size is not None else 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get data with mask\"\"\"\n",
    "        if self.patch_size is not None:\n",
    "            # Extract patch\n",
    "            y, x = self.patch_positions[idx]\n",
    "            data = self.data_tensor[:, :, y:y+self.patch_size, x:x+self.patch_size].copy()\n",
    "            mask = self.mask_tensor[:, :, y:y+self.patch_size, x:x+self.patch_size].copy()\n",
    "            positions = (y, x)\n",
    "        else:\n",
    "            # Return full tensor\n",
    "            data = self.data_tensor.copy()\n",
    "            mask = self.mask_tensor.copy()\n",
    "            positions = (0, 0)\n",
    "\n",
    "        # Convert to tensors\n",
    "        data_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "        mask_tensor = torch.tensor(mask, dtype=torch.float32)  # Convert bool to float for math operations\n",
    "        pos_tensor = torch.tensor(positions, dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            'data': data_tensor,\n",
    "            'mask': mask_tensor,\n",
    "            'positions': pos_tensor\n",
    "        }"
   ],
   "id": "a0b8d00ea936dab6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Basic convolutional block with batch normalization\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.conv(x)))\n",
    "\n",
    "class UpConvBlock(nn.Module):\n",
    "    \"\"\"Upsampling block for decoder\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, scale_factor=2):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=scale_factor, mode='nearest')\n",
    "        self.conv = ConvBlock(in_channels, out_channels, kernel_size, stride, padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(self.upsample(x))\n",
    "\n",
    "class MaskedHyperspectralAutoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoencoder for hyperspectral data with mask handling\n",
    "    \"\"\"\n",
    "    def __init__(self, n_excitations, n_emissions, patch_size=64, latent_dim=128, n_clusters=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_excitations = n_excitations\n",
    "        self.n_emissions = n_emissions\n",
    "        self.patch_size = patch_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.n_clusters = n_clusters\n",
    "\n",
    "        # Number of channels when flattening excitation-emission dims\n",
    "        self.n_channels = n_excitations * n_emissions\n",
    "\n",
    "        # Encoder pathway\n",
    "        self.encoder = nn.Sequential(\n",
    "            # First layer: [batch, n_channels, patch_size, patch_size]\n",
    "            ConvBlock(self.n_channels, 64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Second layer: [batch, 64, patch_size/2, patch_size/2]\n",
    "            ConvBlock(64, 128),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Third layer: [batch, 128, patch_size/4, patch_size/4]\n",
    "            ConvBlock(128, 256),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # Calculate size after encoding\n",
    "        self.encoded_size = patch_size // 8\n",
    "\n",
    "        # Latent representation\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_encode = nn.Linear(256 * self.encoded_size * self.encoded_size, latent_dim)\n",
    "\n",
    "        # Clustering head\n",
    "        self.cluster_head = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, n_clusters)\n",
    "        )\n",
    "\n",
    "        # Decoder pathway\n",
    "        self.fc_decode = nn.Linear(latent_dim, 256 * self.encoded_size * self.encoded_size)\n",
    "        self.unflatten = nn.Unflatten(1, (256, self.encoded_size, self.encoded_size))\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            # First decoder layer: [batch, 256, patch_size/8, patch_size/8]\n",
    "            UpConvBlock(256, 128, scale_factor=2),\n",
    "\n",
    "            # Second decoder layer: [batch, 128, patch_size/4, patch_size/4]\n",
    "            UpConvBlock(128, 64, scale_factor=2),\n",
    "\n",
    "            # Final decoder layer: [batch, 64, patch_size/2, patch_size/2]\n",
    "            UpConvBlock(64, self.n_channels, scale_factor=2),\n",
    "\n",
    "            # Output activation\n",
    "            nn.Sigmoid()  # Normalize output to [0,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass through the autoencoder\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor [batch, n_excitations, n_emissions, patch_size, patch_size]\n",
    "            mask: Mask tensor [batch, n_excitations, n_emissions, patch_size, patch_size]\n",
    "\n",
    "        Returns:\n",
    "            reconstructed: Reconstructed data\n",
    "            latent: Latent features\n",
    "            cluster_logits: Clustering logits\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        # Store original shape\n",
    "        original_shape = x.shape\n",
    "\n",
    "        # Reshape to merge excitation and emission dimensions\n",
    "        x_reshaped = x.reshape(batch_size, self.n_channels, original_shape[3], original_shape[4])\n",
    "\n",
    "        # Encode\n",
    "        encoded = self.encoder(x_reshaped)\n",
    "\n",
    "        # Compress to latent space\n",
    "        flattened = self.flatten(encoded)\n",
    "        latent = self.fc_encode(flattened)\n",
    "\n",
    "        # Prevent NaN values\n",
    "        if torch.isnan(latent).any():\n",
    "            print(\"Warning: NaN in latent space - replacing with zeros\")\n",
    "            latent = torch.nan_to_num(latent, nan=0.0)\n",
    "\n",
    "        # Get cluster assignments\n",
    "        cluster_logits = self.cluster_head(latent)\n",
    "\n",
    "        # Decode from latent space\n",
    "        decoded_flat = self.fc_decode(latent)\n",
    "        decoded_3d = self.unflatten(decoded_flat)\n",
    "\n",
    "        # Reconstruct\n",
    "        reconstructed_flat = self.decoder(decoded_3d)\n",
    "\n",
    "        # Reshape back to original dimensions\n",
    "        reconstructed = reconstructed_flat.reshape(\n",
    "            batch_size,\n",
    "            original_shape[1],  # n_excitations\n",
    "            original_shape[2],  # n_emissions\n",
    "            original_shape[3],  # patch_size/height\n",
    "            original_shape[4]   # patch_size/width\n",
    "        )\n",
    "\n",
    "        # Zero out invalid regions in reconstruction (optional)\n",
    "        if mask is not None:\n",
    "            reconstructed = reconstructed * mask\n",
    "\n",
    "        return reconstructed, latent, cluster_logits"
   ],
   "id": "c93f56dab0695814",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Basic convolutional block with batch normalization\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.conv(x)))\n",
    "\n",
    "class UpConvBlock(nn.Module):\n",
    "    \"\"\"Upsampling block for decoder\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, scale_factor=2):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=scale_factor, mode='nearest')\n",
    "        self.conv = ConvBlock(in_channels, out_channels, kernel_size, stride, padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(self.upsample(x))\n",
    "\n",
    "class MaskedHyperspectralAutoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoencoder for hyperspectral data with mask handling\n",
    "    \"\"\"\n",
    "    def __init__(self, n_excitations, n_emissions, patch_size=64, latent_dim=128, n_clusters=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_excitations = n_excitations\n",
    "        self.n_emissions = n_emissions\n",
    "        self.patch_size = patch_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.n_clusters = n_clusters\n",
    "\n",
    "        # Number of channels when flattening excitation-emission dims\n",
    "        self.n_channels = n_excitations * n_emissions\n",
    "\n",
    "        # Encoder pathway\n",
    "        self.encoder = nn.Sequential(\n",
    "            # First layer: [batch, n_channels, patch_size, patch_size]\n",
    "            ConvBlock(self.n_channels, 64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Second layer: [batch, 64, patch_size/2, patch_size/2]\n",
    "            ConvBlock(64, 128),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Third layer: [batch, 128, patch_size/4, patch_size/4]\n",
    "            ConvBlock(128, 256),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # Calculate size after encoding\n",
    "        self.encoded_size = patch_size // 8\n",
    "\n",
    "        # Latent representation\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_encode = nn.Linear(256 * self.encoded_size * self.encoded_size, latent_dim)\n",
    "\n",
    "        # Clustering head\n",
    "        self.cluster_head = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, n_clusters)\n",
    "        )\n",
    "\n",
    "        # Decoder pathway\n",
    "        self.fc_decode = nn.Linear(latent_dim, 256 * self.encoded_size * self.encoded_size)\n",
    "        self.unflatten = nn.Unflatten(1, (256, self.encoded_size, self.encoded_size))\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            # First decoder layer: [batch, 256, patch_size/8, patch_size/8]\n",
    "            UpConvBlock(256, 128, scale_factor=2),\n",
    "\n",
    "            # Second decoder layer: [batch, 128, patch_size/4, patch_size/4]\n",
    "            UpConvBlock(128, 64, scale_factor=2),\n",
    "\n",
    "            # Final decoder layer: [batch, 64, patch_size/2, patch_size/2]\n",
    "            UpConvBlock(64, self.n_channels, scale_factor=2),\n",
    "\n",
    "            # Output activation\n",
    "            nn.Sigmoid()  # Normalize output to [0,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass through the autoencoder\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor [batch, n_excitations, n_emissions, patch_size, patch_size]\n",
    "            mask: Mask tensor [batch, n_excitations, n_emissions, patch_size, patch_size]\n",
    "\n",
    "        Returns:\n",
    "            reconstructed: Reconstructed data\n",
    "            latent: Latent features\n",
    "            cluster_logits: Clustering logits\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        # Store original shape\n",
    "        original_shape = x.shape\n",
    "\n",
    "        # Reshape to merge excitation and emission dimensions\n",
    "        x_reshaped = x.reshape(batch_size, self.n_channels, original_shape[3], original_shape[4])\n",
    "\n",
    "        # Encode\n",
    "        encoded = self.encoder(x_reshaped)\n",
    "\n",
    "        # Compress to latent space\n",
    "        flattened = self.flatten(encoded)\n",
    "        latent = self.fc_encode(flattened)\n",
    "\n",
    "        # Prevent NaN values\n",
    "        if torch.isnan(latent).any():\n",
    "            print(\"Warning: NaN in latent space - replacing with zeros\")\n",
    "            latent = torch.nan_to_num(latent, nan=0.0)\n",
    "\n",
    "        # Get cluster assignments\n",
    "        cluster_logits = self.cluster_head(latent)\n",
    "\n",
    "        # Decode from latent space\n",
    "        decoded_flat = self.fc_decode(latent)\n",
    "        decoded_3d = self.unflatten(decoded_flat)\n",
    "\n",
    "        # Reconstruct\n",
    "        reconstructed_flat = self.decoder(decoded_3d)\n",
    "\n",
    "        # Reshape back to original dimensions\n",
    "        reconstructed = reconstructed_flat.reshape(\n",
    "            batch_size,\n",
    "            original_shape[1],  # n_excitations\n",
    "            original_shape[2],  # n_emissions\n",
    "            original_shape[3],  # patch_size/height\n",
    "            original_shape[4]   # patch_size/width\n",
    "        )\n",
    "\n",
    "        # Zero out invalid regions in reconstruction (optional)\n",
    "        if mask is not None:\n",
    "            reconstructed = reconstructed * mask\n",
    "\n",
    "        return reconstructed, latent, cluster_logits"
   ],
   "id": "26e591500fab5a67",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MaskedMSELoss(nn.Module):\n",
    "    \"\"\"MSE loss that only considers masked (valid) values\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, pred, target, mask):\n",
    "        \"\"\"\n",
    "        Compute MSE only on valid values\n",
    "\n",
    "        Args:\n",
    "            pred: Predicted values [batch, channels, height, width]\n",
    "            target: Target values  [batch, channels, height, width]\n",
    "            mask: Binary mask [batch, channels, height, width] (1 for valid)\n",
    "\n",
    "        Returns:\n",
    "            Masked MSE loss\n",
    "        \"\"\"\n",
    "        # Element-wise squared error\n",
    "        squared_diff = (pred - target) ** 2\n",
    "\n",
    "        # Apply mask\n",
    "        masked_squared_diff = squared_diff * mask\n",
    "\n",
    "        # Sum and normalize by number of valid elements\n",
    "        valid_elements = mask.sum() + 1e-8  # Avoid division by zero\n",
    "        loss = masked_squared_diff.sum() / valid_elements\n",
    "\n",
    "        return loss\n",
    "\n",
    "class MaskedDeepClusteringLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Combined loss function for masked deep clustering with reconstruction\n",
    "    \"\"\"\n",
    "    def __init__(self, n_clusters, alpha=1.0, beta=0.1, gamma=0.01):\n",
    "        super().__init__()\n",
    "        self.n_clusters = n_clusters\n",
    "\n",
    "        # Loss weights\n",
    "        self.alpha = alpha  # Reconstruction weight\n",
    "        self.beta = beta    # Clustering weight\n",
    "        self.gamma = gamma  # Regularization weight\n",
    "\n",
    "        # MSE loss for reconstruction\n",
    "        self.mse_loss = MaskedMSELoss()\n",
    "\n",
    "        # K-means state\n",
    "        self.kmeans = None\n",
    "        self.centroids = None\n",
    "        self.initialized = False\n",
    "\n",
    "    def forward(self, original, reconstructed, latent_features, mask, target_distribution=None):\n",
    "        \"\"\"\n",
    "        Compute the combined loss\n",
    "\n",
    "        Args:\n",
    "            original: Original input data\n",
    "            reconstructed: Reconstructed data\n",
    "            latent_features: Latent space features\n",
    "            mask: Binary mask of valid values\n",
    "            target_distribution: Optional target distribution\n",
    "\n",
    "        Returns:\n",
    "            total_loss, recon_loss, cluster_loss, reg_loss\n",
    "        \"\"\"\n",
    "        # Reconstruction loss (masked MSE)\n",
    "        recon_loss = self.mse_loss(reconstructed, original, mask)\n",
    "\n",
    "        # Initialize or update centroids\n",
    "        if not self.initialized or self.centroids is None:\n",
    "            # Get features as numpy\n",
    "            features_np = latent_features.detach().cpu().numpy()\n",
    "\n",
    "            # Check for NaN values\n",
    "            if np.isnan(features_np).any():\n",
    "                print(f\"Warning: Found {np.isnan(features_np).sum()} NaN values in features\")\n",
    "                features_np = np.nan_to_num(features_np, nan=0.0)\n",
    "\n",
    "            # Initialize k-means\n",
    "            try:\n",
    "                self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=42)\n",
    "                self.kmeans.fit(features_np)\n",
    "\n",
    "                # Convert centroids to tensor\n",
    "                self.centroids = torch.tensor(\n",
    "                    self.kmeans.cluster_centers_,\n",
    "                    dtype=torch.float,\n",
    "                    device=latent_features.device\n",
    "                )\n",
    "\n",
    "                self.initialized = True\n",
    "            except Exception as e:\n",
    "                print(f\"Error initializing KMeans: {e}\")\n",
    "                # Fallback: random centroids\n",
    "                print(\"Using random centroids as fallback\")\n",
    "                self.centroids = torch.randn(\n",
    "                    self.n_clusters, latent_features.shape[1],\n",
    "                    device=latent_features.device\n",
    "                )\n",
    "                self.initialized = True\n",
    "\n",
    "        # Compute distances to centroids\n",
    "        distances = torch.cdist(latent_features, self.centroids)\n",
    "\n",
    "        # Convert distances to probabilities\n",
    "        q = 1.0 / (1.0 + distances ** 2)\n",
    "        q = q / q.sum(dim=1, keepdim=True)\n",
    "\n",
    "        # Clustering loss\n",
    "        if target_distribution is not None:\n",
    "            # KL divergence\n",
    "            cluster_loss = F.kl_div(q.log(), target_distribution, reduction='batchmean')\n",
    "        else:\n",
    "            # Basic clustering loss\n",
    "            min_distances = torch.min(distances, dim=1)[0]\n",
    "            cluster_loss = torch.mean(min_distances)\n",
    "\n",
    "        # Regularization\n",
    "        feature_var = torch.var(latent_features, dim=0).mean()\n",
    "        reg_loss = 1.0 / (feature_var + 1e-6)\n",
    "\n",
    "        # Combined loss\n",
    "        total_loss = (\n",
    "            self.alpha * recon_loss +\n",
    "            self.beta * cluster_loss +\n",
    "            self.gamma * reg_loss\n",
    "        )\n",
    "\n",
    "        return total_loss, recon_loss, cluster_loss, reg_loss\n",
    "\n",
    "    def update_centroids(self, latent_features):\n",
    "        \"\"\"Update centroids with current batch features\"\"\"\n",
    "        # Get features\n",
    "        features_np = latent_features.detach().cpu().numpy()\n",
    "        features_np = np.nan_to_num(features_np, nan=0.0)\n",
    "\n",
    "        # Update centroids\n",
    "        try:\n",
    "            self.kmeans.fit(features_np)\n",
    "            self.centroids = torch.tensor(\n",
    "                self.kmeans.cluster_centers_,\n",
    "                dtype=torch.float,\n",
    "                device=latent_features.device\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating centroids: {e}\")\n",
    "\n",
    "        return self.centroids"
   ],
   "id": "ab9c815ae543e453",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping to prevent overfitting\"\"\"\n",
    "    def __init__(self, patience=10, min_delta=0, verbose=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                if self.verbose:\n",
    "                    print(\"Early stopping triggered\")\n",
    "\n",
    "def train_masked_autoencoder(model, train_loader, val_loader=None,\n",
    "                           n_epochs=100, n_clusters=5,\n",
    "                           learning_rate=0.001, device='cuda',\n",
    "                           model_save_path='models',\n",
    "                           update_interval=5,\n",
    "                           patience=10):\n",
    "    \"\"\"\n",
    "    Train the masked autoencoder\n",
    "\n",
    "    Args:\n",
    "        model: Autoencoder model\n",
    "        train_loader: Training data loader\n",
    "        val_loader: Validation data loader (optional)\n",
    "        n_epochs: Number of epochs\n",
    "        n_clusters: Number of clusters\n",
    "        learning_rate: Learning rate\n",
    "        device: Device to use\n",
    "        model_save_path: Path to save model\n",
    "        update_interval: Update clusters every N epochs\n",
    "        patience: Early stopping patience\n",
    "\n",
    "    Returns:\n",
    "        Trained model and history\n",
    "    \"\"\"\n",
    "    # Set device\n",
    "    device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define criterion and optimizer\n",
    "    criterion = MaskedDeepClusteringLoss(n_clusters=n_clusters, alpha=1.0, beta=0.1, gamma=0.01)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(patience=patience)\n",
    "\n",
    "    # Create save directory\n",
    "    os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'recon_loss': [],\n",
    "        'cluster_loss': [],\n",
    "        'reg_loss': []\n",
    "    }\n",
    "\n",
    "    # Track best validation loss\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    # Training loop\n",
    "    start_time = time.time()\n",
    "    print(f\"Starting training for {n_epochs} epochs...\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        recon_loss_sum = 0.0\n",
    "        cluster_loss_sum = 0.0\n",
    "        reg_loss_sum = 0.0\n",
    "        batch_count = 0\n",
    "\n",
    "        # Training\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            # Move data to device\n",
    "            data = batch['data'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            reconstructed, latent, _ = model(data, mask)\n",
    "\n",
    "            # Compute loss\n",
    "            loss, recon_loss, cluster_loss, reg_loss = criterion(\n",
    "                data, reconstructed, latent, mask\n",
    "            )\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping for stability\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update statistics\n",
    "            batch_count += 1\n",
    "            total_loss += loss.item()\n",
    "            recon_loss_sum += recon_loss.item()\n",
    "            cluster_loss_sum += cluster_loss.item()\n",
    "            reg_loss_sum += reg_loss.item()\n",
    "\n",
    "            # Print progress\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{n_epochs}, Batch {batch_idx}, \"\n",
    "                      f\"Loss: {loss.item():.6f}, Recon: {recon_loss.item():.6f}, \"\n",
    "                      f\"Cluster: {cluster_loss.item():.6f}, Reg: {reg_loss.item():.6f}\")\n",
    "\n",
    "        # Update centroids periodically\n",
    "        if epoch % update_interval == 0 and epoch > 0:\n",
    "            # Collect all latent representations\n",
    "            all_features = []\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for batch in train_loader:\n",
    "                    data = batch['data'].to(device)\n",
    "                    mask = batch['mask'].to(device)\n",
    "                    _, latent, _ = model(data, mask)\n",
    "                    all_features.append(latent)\n",
    "\n",
    "            if all_features:\n",
    "                all_features = torch.cat(all_features, dim=0)\n",
    "                criterion.update_centroids(all_features)\n",
    "\n",
    "        # Compute epoch averages\n",
    "        avg_loss = total_loss / batch_count\n",
    "        avg_recon_loss = recon_loss_sum / batch_count\n",
    "        avg_cluster_loss = cluster_loss_sum / batch_count\n",
    "        avg_reg_loss = reg_loss_sum / batch_count\n",
    "\n",
    "        # Validation\n",
    "        val_loss = 0.0\n",
    "        if val_loader is not None:\n",
    "            model.eval()\n",
    "            val_batches = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    data = batch['data'].to(device)\n",
    "                    mask = batch['mask'].to(device)\n",
    "\n",
    "                    # Forward pass\n",
    "                    reconstructed, latent, _ = model(data, mask)\n",
    "\n",
    "                    # Compute reconstruction loss only for validation\n",
    "                    mse_criterion = MaskedMSELoss()\n",
    "                    loss = mse_criterion(reconstructed, data, mask)\n",
    "\n",
    "                    val_loss += loss.item()\n",
    "                    val_batches += 1\n",
    "\n",
    "            if val_batches > 0:\n",
    "                val_loss /= val_batches\n",
    "\n",
    "                # Update learning rate\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "                # Early stopping\n",
    "                early_stopping(val_loss)\n",
    "\n",
    "                # Save best model\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    torch.save(model.state_dict(), os.path.join(model_save_path, 'best_model.pt'))\n",
    "                    print(f\"Saved best model with validation loss: {val_loss:.6f}\")\n",
    "\n",
    "                if early_stopping.early_stop:\n",
    "                    print(\"Early stopping triggered!\")\n",
    "                    break\n",
    "\n",
    "        # Store history\n",
    "        history['train_loss'].append(avg_loss)\n",
    "        history['val_loss'].append(val_loss if val_loader is not None else None)\n",
    "        history['recon_loss'].append(avg_recon_loss)\n",
    "        history['cluster_loss'].append(avg_cluster_loss)\n",
    "        history['reg_loss'].append(avg_reg_loss)\n",
    "\n",
    "        # Print epoch summary\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f'Epoch {epoch+1}/{n_epochs}, Time: {elapsed:.2f}s, '\n",
    "              f'Loss: {avg_loss:.6f}, '\n",
    "              f'Recon: {avg_recon_loss:.6f}, '\n",
    "              f'Cluster: {avg_cluster_loss:.6f}, '\n",
    "              f'Reg: {avg_reg_loss:.6f}' +\n",
    "              (f', Val Loss: {val_loss:.6f}' if val_loader is not None else ''))\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_loss,\n",
    "                'history': history\n",
    "            }, os.path.join(model_save_path, f'checkpoint_{epoch+1}.pt'))\n",
    "\n",
    "    # Save final model\n",
    "    torch.save(model.state_dict(), os.path.join(model_save_path, 'final_model.pt'))\n",
    "\n",
    "    # Save history\n",
    "    np.save(os.path.join(model_save_path, 'training_history.npy'), history)\n",
    "\n",
    "    # Load best model if validation was used\n",
    "    if val_loader is not None:\n",
    "        model.load_state_dict(torch.load(os.path.join(model_save_path, 'best_model.pt')))\n",
    "\n",
    "    return model, history"
   ],
   "id": "2f03433acb5a4353",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set data path to your pickle file\n",
    "data_path = \"../Data/Kiwi Experiment/pickles/masked_KiwiData.pkl\"\n",
    "\n",
    "# Create dataset with patches\n",
    "patch_size = 64  # Can adjust based on your data/memory\n",
    "dataset = MaskedHyperspectralDataset(\n",
    "    pickle_file=data_path,\n",
    "    patch_size=patch_size\n",
    ")\n",
    "\n",
    "# Check sample data to verify mask\n",
    "sample = dataset[0]\n",
    "print(f\"Sample data shape: {sample['data'].shape}\")\n",
    "print(f\"Sample mask shape: {sample['mask'].shape}\")\n",
    "print(f\"Valid data percentage in sample: {sample['mask'].sum().item() / sample['mask'].numel() * 100:.2f}%\")\n",
    "\n",
    "# Split dataset into train/validation\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 8  # Adjust based on your GPU memory\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0  # Set to 0 to avoid multiprocessing issues\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ],
   "id": "9ed3be7b6036a139",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create model\n",
    "n_excitations = dataset.n_excitations\n",
    "n_emissions = dataset.max_emissions\n",
    "n_clusters =  10 # Start with fewer clusters for stability\n",
    "\n",
    "model = MaskedHyperspectralAutoencoder(\n",
    "    n_excitations=n_excitations,\n",
    "    n_emissions=n_emissions,\n",
    "    patch_size=patch_size,\n",
    "    latent_dim=128,  # Lower dimension for start\n",
    "    n_clusters=n_clusters\n",
    ")\n",
    "model = model.to(device)\n",
    "# Print model summary\n",
    "print(f\"Created autoencoder with:\")\n",
    "print(f\"  {n_excitations} excitation wavelengths\")\n",
    "print(f\"  {n_emissions} emission bands\")\n",
    "print(f\"  {n_clusters} clusters\")\n",
    "print(f\"  {patch_size}x{patch_size} patch size\")\n",
    "print(f\"  {sum(p.numel() for p in model.parameters()):,} total parameters\")\n",
    "\n",
    "# Test forward pass with a sample\n",
    "with torch.no_grad():\n",
    "    sample = next(iter(train_loader))\n",
    "    data = sample['data'].to(device)\n",
    "    mask = sample['mask'].to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    try:\n",
    "        reconstructed, latent, cluster_logits = model(data, mask)\n",
    "        print(f\"Forward pass successful!\")\n",
    "        print(f\"Input shape: {data.shape}\")\n",
    "        print(f\"Mask shape: {mask.shape}\")\n",
    "        print(f\"Reconstruction shape: {reconstructed.shape}\")\n",
    "        print(f\"Latent shape: {latent.shape}\")\n",
    "        print(f\"Cluster logits shape: {cluster_logits.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in forward pass: {e}\")"
   ],
   "id": "2a07febc3caf0583",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training parameters\n",
    "epochs = 10  # Can increase for better results\n",
    "learning_rate = 0.0001  # Lower learning rate for stability\n",
    "update_interval = 5  # Update cluster centroids every 5 epochs\n",
    "patience = 15  # Early stopping patience\n",
    "\n",
    "# Train model\n",
    "model, history = train_masked_autoencoder(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    n_epochs=epochs,\n",
    "    n_clusters=n_clusters,\n",
    "    learning_rate=learning_rate,\n",
    "    device=device,\n",
    "    model_save_path=model_dir,\n",
    "    update_interval=update_interval,\n",
    "    patience=patience\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot loss curves\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Training Loss')\n",
    "if history['val_loss'][0] is not None:\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot reconstruction loss\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history['recon_loss'], label='Reconstruction Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Reconstruction Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot clustering loss\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(history['cluster_loss'], label='Clustering Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Clustering Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot regularization loss\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(history['reg_loss'], label='Regularization Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Regularization Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, 'training_history.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "23fa60111479a964",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a dataset for patch-based processing of the full image\n",
    "# (Keep using patches, but reconstruct the full image from patches)\n",
    "full_dataset = MaskedHyperspectralDataset(\n",
    "    pickle_file=data_path,\n",
    "    patch_size=patch_size  # Keep using the same patch size\n",
    ")\n",
    "\n",
    "# Create a label grid to store the results\n",
    "height, width = full_dataset.height, full_dataset.width\n",
    "label_grid = np.zeros((height, width), dtype=int)\n",
    "confidence_grid = np.zeros((height, width), dtype=float)\n",
    "\n",
    "# Process each patch\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(full_dataset)):\n",
    "        batch = full_dataset[idx]\n",
    "        data = batch['data'].unsqueeze(0).to(device)  # Add batch dimension\n",
    "        mask = batch['mask'].unsqueeze(0).to(device)\n",
    "        positions = batch['positions']\n",
    "        y, x = positions.numpy()\n",
    "\n",
    "        # Forward pass\n",
    "        _, latent, cluster_logits = model(data, mask)\n",
    "\n",
    "        # Get cluster predictions\n",
    "        probs = F.softmax(cluster_logits, dim=1)\n",
    "        confidence, predictions = torch.max(probs, dim=1)\n",
    "\n",
    "        # Extract patch predictions\n",
    "        pred_cluster = predictions[0].item()\n",
    "        pred_confidence = confidence[0].item()\n",
    "\n",
    "        # Fill in the label grid with this patch's prediction\n",
    "        # Take a portion of the patch (center region) to avoid overlap issues\n",
    "        center_size = patch_size // 2\n",
    "        center_offset = patch_size // 4\n",
    "\n",
    "        y_start = min(y + center_offset, height - center_size)\n",
    "        x_start = min(x + center_offset, width - center_size)\n",
    "        y_end = min(y_start + center_size, height)\n",
    "        x_end = min(x_start + center_size, width)\n",
    "\n",
    "        # Only update if the confidence is higher than what's already there\n",
    "        for yi in range(y_start, y_end):\n",
    "            for xi in range(x_start, x_end):\n",
    "                if mask[0, :, :, yi-y, xi-x].any() and pred_confidence > confidence_grid[yi, xi]:\n",
    "                    label_grid[yi, xi] = pred_cluster\n",
    "                    confidence_grid[yi, xi] = pred_confidence\n",
    "\n",
    "        # Print progress\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"Processed {idx}/{len(full_dataset)} patches\")\n",
    "\n",
    "# Visualize clusters\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(label_grid, cmap='tab10', interpolation='nearest')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.title(f'Hyperspectral Clustering ({n_clusters} clusters)')\n",
    "plt.savefig(os.path.join(results_dir, 'cluster_map.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "mask_grid = confidence_grid > 0"
   ],
   "id": "3ab4cc7c54106e67",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Analyze spectral characteristics of each cluster\n",
    "cluster_stats = {}\n",
    "\n",
    "# Get excitation and emission wavelengths\n",
    "ex_wavelengths = dataset.excitation_wavelengths\n",
    "em_wavelengths = dataset.wavelength_info  # List of wavelength lists for each excitation\n",
    "\n",
    "# For each cluster, analyze spectral signature\n",
    "for cluster_idx in range(n_clusters):\n",
    "    # Get mask for this cluster\n",
    "    cluster_mask = label_grid == cluster_idx\n",
    "\n",
    "    # Skip if cluster is empty\n",
    "    if not np.any(cluster_mask):\n",
    "        continue\n",
    "\n",
    "    # Get pixel count and percentage\n",
    "    pixel_count = np.sum(cluster_mask)\n",
    "    percentage = pixel_count / np.sum(mask_grid) * 100\n",
    "\n",
    "    # Store basic stats\n",
    "    cluster_stats[cluster_idx] = {\n",
    "        'pixel_count': pixel_count,\n",
    "        'percentage': percentage,\n",
    "        'spectra': {}\n",
    "    }\n",
    "\n",
    "    # Get mean spectrum for each excitation\n",
    "    for ex_idx, ex in enumerate(ex_wavelengths):\n",
    "        # Get wavelengths for this excitation\n",
    "        wavelengths = em_wavelengths[ex_idx]\n",
    "\n",
    "        # Get data for this excitation\n",
    "        ex_data = full_dataset.data_tensor[ex_idx, :len(wavelengths)]\n",
    "\n",
    "        # Extract data for cluster pixels\n",
    "        cluster_data = ex_data[:, cluster_mask]\n",
    "\n",
    "        # Calculate mean spectrum\n",
    "        if cluster_data.size > 0:\n",
    "            mean_spectrum = np.mean(cluster_data, axis=1)\n",
    "\n",
    "            # Find peak wavelength and value\n",
    "            peak_idx = np.argmax(mean_spectrum)\n",
    "            if peak_idx < len(wavelengths):\n",
    "                peak_wavelength = wavelengths[peak_idx]\n",
    "                peak_value = mean_spectrum[peak_idx]\n",
    "            else:\n",
    "                peak_wavelength = None\n",
    "                peak_value = None\n",
    "\n",
    "            # Store spectral data\n",
    "            cluster_stats[cluster_idx]['spectra'][ex] = {\n",
    "                'wavelengths': wavelengths,\n",
    "                'mean_spectrum': mean_spectrum,\n",
    "                'peak_wavelength': peak_wavelength,\n",
    "                'peak_value': peak_value\n",
    "            }\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nCluster Statistics:\\n\")\n",
    "print(f\"{'Cluster':<10} {'Pixels':<10} {'Percentage':<15} {'Notable Peaks'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for cluster_idx, stats in cluster_stats.items():\n",
    "    # Get top peaks\n",
    "    peak_info = []\n",
    "    for ex, ex_data in stats['spectra'].items():\n",
    "        if ex_data['peak_wavelength'] is not None:\n",
    "            peak_info.append((ex, ex_data['peak_wavelength'], ex_data['peak_value']))\n",
    "\n",
    "    # Sort by intensity\n",
    "    peak_info.sort(key=lambda x: x[2] if x[2] is not None else 0, reverse=True)\n",
    "\n",
    "    # Format peak info text\n",
    "    peak_text = \", \".join(f\"Ex:{ex:.0f}/Em:{em:.0f}\" for ex, em, _ in peak_info[:2])\n",
    "\n",
    "    print(f\"{cluster_idx:<10} {stats['pixel_count']:<10} {stats['percentage']:.2f}%{' ':<10} {peak_text}\")\n",
    "\n",
    "# Plot spectral signatures by cluster\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Sample a few excitation wavelengths to plot\n",
    "plot_ex_indices = np.linspace(0, len(ex_wavelengths)-1, min(5, len(ex_wavelengths)), dtype=int)\n",
    "\n",
    "for i, ex_idx in enumerate(plot_ex_indices):\n",
    "    ex = ex_wavelengths[ex_idx]\n",
    "    wavelengths = em_wavelengths[ex_idx]\n",
    "\n",
    "    plt.subplot(len(plot_ex_indices), 1, i+1)\n",
    "\n",
    "    for cluster_idx, stats in cluster_stats.items():\n",
    "        if ex in stats['spectra']:\n",
    "            spectrum = stats['spectra'][ex]['mean_spectrum']\n",
    "            plt.plot(wavelengths, spectrum, '-', linewidth=2, label=f'Cluster {cluster_idx}')\n",
    "\n",
    "    plt.xlabel('Emission Wavelength (nm)')\n",
    "    plt.ylabel('Mean Intensity')\n",
    "    plt.title(f'Excitation: {ex} nm')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    if i == 0:  # Only add legend to first plot\n",
    "        plt.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, 'spectral_signatures.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save cluster stats\n",
    "with open(os.path.join(results_dir, 'cluster_stats.pkl'), 'wb') as f:\n",
    "    pickle.dump(cluster_stats, f)"
   ],
   "id": "863bfd99ff89704c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a4e8197b3871ca6f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
