{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-21T17:28:29.240168Z",
     "start_time": "2025-04-21T17:28:26.479371Z"
    }
   },
   "source": [
    "# CNN-Autoencoder.ipynb\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "# Import our modules - importing from the current directory\n",
    "from HyperspectralDataset import HyperspectralDataset\n",
    "from HyperspectralAutoencoder import PatchedHyperspectralAutoencoder\n",
    "from training_utils import train_autoencoder, plot_training_history, evaluate_clustering\n",
    "from visualization_utils import (\n",
    "    visualize_reconstructions,\n",
    "    visualize_cluster_map,\n",
    "    visualize_feature_space,\n",
    "    visualize_spectral_signatures\n",
    ")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create output directories\n",
    "output_dir = \"output\"\n",
    "model_dir = os.path.join(output_dir, 'models')\n",
    "results_dir = os.path.join(output_dir, 'results')\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T17:28:31.806118Z",
     "start_time": "2025-04-21T17:28:29.398277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set path to your data pickle file - update this to point to your data\n",
    "data_path = \"../Data/Kiwi Experiment/pickles/masked_KiwiData.pkl\"\n",
    "\n",
    "# For this example, we'll use patch-based training\n",
    "use_patches = True\n",
    "patch_size = 64\n",
    "\n",
    "dataset = HyperspectralDataset(\n",
    "    data_path,\n",
    "    patch_size=patch_size if use_patches else None\n",
    ")\n",
    "\n",
    "n_excitations = len(dataset.excitation_wavelengths)\n",
    "n_emissions = dataset.max_emissions\n",
    "height, width = dataset.height, dataset.width\n",
    "\n",
    "print(f\"Dataset created with dimensions: {height}x{width}, {n_excitations} excitations, {n_emissions} emissions\")"
   ],
   "id": "2c7f0b76ac2a16d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ..\\Data\\Kiwi Experiment\\pickles\\masked_KiwiData.pkl...\n",
      "Found 21 excitation wavelengths\n",
      "Image dimensions: 1024 x 1392\n",
      "Maximum emission bands: 31\n",
      "Created 1302 patches of size 64x64\n",
      "Dataset created with dimensions: 1024x1392, 21 excitations, 31 emissions\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T17:28:31.823040Z",
     "start_time": "2025-04-21T17:28:31.818677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split dataset into train and validation sets\n",
    "val_split = 0.2  # 20% for validation\n",
    "\n",
    "if use_patches:\n",
    "    train_size = int((1 - val_split) * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    print(f\"Split into {train_size} training patches and {val_size} validation patches\")\n",
    "else:\n",
    "    # For whole-image training, we don't split\n",
    "    train_dataset, val_dataset = dataset, None\n",
    "    print(\"Using whole image - no validation split applied\")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32 if use_patches else 1\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True if use_patches else False,\n",
    "    num_workers=0  # Changed from 4 to 0 to avoid the multiprocessing error\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0  # Changed from 4 to 0\n",
    ") if val_dataset is not None else None"
   ],
   "id": "e1279fffacd5936d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 1041 training patches and 261 validation patches\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T17:28:31.859892Z",
     "start_time": "2025-04-21T17:28:31.833970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model hyperparameters\n",
    "latent_dim = 128\n",
    "n_clusters = 10\n",
    "\n",
    "# Create the model\n",
    "model = PatchedHyperspectralAutoencoder(\n",
    "    n_excitations=n_excitations,\n",
    "    n_emissions=n_emissions,\n",
    "    patch_size=patch_size,\n",
    "    latent_dim=latent_dim,\n",
    "    n_clusters=n_clusters\n",
    ")\n",
    "print(f\"Created patched autoencoder with {patch_size}x{patch_size} patches\")\n",
    "\n",
    "# Print model summary\n",
    "print(f\"Model has {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ],
   "id": "4423637e83246d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created patched autoencoder with 64x64 patches\n",
      "Model has 5,710,827 parameters\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T17:28:32.659817Z",
     "start_time": "2025-04-21T17:28:31.873006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First, move the model to the same device as the data\n",
    "model = model.to(device)\n",
    "print(f\"Model moved to {device}\")\n",
    "\n",
    "# Check the shapes of data from the DataLoader\n",
    "for data in train_loader:\n",
    "    print(f\"Input data shape: {data.shape}\")\n",
    "    break\n",
    "\n",
    "# Test a forward pass through the model\n",
    "with torch.no_grad():\n",
    "    # Now both model and data are on the same device\n",
    "    data = data.to(device)\n",
    "    reconstructed, latent, _ = model(data)\n",
    "    print(f\"Original shape: {data.shape}\")\n",
    "    print(f\"Reconstructed shape: {reconstructed.shape}\")\n",
    "    print(f\"Latent shape: {latent.shape}\")"
   ],
   "id": "a9081baecacfbce8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to cuda\n",
      "Input data shape: torch.Size([32, 21, 31, 64, 64])\n",
      "Original shape: torch.Size([32, 21, 31, 64, 64])\n",
      "Reconstructed shape: torch.Size([32, 21, 31, 64, 64])\n",
      "Latent shape: torch.Size([32, 128])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T17:31:20.235311Z",
     "start_time": "2025-04-21T17:31:19.676113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Before training, check if input data already contains NaNs\n",
    "for batch_idx, data in enumerate(train_loader):\n",
    "    if torch.isnan(data).any():\n",
    "        print(f\"Input batch {batch_idx} contains {torch.isnan(data).sum().item()} NaN values!\")\n",
    "        # Print where they occur\n",
    "        nan_indices = torch.where(torch.isnan(data))\n",
    "        print(f\"First few NaN positions: {[(i.item(), j.item()) for i, j in zip(nan_indices[0][:5], nan_indices[1][:5])]}\")\n",
    "    else:\n",
    "        print(f\"Batch {batch_idx} input is clean (no NaNs)\")\n",
    "    break"
   ],
   "id": "f712816bc0728c7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch 0 contains 8714372 NaN values!\n",
      "First few NaN positions: [(0, 0), (0, 0), (0, 0), (0, 0), (0, 0)]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T17:30:39.293173Z",
     "start_time": "2025-04-21T17:28:33.343337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training parameters - use smaller epochs for initial testing\n",
    "epochs = 10  # For a full run, use 50+ epochs\n",
    "learning_rate = 0.001\n",
    "update_interval = 5\n",
    "patience = 10\n",
    "\n",
    "model, history = train_autoencoder(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    n_epochs=epochs,\n",
    "    n_clusters=n_clusters,\n",
    "    learning_rate=learning_rate,\n",
    "    device=device,\n",
    "    model_save_path=model_dir,\n",
    "    update_interval=update_interval,\n",
    "    patience=patience\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "history_path = os.path.join(results_dir, 'training_history.png')\n",
    "plot_training_history(history, save_path=history_path)"
   ],
   "id": "2af38eaf345ab37d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meloy\\PycharmProjects\\Capstone\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 10 epochs...\n",
      "Warning: Found 4096 NaN values in features\n",
      "All samples contain NaN values - replacing NaNs with zeros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meloy\\PycharmProjects\\Capstone\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 1/10, Time: 19.24s, Loss: nan, Recon: nan, Cluster: nan, Reg: nan, Val Loss: nan\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 2/10, Time: 38.12s, Loss: nan, Recon: nan, Cluster: nan, Reg: nan, Val Loss: nan\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 3/10, Time: 57.09s, Loss: nan, Recon: nan, Cluster: nan, Reg: nan, Val Loss: nan\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 4/10, Time: 76.37s, Loss: nan, Recon: nan, Cluster: nan, Reg: nan, Val Loss: nan\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch 5/10, Time: 95.78s, Loss: nan, Recon: nan, Cluster: nan, Reg: nan, Val Loss: nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      4\u001B[39m update_interval = \u001B[32m5\u001B[39m\n\u001B[32m      5\u001B[39m patience = \u001B[32m10\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m model, history = \u001B[43mtrain_autoencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m    \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_clusters\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_clusters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_save_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[43m    \u001B[49m\u001B[43mupdate_interval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mupdate_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpatience\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpatience\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     20\u001B[39m \u001B[38;5;66;03m# Plot training history\u001B[39;00m\n\u001B[32m     21\u001B[39m history_path = os.path.join(results_dir, \u001B[33m'\u001B[39m\u001B[33mtraining_history.png\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Capstone\\Loader\\Deep Learning\\training_utils.py:294\u001B[39m, in \u001B[36mtrain_autoencoder\u001B[39m\u001B[34m(model, train_loader, val_loader, n_epochs, n_clusters, learning_rate, device, model_save_path, update_interval, patience)\u001B[39m\n\u001B[32m    291\u001B[39m             all_features.append(latent)\n\u001B[32m    293\u001B[39m     all_features = torch.cat(all_features, dim=\u001B[32m0\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m294\u001B[39m     \u001B[43mcriterion\u001B[49m\u001B[43m.\u001B[49m\u001B[43mupdate_centroids\u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_features\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    296\u001B[39m \u001B[38;5;66;03m# Compute epoch averages\u001B[39;00m\n\u001B[32m    297\u001B[39m train_samples = \u001B[38;5;28mlen\u001B[39m(train_loader.dataset)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Capstone\\Loader\\Deep Learning\\training_utils.py:129\u001B[39m, in \u001B[36mDeepClusteringLoss.update_centroids\u001B[39m\u001B[34m(self, latent_features)\u001B[39m\n\u001B[32m    126\u001B[39m features_np = latent_features.detach().cpu().numpy()\n\u001B[32m    128\u001B[39m \u001B[38;5;66;03m# Update centroids with new k-means\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m129\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mkmeans\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures_np\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    130\u001B[39m \u001B[38;5;28mself\u001B[39m.centroids = torch.tensor(\n\u001B[32m    131\u001B[39m     \u001B[38;5;28mself\u001B[39m.kmeans.cluster_centers_,\n\u001B[32m    132\u001B[39m     dtype=torch.float,\n\u001B[32m    133\u001B[39m     device=latent_features.device\n\u001B[32m    134\u001B[39m )\n\u001B[32m    136\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.centroids\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Capstone\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1382\u001B[39m     estimator._validate_params()\n\u001B[32m   1384\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1385\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1386\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1387\u001B[39m     )\n\u001B[32m   1388\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1389\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Capstone\\.venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1454\u001B[39m, in \u001B[36mKMeans.fit\u001B[39m\u001B[34m(self, X, y, sample_weight)\u001B[39m\n\u001B[32m   1426\u001B[39m \u001B[38;5;129m@_fit_context\u001B[39m(prefer_skip_nested_validation=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m   1427\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y=\u001B[38;5;28;01mNone\u001B[39;00m, sample_weight=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m   1428\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Compute k-means clustering.\u001B[39;00m\n\u001B[32m   1429\u001B[39m \n\u001B[32m   1430\u001B[39m \u001B[33;03m    Parameters\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1452\u001B[39m \u001B[33;03m        Fitted estimator.\u001B[39;00m\n\u001B[32m   1453\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1454\u001B[39m     X = \u001B[43mvalidate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1455\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1456\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1457\u001B[39m \u001B[43m        \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcsr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1458\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfloat64\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfloat32\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1459\u001B[39m \u001B[43m        \u001B[49m\u001B[43morder\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mC\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1460\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcopy_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1461\u001B[39m \u001B[43m        \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1462\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1464\u001B[39m     \u001B[38;5;28mself\u001B[39m._check_params_vs_input(X)\n\u001B[32m   1466\u001B[39m     random_state = check_random_state(\u001B[38;5;28mself\u001B[39m.random_state)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Capstone\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001B[39m, in \u001B[36mvalidate_data\u001B[39m\u001B[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001B[39m\n\u001B[32m   2942\u001B[39m         out = X, y\n\u001B[32m   2943\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[32m-> \u001B[39m\u001B[32m2944\u001B[39m     out = \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mX\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2945\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n\u001B[32m   2946\u001B[39m     out = _check_y(y, **check_params)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Capstone\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1107\u001B[39m, in \u001B[36mcheck_array\u001B[39m\u001B[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[39m\n\u001B[32m   1101\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1102\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m expected <= 2.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1103\u001B[39m         % (array.ndim, estimator_name)\n\u001B[32m   1104\u001B[39m     )\n\u001B[32m   1106\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m ensure_all_finite:\n\u001B[32m-> \u001B[39m\u001B[32m1107\u001B[39m     \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1108\u001B[39m \u001B[43m        \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1109\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1110\u001B[39m \u001B[43m        \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1111\u001B[39m \u001B[43m        \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[43m=\u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mallow-nan\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1112\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1114\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m copy:\n\u001B[32m   1115\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m _is_numpy_namespace(xp):\n\u001B[32m   1116\u001B[39m         \u001B[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Capstone\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001B[39m, in \u001B[36m_assert_all_finite\u001B[39m\u001B[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[39m\n\u001B[32m    117\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m first_pass_isfinite:\n\u001B[32m    118\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m120\u001B[39m \u001B[43m_assert_all_finite_element_wise\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    121\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    122\u001B[39m \u001B[43m    \u001B[49m\u001B[43mxp\u001B[49m\u001B[43m=\u001B[49m\u001B[43mxp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    123\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[43m=\u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    124\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmsg_dtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmsg_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    125\u001B[39m \u001B[43m    \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    126\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    127\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Capstone\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001B[39m, in \u001B[36m_assert_all_finite_element_wise\u001B[39m\u001B[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001B[39m\n\u001B[32m    152\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name == \u001B[33m\"\u001B[39m\u001B[33mX\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[32m    153\u001B[39m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[32m    154\u001B[39m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[32m    155\u001B[39m     msg_err += (\n\u001B[32m    156\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m does not accept missing values\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    157\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m    167\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m#estimators-that-handle-nan-values\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    168\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m169\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[31mValueError\u001B[39m: Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "eval_dataset = HyperspectralDataset(data_path)\n",
    "\n",
    "eval_loader = DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=1,  # Process as a single batch for full image\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "# Perform clustering\n",
    "result = evaluate_clustering(\n",
    "    model=model,\n",
    "    dataloader=eval_loader,\n",
    "    n_clusters=n_clusters,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"Clustering completed with {n_clusters} clusters\")\n",
    "print(f\"Metrics: {result['metrics']}\")"
   ],
   "id": "8e1737ea91e104b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get original and reconstructed data for visualization\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in eval_loader:\n",
    "        batch = batch.to(device)\n",
    "        reconstructed, _, _ = model(batch)\n",
    "        original_data = batch.cpu().numpy()\n",
    "        reconstructed_data = reconstructed.cpu().numpy()\n",
    "        break  # Just need one batch for visualization\n",
    "\n",
    "print(\"Data extracted for visualization\")"
   ],
   "id": "ad2de9a12961ae62"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1. Visualize Reconstructions\n",
    "fig = visualize_reconstructions(\n",
    "    original_data, reconstructed_data, n_samples=5,\n",
    "    excitation_idx=0, emission_idx=None,\n",
    "    save_path=os.path.join(results_dir, 'reconstructions.png')\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# 2. Visualize Cluster Map\n",
    "fig = visualize_cluster_map(\n",
    "    result['cluster_labels'], height, width, n_clusters,\n",
    "    save_path=os.path.join(results_dir, 'cluster_map.png')\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# 3. Visualize Feature Space with PCA\n",
    "fig = visualize_feature_space(\n",
    "    result['features'], result['cluster_labels'], n_clusters, method='pca',\n",
    "    save_path=os.path.join(results_dir, 'feature_space_pca.png')\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# 4. Visualize Spectral Signatures for Each Cluster\n",
    "fig = visualize_spectral_signatures(\n",
    "    eval_dataset.data_dict, result['cluster_labels'],\n",
    "    eval_dataset.data_dict, height, width, n_clusters,\n",
    "    save_path=os.path.join(results_dir, 'spectral_signatures.png')\n",
    ")\n",
    "plt.show()"
   ],
   "id": "b23d8c96ac6b94cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Reshape labels to match image dimensions\n",
    "cluster_image = result['cluster_labels'].reshape(height, width)\n",
    "\n",
    "# Count pixels in each cluster\n",
    "cluster_counts = np.bincount(result['cluster_labels'], minlength=n_clusters)\n",
    "cluster_percentages = cluster_counts / len(result['cluster_labels']) * 100\n",
    "\n",
    "# Print cluster statistics\n",
    "print(f\"\\nCluster Statistics (n_clusters={n_clusters}):\\n\")\n",
    "print(f\"{'Cluster':<10} {'Pixels':<10} {'Percentage':<10}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    print(f\"{i:<10} {cluster_counts[i]:<10} {cluster_percentages[i]:.2f}%\")\n",
    "\n",
    "# Save the clustering results\n",
    "results_file = os.path.join(results_dir, 'clustering_results.pkl')\n",
    "with open(results_file, 'wb') as f:\n",
    "    pickle.dump(result, f)\n",
    "\n",
    "print(f\"Clustering results saved to {results_file}\")\n",
    "\n",
    "# Save model for later use\n",
    "model_file = os.path.join(model_dir, 'final_model.pt')\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'n_excitations': n_excitations,\n",
    "    'n_emissions': n_emissions,\n",
    "    'patch_size': patch_size,\n",
    "    'latent_dim': latent_dim,\n",
    "    'n_clusters': n_clusters\n",
    "}, model_file)\n",
    "\n",
    "print(f\"Model saved to {model_file}\")\n",
    "print(f\"\\nEntire pipeline completed successfully!\")"
   ],
   "id": "de68bd884546ff8a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
